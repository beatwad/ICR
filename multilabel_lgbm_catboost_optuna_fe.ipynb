{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabpfn --no-index --find-links=file:///kaggle/input/tab-pfn-dataset\n",
    "# !mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "# !cp /kaggle/input/tab-pfn-dataset/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/\n",
    "\n",
    "# !pip install adjdatatools --no-index --find-links=file:///kaggle/input/adjdatatools\n",
    "# !pip -q install featurewiz --no-index --find-links=file:///kaggle/input/featurewiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:23.665663Z",
     "iopub.status.busy": "2023-06-08T15:31:23.665223Z",
     "iopub.status.idle": "2023-06-08T15:31:35.997437Z",
     "shell.execute_reply": "2023-06-08T15:31:35.996163Z",
     "shell.execute_reply.started": "2023-06-08T15:31:23.665630Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/iter-strat/iter_strat')\n",
    "\n",
    "import math\n",
    "import copy \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "from catboost import Pool\n",
    "import xgboost as xgb\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import category_encoders as encoders\n",
    "\n",
    "import itertools\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits, BaseShuffleSplit, _validate_shuffle_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from adjdatatools.preprocessing import AdjustedScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import _num_samples, check_array\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import eli5\n",
    "from IPython.display import display\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "from colorama import Style, Fore\n",
    "\n",
    "palette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n",
    "           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n",
    "\n",
    "blk = Style.BRIGHT + Fore.BLACK\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "res = Style.RESET_ALL\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    # main\n",
    "    kaggle = False\n",
    "    test = False\n",
    "    \n",
    "    # features\n",
    "    fe_drop = True\n",
    "    \n",
    "    fix_errs = False\n",
    "    err_objs = [292, 102, 509, 367, 313, 380, 556]\n",
    "\n",
    "    del_outliers = False\n",
    "    del_outliers_adj = True\n",
    "    \n",
    "    feature_sel = False\n",
    "    n_feature_sel_repeats = 5\n",
    "    n_feature_sel_folds = 5\n",
    "    \n",
    "    undersample = False\n",
    "    oversample = False\n",
    "    \n",
    "    nan_impute = True\n",
    "    encode_cat = False\n",
    "    standard_scale = False\n",
    "    log = False\n",
    "    \n",
    "    # optimization\n",
    "    n_estimators = 3000\n",
    "    early_stopping_rounds = 100\n",
    "    \n",
    "    lgbm_optimize = False\n",
    "    lgbm_optimize2 = True\n",
    "    xgb_optimize = False\n",
    "    cb_optimize = False\n",
    "    \n",
    "    n_trials = 500\n",
    "    n_optimize_folds = 5\n",
    "    n_optimize_repeats = 3\n",
    "    \n",
    "    # train\n",
    "    k_fold = False\n",
    "    strat_k_fold = True\n",
    "    add_err_objs = False\n",
    "    select_best_fold = False\n",
    "    \n",
    "    lgbm_train = True\n",
    "    xgb_train = False\n",
    "    cb_train = False\n",
    "    tabpfn_train = False\n",
    "    logreg_train = False\n",
    "\n",
    "    # inference\n",
    "    n_stacking_folds = 5\n",
    "    n_stacking_folds_min = 1\n",
    "    n_stacking_folds_max = 5\n",
    "\n",
    "    n_stacking_models_lgbm = 5\n",
    "    n_stacking_models_xgb = 10\n",
    "    n_stacking_models_cb = 5\n",
    "    n_stacking_models_tabpfn = 5\n",
    "\n",
    "    adjust_class_threshold = False\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.001085Z",
     "iopub.status.busy": "2023-06-08T15:31:35.999808Z",
     "iopub.status.idle": "2023-06-08T15:31:36.066222Z",
     "shell.execute_reply": "2023-06-08T15:31:36.064862Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.001050Z"
    }
   },
   "outputs": [],
   "source": [
    "if CFG.kaggle:\n",
    "    COMP_PATH = \"/kaggle/input/icr-identify-age-related-conditions\"\n",
    "else:\n",
    "    COMP_PATH = \"icr-identify-age-related-conditions\"\n",
    "\n",
    "train_df = pd.read_csv(f'{COMP_PATH}/train.csv')\n",
    "test_df = pd.read_csv(f'{COMP_PATH}/test.csv')\n",
    "greeks = pd.read_csv(f\"{COMP_PATH}/greeks.csv\")\n",
    "sample_submission = pd.read_csv(f\"{COMP_PATH}/sample_submission.csv\")\n",
    "\n",
    "train_df['EJ'] = train_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "test_df['EJ'] = test_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "\n",
    "train_df.columns = train_df.columns.str.replace(' ', '')\n",
    "test_df.columns = test_df.columns.str.replace(' ', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix erroneus objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.fix_errs:\n",
    "    train_df.loc[CFG.err_objs, 'Class'] = 1 - train_df.loc[CFG.err_objs, 'Class']\n",
    "\n",
    "class_imbalance = train_df[train_df['Class'] == 0].shape[0] / train_df[train_df['Class'] == 1].shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "if CFG.nan_impute:\n",
    "    #EL datasets\n",
    "    train_el_df = train_df[~train_df.EL.isna()]\n",
    "    X_train_el_df=train_el_df.drop(['BQ', 'EL', 'Class', 'Id'], axis=1)\n",
    "    y_train_el_df=train_el_df.EL\n",
    "\n",
    "    val_el_df = train_df[train_df.EL.isna()]\n",
    "    X_val_el_df = val_el_df.drop(['BQ', 'EL', 'Class', 'Id'], axis=1)\n",
    "\n",
    "#     test_df['EL'] = [0, 0, np.nan, 0, np.nan]\n",
    "#     test_df['CU'] = [np.nan, 0, np.nan, np.nan, 0]\n",
    "    \n",
    "    test_el_df = test_df[test_df.EL.isna()]\n",
    "    X_test_el_df = test_el_df.drop(['BQ', 'EL', 'Id'], axis=1)\n",
    "\n",
    "    #making grid for hyperparamters optimization for feature selection\n",
    "    el_grid_fs = GridSearchCV(xgb.XGBRegressor(), param_grid={'n_estimators':[50,80,100], 'eta': [0.001, 0.005, 0.01, 0.03, 0.1, 1]},\n",
    "                            n_jobs=-1, cv=10, verbose=1,scoring='neg_mean_squared_error')\n",
    "    el_grid_fs.fit(X_train_el_df, y_train_el_df)\n",
    "\n",
    "    #making model for features selection\n",
    "    el_model_fs = xgb.XGBRegressor(n_estimators=el_grid_fs.best_params_['n_estimators'], eta=el_grid_fs.best_params_['eta'])\n",
    "    el_model_fs.fit(X_train_el_df, y_train_el_df)\n",
    "\n",
    "    #chosing 10 most important features\n",
    "    feature_importances = el_model_fs.feature_importances_\n",
    "    sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "    features_el = sorted_indices[:10]\n",
    "\n",
    "    X_train_el_df = X_train_el_df.iloc[:,features_el]\n",
    "    X_val_el_df = X_val_el_df.iloc[:,features_el]\n",
    "    X_test_el_df = X_test_el_df.iloc[:,features_el]\n",
    "\n",
    "    #making grid for hyperparamters optimization for prediction\n",
    "    el_grid = GridSearchCV(xgb.XGBRegressor(), param_grid={'n_estimators':[50,80,100], 'eta': [0.001, 0.005, 0.01, 0.03, 0.1, 1]},\n",
    "                            n_jobs=-1, cv=10, verbose=1, scoring='neg_mean_squared_error')\n",
    "    el_grid.fit(X_train_el_df, y_train_el_df)\n",
    "\n",
    "    #making model for prediction\n",
    "    el_model = xgb.XGBRegressor(n_estimators=el_grid.best_params_['n_estimators'], eta=el_grid.best_params_['eta'])\n",
    "    el_model.fit(X_train_el_df, y_train_el_df)\n",
    "\n",
    "    el_pred = el_model.predict(X_val_el_df)\n",
    "    train_df.loc[train_df.EL.isna(), 'EL'] = el_pred\n",
    "\n",
    "    if X_test_el_df.shape[0] > 0:\n",
    "        try:\n",
    "            el_pred_test = el_model.predict(X_test_el_df)\n",
    "            test_df.loc[test_df.EL.isna(), 'EL'] = el_pred_test\n",
    "        except:\n",
    "            el_pred_test = el_model.predict(X_test_el_df.fillna(X_test_el_df.mean()))\n",
    "            test_df.loc[test_df.EL.isna(), 'EL'] = el_pred_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop not necessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 41, 58)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['DI DU'] = train_df['DI'] * train_df['DU']\n",
    "test_df['DI DU'] = test_df['DI'] * test_df['DU']\n",
    "\n",
    "train_df['DA DE'] = train_df['DA'] * train_df['DE']\n",
    "test_df['DA DE'] = test_df['DA'] * test_df['DE']\n",
    "\n",
    "train_df['DH EG'] = train_df['DH'] * train_df['EG']\n",
    "test_df['DH EG'] = test_df['DH'] * test_df['EG']\n",
    "\n",
    "if CFG.fe_drop:\n",
    "    features = [fe for fe in train_df.columns if fe not in ['CF', 'CB', 'DV', 'BR', 'DF', 'GB', 'AH',\n",
    "                                                            'CW', 'CL', 'BP', 'BD', 'FC', 'GE', 'GF',\n",
    "                                                            'AR', 'GI', 'Id', 'Class', 'AX', 'DA']]\n",
    "else:\n",
    "    features = [fe for fe in train_df.columns if fe not in ['Id', 'Class', 'EJ']]\n",
    "\n",
    "num_cols = [nc for nc in train_df.select_dtypes(include=['float64']).columns if nc != 'Class']\n",
    "\n",
    "# clip values to avoid different values in the test set from train\n",
    "test_df[features] = test_df[features].clip(train_df[features].min(axis=0).values, train_df[features].max(axis=0).values, axis=1)\n",
    "\n",
    "len(train_df.columns), len(features), len(num_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_outliers = [fe for fe in train_df.columns if fe not in ['BN', 'BQ', 'CW', 'EL', 'GH', \n",
    "                                                                      'GI', 'GL', 'Id', 'Class', 'EJ']]\n",
    "\n",
    "if CFG.del_outliers:\n",
    "    for f in features_with_outliers:\n",
    "        train_df[f] = train_df[f].clip(upper=train_df[f].quantile(0.99))\n",
    "        test_df[f] = test_df[f].clip(upper=test_df[f].quantile(0.99))\n",
    "\n",
    "if CFG.del_outliers_adj:\n",
    "    adj_scaler = AdjustedScaler(with_centering=True)\n",
    "    adj_features = ['EL', 'CH', 'DA', 'EE', 'GH', 'DY']\n",
    "    \n",
    "    adj_scaler.fit(train_df[adj_features])\n",
    "    train_df[['EL_adj', 'CH', 'DA_adj', 'EE_adj', 'GH_adj', 'DY_adj']] = adj_scaler.transform(train_df[adj_features])\n",
    "    test_df[['EL_adj', 'CH', 'DA_adj', 'EE_adj', 'GH_adj', 'DY_adj']] = adj_scaler.transform(test_df[adj_features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.log:\n",
    "    train_df[num_cols] = np.log1p(train_df[num_cols])\n",
    "    test_df[num_cols] = np.log1p(test_df[num_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:41.223344Z",
     "iopub.status.busy": "2023-06-08T15:32:41.222954Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    N_inv_0 = 1/N_0 if N_0 > 0 else 0\n",
    "    N_inv_1 = 1/N_1 if N_1 > 0 else 0\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability 𝑝 is replaced with max(min(𝑝,1−10−15),10−15)\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - N_inv_0 * np.sum((1 - y_true) * np.log(1 - y_pred)) - N_inv_1 * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2\n",
    "\n",
    "if not CFG.kaggle and CFG.feature_sel:\n",
    "\n",
    "    from shaphypetune import BoostBoruta\n",
    "\n",
    "    params = {\n",
    "                'n_estimators': CFG.n_estimators,\n",
    "                'early_stopping_round': CFG.early_stopping_rounds,\n",
    "                'objective': 'binary',\n",
    "                'metric': 'logloss', \n",
    "                'n_jobs': -1,\n",
    "                'is_unbalance':True, \n",
    "                'class_weight':'balanced', \n",
    "                'verbose': -1,\n",
    "                'seed': 19062023,\n",
    "            }\n",
    "\n",
    "    def bll_metric(y_true, y_pred):\n",
    "        return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "    def lgbm_tuning(features, permut=False, boruta=False):\n",
    "        metric = balanced_log_loss\n",
    "        eval_results_ = {}\n",
    "\n",
    "        cv_scores = [] # store all cv scores of outer loop inference\n",
    "\n",
    "        perm_df_ = pd.DataFrame()\n",
    "        feature_importances_ = pd.DataFrame()\n",
    "        boruta_df_ = pd.DataFrame()\n",
    "        \n",
    "        for i in range(CFG.n_feature_sel_repeats):\n",
    "            print(f'Repeat {blu}#{i+1}')\n",
    "            \n",
    "            # Make random under-sampling to balance classes\n",
    "            positive_count_train = train_df['Class'].value_counts()[1]\n",
    "            sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train * 3, \n",
    "                                                            1: positive_count_train}, \n",
    "                                        random_state=15062023+i, \n",
    "                                        replacement=True)\n",
    "\n",
    "            X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "            \n",
    "            if CFG.undersample:\n",
    "                X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "            \n",
    "            # Create Stratified Multilabel k-Fold scheme\n",
    "            kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=8062023+i)\n",
    "\n",
    "            # Create an oof array for inner loop\n",
    "            oof = np.zeros(X_re.shape[0])\n",
    "            \n",
    "            # Stratify based on Class and Alpha (3 types of conditions)\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start = 1): \n",
    "                X, y = X_re[features], y_re\n",
    "\n",
    "                # Split the dataset according to the fold indexes.\n",
    "                X_train = X.iloc[train_idx]\n",
    "                X_val = X.iloc[val_idx]\n",
    "                y_train = y.iloc[train_idx]\n",
    "                y_val = y.iloc[val_idx]\n",
    "\n",
    "                X_train = X_train.reset_index(drop=True)\n",
    "                y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "                # Store models here\n",
    "                models_ = [] \n",
    "\n",
    "                eval_results_[fold]= {}\n",
    "\n",
    "                clf = lgb.LGBMClassifier(**params)\n",
    "                clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=bll_metric, verbose=0)\n",
    "\n",
    "                models_.append(clf)\n",
    "\n",
    "                val_preds = clf.predict_proba(X_val)[:,1]\n",
    "                oof[val_idx] = val_preds\n",
    "\n",
    "                val_score = metric(y_val, val_preds)\n",
    "                best_iter = clf.best_iteration_\n",
    "\n",
    "                print(f'Fold: {blu}{fold:>3}{res}| {metric.__name__}: {blu}{val_score:.5f}{res}'\n",
    "                    f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "\n",
    "                # permutation importance\n",
    "                if permut:\n",
    "                    perm = PermutationImportance(clf, scoring=None, n_iter=1, \n",
    "                                                random_state=42, cv=None, refit=False).fit(X_val, y_val)\n",
    "\n",
    "                    perm_importance_df = pd.DataFrame({'importance': perm.feature_importances_}, \n",
    "                                                    index=X_val.columns).sort_index()\n",
    "\n",
    "                    if perm_df_.shape[0] == 0:\n",
    "                        perm_df_ = perm_importance_df.copy()\n",
    "                    else:\n",
    "                        perm_df_ += perm_importance_df\n",
    "\n",
    "                # tree feature importance\n",
    "                f_i = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns), \n",
    "                                                reverse=True, key=lambda x: x[1]), \n",
    "                                columns=['Value','Feature'])\n",
    "\n",
    "                if feature_importances_.shape[0] == 0:\n",
    "                    feature_importances_ = f_i.copy()\n",
    "                else:\n",
    "\n",
    "                    feature_importances_['Value'] += f_i['Value']\n",
    "\n",
    "                # Boruta SHAP importance\n",
    "                if boruta:\n",
    "                    model = BoostBoruta(clf, importance_type='shap_importances', train_importance=False)\n",
    "                    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=bll_metric, verbose=0)\n",
    "\n",
    "                    boruta_importance_df = pd.DataFrame({'importance': model.ranking_}, index=X_train.columns).sort_index()\n",
    "                    if boruta_df_.shape[0] == 0:\n",
    "                        boruta_df_ = boruta_importance_df.copy()\n",
    "                    else:\n",
    "                        boruta_df_ += boruta_importance_df\n",
    "\n",
    "            fold_cv_score = metric(y_re, oof)\n",
    "            print(f'{red} CV score: {res} {metric.__name__}: {red}{fold_cv_score:.5f}{res}')\n",
    "            print(f'{\"*\" * 50}\\n')\n",
    "            cv_scores.append(fold_cv_score)\n",
    "\n",
    "\n",
    "        print(f'{red} Avg score {CFG.n_feature_sel_folds}-fold: {res} {metric.__name__}: {red}{np.mean(cv_scores):.5f}{res}')\n",
    "        print(f'{\"*\" * 50}\\n')\n",
    "        \n",
    "        if permut:\n",
    "            perm_df_ = perm_df_.sort_values('importance', ascending=False)\n",
    "            \n",
    "        if boruta:\n",
    "            boruta_df_ = boruta_df_.sort_values('importance')\n",
    "                                        \n",
    "        feature_importances_ = feature_importances_.sort_values('Value', ascending=False)\n",
    "        \n",
    "        return perm_df_, feature_importances_, boruta_df_, np.mean(cv_scores)\n",
    "\n",
    "    if CFG.feature_sel:\n",
    "        perm_df_, feature_importances_, boruta_df_, cv_scores = lgbm_tuning(features, permut=True, boruta=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check features correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    col = 'DA'\n",
    "    x = train_df[train_df[col] <= train_df[col].quantile(0.99)]\n",
    "    cm = x[[c for c in train_df.columns if c not in ['Id', 'Class']]].corr()\n",
    "    display(np.abs(cm[col]).sort_values(ascending=False)[1:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.619184Z",
     "iopub.status.busy": "2023-06-08T15:32:11.618864Z",
     "iopub.status.idle": "2023-06-08T15:32:11.652915Z",
     "shell.execute_reply": "2023-06-08T15:32:11.652069Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.619157Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    perm_df_.to_csv('perm_df.csv')\n",
    "    perm_df_\n",
    "    perm_cols = set(perm_df_.index[-35:])\n",
    "    display(perm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pd.read_csv('perm_df.csv', index_col='Unnamed: 0')\n",
    "# x['feature'] = x.index.copy()\n",
    "# x = x.reset_index(drop=True)\n",
    "# x['rank'] = x['importance'].rank()\n",
    "# x = x[['feature', 'rank']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze tree gain feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.654626Z",
     "iopub.status.busy": "2023-06-08T15:32:11.654102Z",
     "iopub.status.idle": "2023-06-08T15:32:11.669674Z",
     "shell.execute_reply": "2023-06-08T15:32:11.668840Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.654583Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    feature_importances_.to_csv('feature_importances.csv')\n",
    "    feature_importances_\n",
    "    fi_cols = set(feature_importances_['Feature'].values[-23:])\n",
    "    display(fi_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = pd.read_csv('feature_importances.csv')\n",
    "# y['feature'] = y['Feature']\n",
    "# y = y.reset_index(drop=True)\n",
    "# y['rank'] = y['Value'].rank()\n",
    "# y = y[['feature', 'rank']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze BORUTA importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    boruta_df_.to_csv('boruta_df_.csv')\n",
    "    boruta_df_\n",
    "    boruta_cols = set(boruta_df_.index[-35:])\n",
    "    display(boruta_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = pd.read_csv('boruta_df_.csv', index_col='Unnamed: 0')\n",
    "# z['feature'] = z.index.copy()\n",
    "# z = z.reset_index(drop=True)\n",
    "# z['rank'] = z['importance'].rank(ascending=False)\n",
    "# z = z[['feature', 'rank']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort all features according to their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.concat([x, y, z])\n",
    "# a = a[['feature', 'rank']]\n",
    "# res = a.groupby('feature')['rank'].sum().sort_values(ascending=False)#.index.to_list()\n",
    "# res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "X, y = train_df[features], train_df['Class'] \n",
    "best_iterations = list()\n",
    "    \n",
    "def optimize_model(params, how, X, y):\n",
    "    bll_list = list()\n",
    "    best_trial_iterations = list()\n",
    "    \n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under- or oversampling to balance classes\n",
    "        if CFG.undersample:\n",
    "            positive_count_train = y.value_counts()[1]\n",
    "            sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train * class_imbalance, \n",
    "                                                            1: positive_count_train}, \n",
    "                                        random_state=15062023+i, \n",
    "                                        replacement=True)\n",
    "        elif CFG.oversample:\n",
    "            negative_count_train = y.value_counts()[0]\n",
    "            sampler = RandomOverSampler(sampling_strategy={0: negative_count_train, \n",
    "                                                        1: negative_count_train // class_imbalance}, \n",
    "                                        random_state=2306020231)\n",
    "\n",
    "\n",
    "        X_re, y_re = pd.concat([X, greeks.iloc[:,1:4]], axis=1), y\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified (Multilabel) k-Fold scheme\n",
    "        if CFG.k_fold:\n",
    "            kf = KFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=100720231+i)\n",
    "            y_fold = y_re\n",
    "        elif CFG.strat_k_fold:\n",
    "            kf = StratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=70720231+i)\n",
    "            y_fold = y_re\n",
    "        else:\n",
    "            kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=70720231+i)\n",
    "            y_fold = X_re.iloc[:,-3:]\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        # for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1):\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re, y=y_re)):\n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # oversample\n",
    "            if CFG.oversample:\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "            if how == 'lgbm':\n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=bll_metric, verbose=0)\n",
    "                best_iter = model.best_iteration_\n",
    "            elif how == 'xgboost':\n",
    "                model = xgb.XGBClassifier(**params)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "                best_iter = model.get_booster().best_iteration\n",
    "            elif how == 'catboost':\n",
    "                train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "                val_pool = Pool(X_val, y_val, cat_features=['EJ']) \n",
    "                model = cat.CatBoostClassifier(**params)\n",
    "                model.fit(train_pool, eval_set=val_pool, verbose=0)\n",
    "                best_iter = model.best_iteration_\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "            val_preds = model.predict_proba(X_val)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "        \n",
    "        bll_list.append(balanced_log_loss(y_re, oof))\n",
    "        best_trial_iterations.append(best_iter)\n",
    "    \n",
    "    best_iterations.append(int(np.mean(best_trial_iterations)))\n",
    "\n",
    "    res = np.mean(bll_list)\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        # Main parameters\n",
    "#                     'device': 'gpu',\n",
    "#                     'gpu_platform_id': 0,\n",
    "#                     'gpu_device_id': 0,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'none',\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['goss', 'gbdt']),#, 'dart']),   \n",
    "        # Hyperparamters (in order of importance decreasing)\n",
    "        'n_estimators': CFG.n_estimators, # trial.suggest_int('n_estimators', 500, 1500),  # max number of trees in model\n",
    "        'early_stopping_round': CFG.early_stopping_rounds, \n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 3e-1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True), # L1,  alias: lambda_l1\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True), # L2, alias: lambda_l2\n",
    "         # decrease to deal with overfit\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),   # tree max depth \n",
    "         # decrease to deal with overfit\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 128),  # Max number of leaves in one tree\n",
    "                                                                # should be ~ 2**(max_depth-1)\n",
    "        'subsample': None, # Randomly select part of data without \n",
    "                                  # resampling if subsample < 1.0\n",
    "                                  # alias: bagging_fraction\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.7), # Randomly select a subset of features \n",
    "                                                                   # if colsample_bytree < 1.0\n",
    "                                                                   # alias:feature_fraction\n",
    "        # decrease to deal with overfit\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                             # aliases: min_data_in_leaf, \n",
    "        # increase for accuracy, decrease to deal with overfit\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255), # Max number of bins that feature values will be bucketed in\n",
    "        # increase to deal with overfit\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 1, 7), # Perform bagging at every k iteration, alias: bagging_freq\n",
    "\n",
    "#           'subsample_for_bin': 200000, # Number of data that sampled to construct feature discrete bins; setting this \n",
    "                                     # to larger value will give better training result but may increase train time \n",
    "#           'cat_smooth': trial.suggest_float('cat_smooth', 10.0, 100.0),  # this can reduce the effect of noises in \n",
    "                                                                       # categorical features, especially for \n",
    "                                                                       # categories with few data\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        params['is_unbalance'] = True\n",
    "        params['class_weight'] = 'balanced'\n",
    "    else:\n",
    "        params['scale_pos_weight'] = class_imbalance\n",
    "    \n",
    "    if params['boosting_type'] != 'goss':\n",
    "        params['subsample'] = trial.suggest_float('subsample', 0.3, 0.7)\n",
    "    \n",
    "    return optimize_model(params, how='lgbm', X=train_df[features], y=train_df['Class'])\n",
    "            \n",
    "\n",
    "if CFG.lgbm_optimize:\n",
    "#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective_lgbm, n_trials=CFG.n_trials * 2) \n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe()\n",
    "    df['params_n_estimators'] = best_iterations\n",
    "    df = df.sort_values('value')\n",
    "    df.to_csv(f'optuna_lgbm.csv')\n",
    "\n",
    "    display(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LGBM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def load_lgbm_parameters(filename):\n",
    "    param_list = glob.glob(filename)\n",
    "\n",
    "    models = list()\n",
    "    best_lgbm_params = list()\n",
    "\n",
    "    lgbm_params = pd.DataFrame()\n",
    "\n",
    "    for f in param_list:\n",
    "        tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "        if lgbm_params.shape[0] == 0:\n",
    "            lgbm_params = tmp\n",
    "        else:\n",
    "            lgbm_params = pd.concat([lgbm_params, tmp])\n",
    "            \n",
    "    lgbm_params = lgbm_params.sort_values('value').head(CFG.n_stacking_models_lgbm)\n",
    "    param_cols = [c for c in lgbm_params.columns if c.startswith('params_')]\n",
    "    lgbm_params = lgbm_params[param_cols]\n",
    "\n",
    "    for idx, row in lgbm_params.iterrows():\n",
    "        row_dict = {k[7:]: v for k, v in row.items()}\n",
    "        row_dict['objective'] = 'binary'\n",
    "        row_dict['metric'] = 'none'\n",
    "    #     row_dict['subsample_for_bin'] = 300000\n",
    "        row_dict['force_col_wise'] = False\n",
    "        row_dict['verbose'] = -1\n",
    "        # row_dict['max_bin'] = 255\n",
    "        \n",
    "        if CFG.n_stacking_folds > 0:\n",
    "            row_dict['n_estimators'] = CFG.n_estimators\n",
    "            row_dict['early_stopping_round'] = CFG.early_stopping_rounds\n",
    "        else:\n",
    "            row_dict['n_estimators'] = int(row_dict['n_estimators'])\n",
    "        row_dict['num_leaves'] = int(row_dict['num_leaves'])\n",
    "        row_dict['max_depth'] = int(row_dict['max_depth'])\n",
    "        row_dict['min_child_samples'] = int(row_dict['min_child_samples'])\n",
    "        row_dict['subsample_freq'] = int(row_dict['subsample_freq'])\n",
    "        row_dict['learning_rate'] = float(row_dict['learning_rate'])\n",
    "        row_dict['max_bin'] = int(row_dict['max_bin'])\n",
    "        \n",
    "        if not CFG.oversample and not CFG.undersample:\n",
    "            row_dict['is_unbalance'] = True\n",
    "            row_dict['class_weight'] = 'balanced'\n",
    "        else:\n",
    "            row_dict['scale_pos_weight'] = class_imbalance\n",
    "        \n",
    "        if row_dict['boosting_type'] == 'goss':\n",
    "            row_dict['subsample'] = None\n",
    "            \n",
    "        best_lgbm_params.append(row_dict)\n",
    "    return best_lgbm_params\n",
    "\n",
    "best_lgbm_params = load_lgbm_parameters(\"optuna_lgbm.csv\")\n",
    "\n",
    "if CFG.test:\n",
    "    best_lgbm_params = [{\n",
    "            'boosting_type': 'goss',\n",
    "            'n_estimators': 50000,\n",
    "            'early_stopping_round': 300,\n",
    "            'max_depth': 8,\n",
    "            'learning_rate': 0.06733232950390658,\n",
    "            'subsample': 0.6970532011679706,\n",
    "            'colsample_bytree': 0.6055755840633003,\n",
    "            'is_unbalance': True, \n",
    "            'class_weight': 'balanced',\n",
    "            'metric':'none',\n",
    "            'verbose': -1,\n",
    "            'random_state': 42,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "                         "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = train_df[features], train_df['Class']\n",
    "best_iterations = list()\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    bll_list = list()\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": CFG.n_estimators, # trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        \"early_stopping_rounds\": CFG.early_stopping_rounds,\n",
    "        \"verbosity\": 0,\n",
    "        \"random_state\": 14062023,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        # use exact for small dataset.\n",
    "        \"tree_method\": \"exact\",\n",
    "        # defines booster, gblinear for linear functions.\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),# \"dart\", \"gblinear\"]), \n",
    "        # L1 regularization weight.\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        # L2 regularization weight.\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        # sampling ratio for training data.\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "        # sampling according to each tree.\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "    }\n",
    "\n",
    "    # if not CFG.oversample and not CFG.undersample:\n",
    "    params[\"scale_pos_weight\"] = train_df[train_df['Class'] == 0].shape[0] / train_df[train_df['Class'] == 1].shape[0]\n",
    "    \n",
    "    if params[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        params[\"learning_rate\"] = trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True) # alias eta\n",
    "        # maximum depth of the tree, signifies complexity of the tree.\n",
    "        params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "        # minimum child weight, larger the term more conservative the tree.\n",
    "        params[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "        # defines how selective algorithm is.\n",
    "        params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "    if params[\"booster\"] == \"dart\":\n",
    "        params[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        params[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        params[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        params[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "\n",
    "    return optimize_model(params, how='xgboost')\n",
    "\n",
    "if CFG.xgb_optimize:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective_xgb, n_trials=CFG.n_trials * 2)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df['params_n_estimators'] = best_iterations\n",
    "    df.to_csv(f'optuna_xgb.csv')\n",
    "\n",
    "    display(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load XGBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if CFG.kaggle:\n",
    "    param_list = glob.glob(\"/kaggle/input/icr-optuna-no-da/optuna_xgb.csv\")\n",
    "else:\n",
    "    param_list = glob.glob(\"optuna_xgb.csv\")\n",
    "\n",
    "models = list()\n",
    "best_xgb_params = list()\n",
    "\n",
    "xgb_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if xgb_params.shape[0] == 0:\n",
    "        xgb_params = tmp\n",
    "    else:\n",
    "        xgb_params = pd.concat([xgb_params, tmp])\n",
    "        \n",
    "xgb_params = xgb_params.sort_values('value').head(CFG.n_stacking_models_xgb)\n",
    "param_cols = [c for c in xgb_params.columns if c.startswith('params_')]\n",
    "xgb_params = xgb_params[param_cols]\n",
    "\n",
    "for idx, row in xgb_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['n_estimators'] = CFG.n_estimators\n",
    "    row_dict['early_stopping_rounds'] = CFG.early_stopping_rounds\n",
    "    row_dict['random_state'] = 14062023\n",
    "    row_dict['verbosity'] = 0\n",
    "    row_dict['objective'] = \"binary:logistic\"\n",
    "    row_dict['eval_metric'] = \"logloss\"\n",
    "    row_dict['tree_method'] = \"exact\"\n",
    "    row_dict['booster'] = \"gbtree\"\n",
    "\n",
    "    # if not CFG.oversample and not CFG.undersample:\n",
    "    row_dict['scale_pos_weight'] = class_imbalance\n",
    "\n",
    "    if row_dict[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        row_dict[\"max_depth\"] = int(row_dict[\"max_depth\"])\n",
    "        row_dict[\"min_child_weight\"] = int(row_dict[\"min_child_weight\"])\n",
    "    else:\n",
    "        row_dict[\"learning_rate\"] = None\n",
    "        row_dict[\"max_depth\"] = None\n",
    "        row_dict[\"min_child_weight\"] = None\n",
    "        row_dict[\"gamma\"] = None\n",
    "        row_dict[\"grow_policy\"] = None     \n",
    "\n",
    "    if row_dict[\"booster\"] != \"dart\":\n",
    "        row_dict[\"sample_type\"] = None\n",
    "        row_dict[\"normalize_type\"] = None\n",
    "        row_dict[\"rate_drop\"] = None\n",
    "        row_dict[\"skip_drop\"] = None\n",
    "\n",
    "    best_xgb_params.append(row_dict)\n",
    "\n",
    "if CFG.test:\n",
    "    best_xgb_params = [{\n",
    "            'n_estimators': CFG.n_estimators,\n",
    "            'early_stopping_rounds': CFG.early_stopping_rounds,\n",
    "            'objective': \"binary:logistic\",\n",
    "            'scale_pos_weight': class_imbalance, \n",
    "            'verbosity': 0,\n",
    "            'random_state': 19062023,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = train_df[features], train_df['Class']\n",
    "best_iterations = list()\n",
    "\n",
    "def objective_cb(trial):\n",
    "    \n",
    "    bll_list = list()\n",
    "\n",
    "    # Parameters\n",
    "    params = {\n",
    "        'task_type': 'CPU', # GPU\n",
    "        # 'devices':'0:1',\n",
    "        'eval_metric': 'Logloss',\n",
    "        'loss_function': 'Logloss', \n",
    "        'random_seed': 19062023,\n",
    "        'od_type': 'Iter', # Type of overfitting detector - stop after k iteraions\n",
    "        'iterations' : CFG.n_estimators * 2, # trial.suggest_int('iterations', 300, 1200),        \n",
    "        'od_wait': CFG.early_stopping_rounds, # Overfitting detector - stop training after k iterations without metric improvement\n",
    "        # 'metric_period': 100, # Show metric each k iterations\n",
    "        # Hyperparamters (in order of importance decreasing)\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS', 'No']),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-3, 3e-1), \n",
    "        'l2_leaf_reg': trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
    "        'depth' : trial.suggest_int('depth', 4, 10),  # Max tree depth                                          \n",
    "         # increase to deal with overfit\n",
    "        'random_strength': trial.suggest_float('random_strength', 0, 100), # The amount of randomness to use\n",
    "                                                                           # for scoring splits when the tree structure\n",
    "                                                                           # is selected. Helps to avoid overfitting\n",
    "                                                                           # CPU only\n",
    "        # per_float_feature_quantization='0:border_count=1024'\n",
    "        'border_count': 254, # trial.suggest_categorical('border_count', [128, 254]), # The number of splits for numerical features\n",
    "                                                                                      # bigger is better but slowly\n",
    "                                                                                      # alias: max_bin\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                           # aliases: min_child_samples\n",
    "    }\n",
    "\n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        params['auto_class_weights'] = 'Balanced'\n",
    "    else:\n",
    "        params['scale_pos_weight'] = class_imbalance\n",
    "        \n",
    "        \n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 100) # Assigns random \n",
    "                                                                                           # weights to objects\n",
    "                                                                                           # works only with \n",
    "                                                                                           # Bayesian bootstrap\n",
    "    if params[\"bootstrap_type\"] in [\"Poisson\", \"Bernoulli\", \"MVS\"]:\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.3, 1) # Percentage of objects to use \n",
    "                                                                        # at each split\n",
    "\n",
    "    if params['task_type'] == 'CPU' and params['bootstrap_type'] != 'Bayesian':\n",
    "        params[\"colsample_bylevel\"] = trial.suggest_float(\"colsample_bylevel\", 0.3, 1)  # Percentage of features to use \n",
    "                                                                                        # at each split;\n",
    "                                                                                        # with Bayesian bootstrap and Lossguide grop policy\n",
    "                                                                                        # leads to error (CatBoost bug)\n",
    "    else:\n",
    "        params[\"colsample_bylevel\"] = None                                                     \n",
    "\n",
    "    if params['grow_policy'] == 'Lossguide': \n",
    "        params['max_leaves'] = trial.suggest_int('max_leaves', 4, 128) # Max number of leaves in one tree \n",
    "                                                                       # decrease to deal with the overfit\n",
    "\n",
    "    if params['grow_policy'] == 'SymmetricTree': \n",
    "        params['boosting_type'] = trial.suggest_categorical('boosting_type', ['Ordered', 'Plain'])\n",
    "    else:\n",
    "        params['boosting_type'] = 'Plain'\n",
    "    \n",
    "    return optimize_model(params, how='catboost')\n",
    "\n",
    "if CFG.cb_optimize:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective_cb, n_trials=CFG.n_trials * 2)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df['params_n_estimators'] = best_iterations\n",
    "    df.to_csv(f'optuna_catboost.csv')\n",
    "\n",
    "    display(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CatBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if CFG.kaggle:\n",
    "    param_list = glob.glob(\"/kaggle/input/icr-optuna-no-da/optuna_catboost.csv\")\n",
    "else:\n",
    "    param_list = glob.glob(\"optuna_del_outliers_adj_strat_k_fold/optuna_catboost.csv\")\n",
    "\n",
    "models = list()\n",
    "best_cb_params = list()\n",
    "\n",
    "cb_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if cb_params.shape[0] == 0:\n",
    "        cb_params = tmp\n",
    "    else:\n",
    "        cb_params = pd.concat([cb_params, tmp])\n",
    "        \n",
    "cb_params = cb_params.sort_values('value').head(CFG.n_stacking_models_cb)\n",
    "param_cols = [c for c in cb_params.columns if c.startswith('params_')]\n",
    "cb_params = cb_params[param_cols]\n",
    "\n",
    "\n",
    "for idx, row in cb_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['task_type'] = 'CPU'\n",
    "    row_dict['eval_metric'] = 'Logloss'\n",
    "    row_dict['loss_function'] = 'Logloss'\n",
    "    row_dict['random_seed'] = 13062023\n",
    "    row_dict['verbose'] = 0\n",
    "    row_dict['od_type'] = 'Iter'\n",
    "    row_dict['n_estimators'] = CFG.n_estimators * 2\n",
    "    row_dict['od_wait'] = CFG.early_stopping_rounds\n",
    "    row_dict['border_count'] = 254\n",
    "    \n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        row_dict['auto_class_weights'] = 'Balanced'\n",
    "    else:\n",
    "        row_dict['scale_pos_weight'] = class_imbalance\n",
    "        \n",
    "    if row_dict[\"task_type\"] != \"GPU\":\n",
    "        row_dict['colsample_bylevel'] = None\n",
    "    \n",
    "    if row_dict[\"bootstrap_type\"] != \"Bayesian\":\n",
    "        row_dict['bagging_temperature'] = None\n",
    "        \n",
    "    if row_dict[\"bootstrap_type\"] not in [\"Poisson\", \"Bernoulli\", \"MVS\"]:\n",
    "        row_dict['subsample'] = None\n",
    "    \n",
    "    if row_dict['grow_policy'] == 'Lossguide':\n",
    "        row_dict['max_leaves'] = int(row_dict['max_leaves'])\n",
    "    else:\n",
    "        row_dict['max_leaves'] = None\n",
    "    \n",
    "    if row_dict['grow_policy'] != 'SymmetricTree':\n",
    "        row_dict['boosting_type'] = 'Plain'\n",
    "    \n",
    "    best_cb_params.append(row_dict)\n",
    "\n",
    "if CFG.test:\n",
    "    best_cb_params = [{\n",
    "            'iterations': CFG.n_estimators,\n",
    "            'od_type': 'Iter',\n",
    "            'od_wait': CFG.early_stopping_rounds,\n",
    "            'eval_metric': \"Logloss\",\n",
    "            'loss_function': \"Logloss\",\n",
    "            'auto_class_weights': 'Balanced', \n",
    "            'verbose': 0,\n",
    "            'random_seed': 19062023,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96269b26a078414fb1965b336ce31dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with \u001b[1m\u001b[34m41\u001b[0m features\n",
      "Fold: \u001b[1m\u001b[34m  0\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10173\u001b[0m | Best iteration: \u001b[1m\u001b[34m  84\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14204\u001b[0m | Best iteration: \u001b[1m\u001b[34m  60\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12708\u001b[0m | Best iteration: \u001b[1m\u001b[34m 156\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12751\u001b[0m | Best iteration: \u001b[1m\u001b[34m  70\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26466\u001b[0m | Best iteration: \u001b[1m\u001b[34m 236\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.00345\u001b[0m | Best iteration: \u001b[1m\u001b[34m 343\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.30045\u001b[0m | Best iteration: \u001b[1m\u001b[34m  42\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17813\u001b[0m | Best iteration: \u001b[1m\u001b[34m 179\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14682\u001b[0m | Best iteration: \u001b[1m\u001b[34m  72\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42159\u001b[0m | Best iteration: \u001b[1m\u001b[34m  32\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13395\u001b[0m | Best iteration: \u001b[1m\u001b[34m  74\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 11\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.04341\u001b[0m | Best iteration: \u001b[1m\u001b[34m 342\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 12\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09725\u001b[0m | Best iteration: \u001b[1m\u001b[34m 655\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 13\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.04134\u001b[0m | Best iteration: \u001b[1m\u001b[34m 415\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 14\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07119\u001b[0m | Best iteration: \u001b[1m\u001b[34m 200\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m41\u001b[0m features\n",
      "Fold: \u001b[1m\u001b[34m  0\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13080\u001b[0m | Best iteration: \u001b[1m\u001b[34m  47\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20302\u001b[0m | Best iteration: \u001b[1m\u001b[34m  49\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14908\u001b[0m | Best iteration: \u001b[1m\u001b[34m 228\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08497\u001b[0m | Best iteration: \u001b[1m\u001b[34m  87\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26299\u001b[0m | Best iteration: \u001b[1m\u001b[34m 131\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.05893\u001b[0m | Best iteration: \u001b[1m\u001b[34m 152\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33187\u001b[0m | Best iteration: \u001b[1m\u001b[34m  22\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16892\u001b[0m | Best iteration: \u001b[1m\u001b[34m 245\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10051\u001b[0m | Best iteration: \u001b[1m\u001b[34m  68\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42211\u001b[0m | Best iteration: \u001b[1m\u001b[34m  41\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21443\u001b[0m | Best iteration: \u001b[1m\u001b[34m  61\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 11\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09207\u001b[0m | Best iteration: \u001b[1m\u001b[34m 306\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 12\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09849\u001b[0m | Best iteration: \u001b[1m\u001b[34m 510\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 13\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06722\u001b[0m | Best iteration: \u001b[1m\u001b[34m1322\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 14\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15097\u001b[0m | Best iteration: \u001b[1m\u001b[34m 278\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m41\u001b[0m features\n",
      "Fold: \u001b[1m\u001b[34m  0\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12899\u001b[0m | Best iteration: \u001b[1m\u001b[34m 209\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10637\u001b[0m | Best iteration: \u001b[1m\u001b[34m  84\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11041\u001b[0m | Best iteration: \u001b[1m\u001b[34m 208\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07823\u001b[0m | Best iteration: \u001b[1m\u001b[34m 195\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28309\u001b[0m | Best iteration: \u001b[1m\u001b[34m 131\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.00570\u001b[0m | Best iteration: \u001b[1m\u001b[34m 493\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.31529\u001b[0m | Best iteration: \u001b[1m\u001b[34m 146\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21813\u001b[0m | Best iteration: \u001b[1m\u001b[34m 250\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10843\u001b[0m | Best iteration: \u001b[1m\u001b[34m 186\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.36607\u001b[0m | Best iteration: \u001b[1m\u001b[34m  77\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19519\u001b[0m | Best iteration: \u001b[1m\u001b[34m 119\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 11\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.05781\u001b[0m | Best iteration: \u001b[1m\u001b[34m 566\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 12\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09920\u001b[0m | Best iteration: \u001b[1m\u001b[34m 431\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 13\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06358\u001b[0m | Best iteration: \u001b[1m\u001b[34m 420\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 14\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09921\u001b[0m | Best iteration: \u001b[1m\u001b[34m 429\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m41\u001b[0m features\n",
      "Fold: \u001b[1m\u001b[34m  0\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12476\u001b[0m | Best iteration: \u001b[1m\u001b[34m 308\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15484\u001b[0m | Best iteration: \u001b[1m\u001b[34m 216\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12693\u001b[0m | Best iteration: \u001b[1m\u001b[34m 266\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08887\u001b[0m | Best iteration: \u001b[1m\u001b[34m 310\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26127\u001b[0m | Best iteration: \u001b[1m\u001b[34m 231\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.01045\u001b[0m | Best iteration: \u001b[1m\u001b[34m 572\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.32799\u001b[0m | Best iteration: \u001b[1m\u001b[34m 150\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17497\u001b[0m | Best iteration: \u001b[1m\u001b[34m 340\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18104\u001b[0m | Best iteration: \u001b[1m\u001b[34m 111\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.37007\u001b[0m | Best iteration: \u001b[1m\u001b[34m 124\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23374\u001b[0m | Best iteration: \u001b[1m\u001b[34m 188\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 11\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.03832\u001b[0m | Best iteration: \u001b[1m\u001b[34m 894\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 12\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12737\u001b[0m | Best iteration: \u001b[1m\u001b[34m 578\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 13\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.02627\u001b[0m | Best iteration: \u001b[1m\u001b[34m2041\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 14\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13625\u001b[0m | Best iteration: \u001b[1m\u001b[34m 360\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m41\u001b[0m features\n",
      "Fold: \u001b[1m\u001b[34m  0\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14320\u001b[0m | Best iteration: \u001b[1m\u001b[34m 133\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16798\u001b[0m | Best iteration: \u001b[1m\u001b[34m  98\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10604\u001b[0m | Best iteration: \u001b[1m\u001b[34m 308\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06169\u001b[0m | Best iteration: \u001b[1m\u001b[34m 246\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25272\u001b[0m | Best iteration: \u001b[1m\u001b[34m 284\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.00203\u001b[0m | Best iteration: \u001b[1m\u001b[34m 600\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28877\u001b[0m | Best iteration: \u001b[1m\u001b[34m 118\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18014\u001b[0m | Best iteration: \u001b[1m\u001b[34m 315\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13357\u001b[0m | Best iteration: \u001b[1m\u001b[34m 105\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39675\u001b[0m | Best iteration: \u001b[1m\u001b[34m 109\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18700\u001b[0m | Best iteration: \u001b[1m\u001b[34m  95\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 11\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.02239\u001b[0m | Best iteration: \u001b[1m\u001b[34m 613\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 12\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12361\u001b[0m | Best iteration: \u001b[1m\u001b[34m 539\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 13\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07209\u001b[0m | Best iteration: \u001b[1m\u001b[34m 836\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 14\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.05380\u001b[0m | Best iteration: \u001b[1m\u001b[34m 592\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    N_inv_0 = 1/N_0 if N_0 > 0 else 0\n",
    "    N_inv_1 = 1/N_1 if N_1 > 0 else 0\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability 𝑝 is replaced with max(min(𝑝,1−10−15),10−15)\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - N_inv_0 * np.sum((1 - y_true) * np.log(1 - y_pred)) - N_inv_1 * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2\n",
    "\n",
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def pp_prob(p):\n",
    "    c0 = p[:,0].sum()\n",
    "    c1 = p[:,1:].sum()\n",
    "    new_p = p * np.array([[1/(c0 if i==0 else c1) for i in range(p.shape[1])]])\n",
    "    new_p = new_p / np.sum(new_p,axis=1,keepdims=1)\n",
    "    return np.sum(new_p[:,1:],1,keepdims=False)\n",
    "\n",
    "def model_train(how, best_params, X, y, test):\n",
    "    oof_level2 = np.zeros([y.shape[0], len(best_params) + 1])\n",
    "    oof_level2[:, len(best_params)] = y\n",
    "    oof_level2_test = np.zeros([test_df.shape[0], len(best_params)])\n",
    "    oof_val = np.zeros([CFG.n_stacking_folds, len(best_params)])\n",
    "    \n",
    "    for i, params in tqdm(enumerate(best_params), total=len(best_params)):\n",
    "        model_dict = dict()\n",
    "    \n",
    "        if CFG.n_stacking_folds > 0:\n",
    "            if CFG.k_fold:\n",
    "                kf = KFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=3082023)\n",
    "                y_fold = y\n",
    "            elif CFG.strat_k_fold:\n",
    "                kf = StratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=3082023)\n",
    "                y_fold = y\n",
    "            else:\n",
    "                kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=3082023)\n",
    "                y_fold = greeks.iloc[:,1:4]\n",
    "            \n",
    "            print(f\"Training with {blu}{len(features)}{res} features\")\n",
    "\n",
    "            best_val = np.inf\n",
    "            \n",
    "            for fold, (fit_idx, val_idx) in enumerate(kf.split(X=X, y=y_fold)):\n",
    "                \n",
    "                # Split the dataset according to the fold indexes.\n",
    "                X_train = X.iloc[fit_idx]\n",
    "                X_val = X.iloc[val_idx]\n",
    "                y_train = y.iloc[fit_idx]\n",
    "                y_val = y.iloc[val_idx]\n",
    "\n",
    "                # Make random under- or oversampling to balance classes\n",
    "                if CFG.undersample or CFG.oversample:\n",
    "                    if CFG.undersample:\n",
    "                        positive_count_train = y_train.value_counts()[1]\n",
    "                        sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train * class_imbalance, \n",
    "                                                                        1: positive_count_train}, \n",
    "                                                    random_state=3082023, \n",
    "                                                    replacement=True)\n",
    "                    elif CFG.oversample:\n",
    "                        negative_count_train = y_train.value_counts()[0]\n",
    "                        sampler = RandomOverSampler(sampling_strategy={0: negative_count_train, \n",
    "                                                                    1: negative_count_train // class_imbalance}, \n",
    "                                                    random_state=3082023)\n",
    "\n",
    "                    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "                \n",
    "                if how == 'lgbm':\n",
    "                    model = lgb.LGBMClassifier(**params)\n",
    "                    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=bll_metric, verbose=0)\n",
    "                    best_iter = model.best_iteration_\n",
    "                elif how == 'xgboost':\n",
    "                    model = xgb.XGBClassifier(**params)\n",
    "                    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "                    best_iter = model.get_booster().best_iteration\n",
    "                elif how == 'catboost':\n",
    "                    train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "                    val_pool = Pool(X_val, y_val, cat_features=['EJ'])   \n",
    "                    model = cat.CatBoostClassifier(**params)\n",
    "                    model.fit(train_pool, eval_set=val_pool, verbose=0)\n",
    "                    best_iter = model.best_iteration_\n",
    "                elif how == 'tabpfn':\n",
    "                    model = TabPFNClassifier(N_ensemble_configurations=64, device='cuda:0')\n",
    "                    model.fit(X_train, y_train, overwrite_warning=True)\n",
    "                    best_iter = 0\n",
    "                elif how == 'logreg':\n",
    "                    model = LogisticRegression(random_state=2306020231+i, C=0.1, n_jobs=-1, max_iter=2000, class_weight='balanced')\n",
    "                    model.fit(X_train, y_train)\n",
    "                    best_iter = 0\n",
    "                else:\n",
    "                    return None, None, None\n",
    "                    \n",
    "                try:\n",
    "                    if how == 'tabpfn':\n",
    "                        val_preds = pp_prob(model.predict_proba(X_val))\n",
    "                        val_score = balanced_log_loss(y_val, val_preds)\n",
    "                        pp = pp_prob(model.predict_proba(test))\n",
    "                    else:\n",
    "                        val_preds = model.predict_proba(X_val)[:,1]\n",
    "                        val_score = balanced_log_loss(y_val, val_preds)\n",
    "                        pp = model.predict_proba(test)[:,1]\n",
    "                except:\n",
    "                    val_score = 100\n",
    "                    pp = np.zeros(test.shape[0])\n",
    "\n",
    "                model_dict[val_score] = pp\n",
    "                \n",
    "                oof_level2[val_idx, i] = val_preds\n",
    "                oof_val[fold, i] = val_score\n",
    "                \n",
    "                print(f'Fold: {blu}{fold:>3}{res}| bll_metric: {blu}{val_score:.5f}{res}'\n",
    "                      f' | Best iteration: {blu}{best_iter:>4}{res}')  \n",
    "            \n",
    "            model_dict = sorted(model_dict.items(), key=lambda x: x[0])\n",
    "            \n",
    "            n_stacking_folds = CFG.n_stacking_folds\n",
    "            \n",
    "            for j, _pp in enumerate(model_dict):\n",
    "                # if j >= CFG.n_stacking_folds_min or _pp[0] >= 0.1:\n",
    "                if _pp[0] >= 0.1:\n",
    "                    oof_level2_test[:, i] += _pp[1]\n",
    "                else:\n",
    "                    n_stacking_folds -= 1\n",
    "            oof_level2_test[:, i] = oof_level2_test[:, i] / max(1, n_stacking_folds)\n",
    "        else:\n",
    "            if how == 'lgbm':\n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "                model.fit(X, y, verbose=0)\n",
    "            elif how == 'xgboost':\n",
    "                model = xgb.XGBClassifier(**params)\n",
    "                model.fit(X, y, verbose=0)\n",
    "            elif how == 'catboost':\n",
    "                train_pool = Pool(X, y, cat_features=['EJ'])\n",
    "                model = cat.CatBoostClassifier(**params)\n",
    "                model.fit(train_pool, verbose=0)\n",
    "            elif how == 'tabpfn':\n",
    "                model = TabPFNClassifier(N_ensemble_configurations=64, device='cuda:0')\n",
    "                model.fit(X, y, overwrite_warning=True)\n",
    "            elif how == 'logreg':\n",
    "                model = LogisticRegression(random_state=2306020231+i, C=0.1, n_jobs=-1, max_iter=2000, class_weight='balanced')\n",
    "                model.fit(X, y)\n",
    "            else:\n",
    "                return None, None, None\n",
    "    \n",
    "    return oof_level2, oof_level2_test, oof_val\n",
    "\n",
    "oof_train_list = list()\n",
    "oof_test_list = list()\n",
    "oof_val_list = list()\n",
    "\n",
    "if CFG.lgbm_train:\n",
    "    oof_level2_lgbm, oof_level2_test_lgbm, oof_val_lgbm = model_train('lgbm', best_lgbm_params, train_df[features], train_df['Class'], test_df[features])\n",
    "    oof_train_list.append(oof_level2_lgbm[:,:-1])\n",
    "    oof_test_list.append(oof_level2_test_lgbm)\n",
    "    oof_val_list.append(oof_val_lgbm)\n",
    "    y = oof_level2_lgbm[:,-1]\n",
    "\n",
    "# if CFG.xgb_train:\n",
    "#     oof_level2_xgb, oof_level2_test_xgb, oof_val_xgb = model_train('xgboost', best_xgb_params, train_df[features], train_df['Class'], test_df[features])\n",
    "#     oof_train_list.append(oof_level2_xgb[:,:-1])\n",
    "#     oof_test_list.append(oof_level2_test_xgb)\n",
    "#     oof_val_list.append(oof_val_xgb)\n",
    "#     y = oof_level2_xgb[:,-1]\n",
    "\n",
    "# if CFG.cb_train:\n",
    "#     oof_level2_cb, oof_level2_test_cb, oof_val_cb = model_train('catboost', best_cb_params, train_df[features], train_df['Class'], test_df[features])\n",
    "#     oof_train_list.append(oof_level2_cb[:,:-1])\n",
    "#     oof_test_list.append(oof_level2_test_cb)\n",
    "#     oof_val_list.append(oof_val_cb)\n",
    "#     y = oof_level2_cb[:,-1]\n",
    "\n",
    "if CFG.tabpfn_train:\n",
    "    oof_level2_tabpfn, oof_level2_test_tabpfn, oof_val_tabpfn = model_train('tabpfn', [i for i in range(CFG.n_stacking_models_tabpfn)], \n",
    "                                                                             train_df[features], train_df['Class'], test_df[features])\n",
    "    oof_train_list.append(oof_level2_tabpfn[:,:-1])\n",
    "    oof_test_list.append(oof_level2_test_tabpfn)\n",
    "    oof_val_list.append(oof_val_tabpfn)\n",
    "    y = oof_level2_tabpfn[:,-1]\n",
    "\n",
    "# if CFG.logreg_train:\n",
    "#     oof_level2_logreg, oof_level2_test_logreg, oof_val_logreg = model_train('logreg', [i for i in range (10)])\n",
    "#     oof_train_list.append(oof_level2_logreg[:,:-1])\n",
    "#     oof_test_list.append(oof_level2_test_logreg)\n",
    "#     oof_val_list.append(oof_val_logreg)\n",
    "#     y = oof_level2_logreg[:,-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending and Stacking with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1451437619126687\n",
      "0.14329042526256158\n"
     ]
    }
   ],
   "source": [
    "oof_level2_LGBM = np.concatenate(oof_train_list, axis=1)\n",
    "oof_level2_LGBM_test = np.concatenate(oof_test_list, axis=1)\n",
    "# oof_level2_val = np.concatenate(oof_val_list, axis=1).reshape(-1, )\n",
    "\n",
    "X = oof_level2_LGBM\n",
    "\n",
    "# mean bll\n",
    "print(balanced_log_loss(y, np.mean(X, axis=1)))\n",
    "\n",
    "# lr bll\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "lr.fit(X, y)\n",
    "\n",
    "pred = lr.predict_proba(X)[:,1]\n",
    "weights = lr.coef_[0]\n",
    "print(balanced_log_loss(y, (weights * X).sum(axis=1) / sum(weights)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Optuna to calculate model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14000400528634557"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([7.60415780e-01, 7.51312485e-05, 5.24694868e-01, 5.03135749e-07,\n",
       "       6.80348675e-01])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "class OptunaWeights:\n",
    "    def __init__(self, random_state, n_trials=2000):\n",
    "        self.study = None\n",
    "        self.weights = None\n",
    "        self.random_state = random_state\n",
    "        self.n_trials = n_trials\n",
    "\n",
    "    def _objective(self, trial, y_true, y_preds):\n",
    "        # Define the weights for the predictions from each model\n",
    "        weights = [trial.suggest_float(f\"weight{n}\", 1e-13, 1) for n in range(len(y_preds))]\n",
    "\n",
    "        # Calculate the weighted prediction\n",
    "        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=weights)\n",
    "\n",
    "        # Calculate the score for the weighted prediction\n",
    "        # score = log_loss(y_true, weighted_pred)\n",
    "        score = balanced_log_loss(y_true, weighted_pred)\n",
    "        return score\n",
    "\n",
    "    def fit(self, y_true, y_preds):\n",
    "        optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "        sampler = optuna.samplers.CmaEsSampler(seed=self.random_state)\n",
    "        pruner = optuna.pruners.HyperbandPruner()\n",
    "        self.study = optuna.create_study(sampler=sampler, pruner=pruner, study_name=\"OptunaWeights\", direction='minimize')\n",
    "        objective_partial = partial(self._objective, y_true=y_true, y_preds=y_preds)\n",
    "        self.study.optimize(objective_partial, n_trials=self.n_trials)\n",
    "        self.weights = [self.study.best_params[f\"weight{n}\"] for n in range(len(y_preds))]\n",
    "\n",
    "    def predict(self, y_preds):\n",
    "        assert self.weights is not None, 'OptunaWeights error, must be fitted before predict'\n",
    "        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=self.weights)\n",
    "        return weighted_pred\n",
    "\n",
    "    def fit_predict(self, y_true, y_preds):\n",
    "        self.fit(y_true, y_preds)\n",
    "        return self.predict(y_preds)\n",
    "    \n",
    "    def weights(self):\n",
    "        return self.weights\n",
    "\n",
    "# Use Optuna to find the best ensemble weights\n",
    "optweights = OptunaWeights(random_state=19072023)\n",
    "y_val_pred = optweights.fit_predict(y, [oof_level2_LGBM[:,i] for i in range(oof_level2_LGBM.shape[1])])\n",
    "optuna_weights_LGBM = np.array(optweights.weights)\n",
    "\n",
    "display(balanced_log_loss(y, y_val_pred))\n",
    "display(optuna_weights_LGBM)\n",
    "\n",
    "oof_level2_LGBM = (optuna_weights_LGBM * oof_level2_LGBM).sum(axis=1) / sum(optuna_weights_LGBM)\n",
    "oof_level2_LGBM_test = (optuna_weights_LGBM * oof_level2_LGBM_test).sum(axis=1) / sum(optuna_weights_LGBM)\n",
    "\n",
    "# oof_level2_LGBM = oof_level2_LGBM.mean(axis=1)\n",
    "# oof_level2_LGBM_test = oof_level2_LGBM_test.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.16073210294764578"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which objects are the most erroneus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[292, 102, 509, 337, 514, 313, 556]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.mean(X, axis=1)\n",
    "errors = pd.Series(np.abs(y - preds))\n",
    "errors = errors.sort_values(ascending=False) \n",
    "errors[errors >= errors.quantile(0.99)].index.to_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best class threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_prob3(_oof, _p, num=1.5):\n",
    "    # increase (num > 1) or decrease (num < 1) binary prediction value\n",
    "    oof = num * _oof / ((num - 1) * _oof + 1)\n",
    "    p = num * _p / ((num - 1) * _p + 1)\n",
    "    return oof, p\n",
    "\n",
    "def inflate_preds(_y, _oof, _p):\n",
    "    # find the best num multiplier for binary prediction\n",
    "    best_score = np.inf\n",
    "    best_num = None\n",
    "    best_oof = None\n",
    "    best_p = None\n",
    "    \n",
    "    candidates = np.linspace(0.05,5,100)\n",
    "    for num in candidates:\n",
    "        curr_oof, curr_p = pp_prob3(_oof, _p, num)\n",
    "        curr_score = balanced_log_loss(_y, curr_oof)\n",
    "        if curr_score < best_score:\n",
    "            best_num = num\n",
    "            best_score = curr_score\n",
    "            best_p = curr_p\n",
    "            best_oof = curr_oof\n",
    "    print('best num:', round(best_num, 2), '/ best score:', best_score)\n",
    "    return best_oof, best_p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================================================================\n",
    "# Logistic Regression\n",
    "\n",
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f'{COMP_PATH}/train.csv')\n",
    "test = pd.read_csv(f'{COMP_PATH}/test.csv')\n",
    "greeks = pd.read_csv(f'{COMP_PATH}/greeks.csv')\n",
    "\n",
    "train.columns = train.columns.str.replace(' ', '')\n",
    "test.columns = test.columns.str.replace(' ', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greeks will be used in the stratified k-fold strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeks['k'] = greeks['Alpha'] + greeks['Beta'] + greeks['Gamma'] + greeks['Delta']\n",
    "train = pd.merge( greeks[['k', 'Id']],train,on='Id')\n",
    "\n",
    "names = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD', 'BN',\n",
    "         'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD', 'CF', 'CH', 'CL', 'CR', 'CS',\n",
    "         'CU', 'CW', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n",
    "         'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD', 'FE', 'FI',\n",
    "         'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL']\n",
    "target_name = 'Class'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['EJ'] = pd.Series(np.where(train.EJ.values == 'A', 1, 0), train.index)\n",
    "test['EJ'] = pd.Series(np.where(test.EJ.values == 'A', 1, 0), test.index)\n",
    "\n",
    "# fill nan data with mean values \n",
    "train[names] = train[names].fillna(train[names].mean())\n",
    "test[names] = test[names].fillna(train[names].mean())\n",
    "# clip values to avoid different values in the test set from train\n",
    "test = test[names].clip(train[names].min(axis=0).values,train[names].max(axis=0).values, axis=1)\n",
    "\n",
    "# data scaled to allow the features interaction (by multiplication)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train2 = copy.copy(train)\n",
    "teste2 = copy.copy(test)\n",
    "\n",
    "vals = scaler.fit_transform(train[names])\n",
    "vals_test = scaler.transform(test[names])\n",
    "\n",
    "train2[names] = vals\n",
    "teste2[names] = vals_test\n",
    "\n",
    "if CFG.nan_impute:\n",
    "    train2['EL'] = train_df['EL_adj']\n",
    "    teste2['EL'] = test_df['EL_adj']\n",
    "    train2['DA'] = train_df['DA_adj']\n",
    "    teste2['DA'] = test_df['DA_adj']\n",
    "    train2['EE'] = train_df['EE_adj']\n",
    "    teste2['EE'] = test_df['EE_adj']\n",
    "    train2['GH'] = train_df['GH_adj']\n",
    "    teste2['GH'] = test_df['GH_adj']\n",
    "    train2['DY'] = train_df['DY_adj']\n",
    "    teste2['DY'] = test_df['DY_adj']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining 2 order interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multiply and make a array of all interactions\n",
    "def mab(df,nome1,nome2):\n",
    "    a  = df[nome1]*df[nome2]\n",
    "    return(a/max(a))\n",
    "\n",
    "h = []\n",
    "ht = []\n",
    "\n",
    "n = 1\n",
    "for n1 in names:\n",
    "    for n2 in names[n:]:\n",
    "        h.append(mab(train2,n1,n2).rename(n1+'_mul_'+n2))\n",
    "        ht.append(mab(teste2,n1,n2).rename(n1+'_mul_'+n2))\n",
    "        \n",
    "    n+=1\n",
    "    \n",
    "newF = pd.DataFrame(h)\n",
    "newF_test = pd.DataFrame(ht)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get IV and WOE features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://lucastiagooliveira.github.io/datascience/iv/woe/python/2020/12/15/iv_woe.html\n",
    "def iv_woe(data, target, bins=10, show_woe=False):\n",
    "    \n",
    "    #Empty Dataframe\n",
    "    newDF,woeDF = pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    #Extract Column Names\n",
    "    cols = data.columns\n",
    "    \n",
    "    #Run WOE and IV on all the independent variables\n",
    "    for ivars in cols[~cols.isin([target])]:\n",
    "        if (data[ivars].dtype.kind in 'bifc') and (len(np.unique(data[ivars]))>10):\n",
    "            binned_x = pd.qcut(data[ivars], bins,  duplicates='drop')\n",
    "            d0 = pd.DataFrame({'x': binned_x, 'y': data[target]})\n",
    "        else:\n",
    "            d0 = pd.DataFrame({'x': data[ivars], 'y': data[target]})\n",
    "\n",
    "        \n",
    "        # Calculate the number of events in each group (bin)\n",
    "        d = d0.groupby(\"x\", as_index=False).agg({\"y\": [\"count\", \"sum\"]})\n",
    "        d.columns = ['Cutoff', 'N', 'Events']\n",
    "        \n",
    "        # Calculate % of events in each group.\n",
    "        d['% of Events'] = np.maximum(d['Events'], 0.5) / d['Events'].sum()\n",
    "\n",
    "        # Calculate the non events in each group.\n",
    "        d['Non-Events'] = d['N'] - d['Events']\n",
    "        # Calculate % of non events in each group.\n",
    "        d['% of Non-Events'] = np.maximum(d['Non-Events'], 0.5) / d['Non-Events'].sum()\n",
    "\n",
    "        # Calculate WOE by taking natural log of division of % of non-events and % of events\n",
    "        d['WoE'] = np.log(d['% of Events']/d['% of Non-Events'])\n",
    "        d['IV'] = d['WoE'] * (d['% of Events'] - d['% of Non-Events'])\n",
    "        d.insert(loc=0, column='Variable', value=ivars)\n",
    "        #print(\"Information value of \" + ivars + \" is \" + str(round(d['IV'].sum(),6)))\n",
    "        temp =pd.DataFrame({\"Variable\" : [ivars], \"IV\" : [d['IV'].sum()]}, columns = [\"Variable\", \"IV\"])\n",
    "        newDF=pd.concat([newDF,temp], axis=0)\n",
    "        woeDF=pd.concat([woeDF,d], axis=0)\n",
    "\n",
    "        #Show WOE Table\n",
    "        if show_woe == True:\n",
    "            print(d)\n",
    "    return newDF, woeDF\n",
    "\n",
    "a,b = iv_woe(train2, target_name, bins=10, show_woe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['k', 'Id', 'DU', 'GL', 'FL', 'CR', 'DA', 'AF', 'AB', 'BQ', 'DI',\n",
       "       'EB', 'FD', 'EE', 'EH', 'FR', 'CD', 'DE', 'CC', 'BN', 'FI', 'FE',\n",
       "       'DH', 'EU', 'GF', 'DF', 'BC', 'DL', 'AM', 'BP', 'AH', 'AR', 'GH',\n",
       "       'DN', 'CS', 'GB', 'DY', 'CF', 'CB', 'GI', 'BD', 'FC', 'BR', 'CU',\n",
       "       'EL', 'FS', 'AZ', 'EJ', 'CW', 'AX', 'GE', 'AY', 'EG', 'EP', 'CH',\n",
       "       'CL', 'BZ', 'DV'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most important features based on IV\n",
    "a.sort_values(by='IV',ascending=False).Variable.values "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset with the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the dataframe to keep IV with higger values in front\n",
    "trainE = train[a.sort_values(by='IV',ascending=False).Variable.values]\n",
    "trainE[target_name] = train[target_name]\n",
    "testeE = test[a.sort_values(by='IV',ascending=False).Variable.values[2:]]\n",
    "\n",
    "# join the original vars and the interactions between them\n",
    "ff = pd.concat([trainE,newF.T],axis=1)\n",
    "ff_teste = pd.concat([testeE,newF_test.T],axis=1)\n",
    "\n",
    "a,b = iv_woe(ff, target_name, bins=10, show_woe=False)\n",
    "\n",
    "# deleting all IVs below 0.05\n",
    "a = a.loc[a['IV']> 0.05]\n",
    "\n",
    "allNames = a.sort_values(by='IV',ascending=False).Variable.values\n",
    "crossNames = [x for x in allNames if '_mul_' in x]\n",
    "\n",
    "nomes2 = list(trainE) + crossNames\n",
    "nomes2.remove('Class')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set threshold for correlation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "\n",
    "cc = ff[nomes2[2:]].corr()\n",
    "\n",
    "mat_x = abs(cc)>threshold\n",
    "mat_x = mat_x.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select variables with low correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are +- 70 features with low correlation\n",
    "var1 = []\n",
    "nomes = list(cc)\n",
    "var1.append(nomes[0])\n",
    "max_vars = 100\n",
    "\n",
    "count = 1\n",
    "for n in range(1,len(nomes)):\n",
    "    \n",
    "    if (mat_x[n,:n+1].sum() ) == 1:\n",
    "        \n",
    "        var1.append(nomes[n])        \n",
    "        count+=1\n",
    "        \n",
    "        if(count == max_vars):\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop features that get low score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['CW', 'AZ', 'FS', 'BR', 'FE', 'BN', 'DE', 'AF', 'CR',\n",
    "                    'CR_mul_DE', 'BQ_mul_FE', 'CR_mul_GE', 'EE_mul_GF', \n",
    "                    'CR_mul_FE', 'BQ_mul_FC', 'DE_mul_DL', 'AZ_mul_GL', 'CW_mul_DL', \n",
    "                    'BN_mul_CR', 'DN_mul_FI', 'AZ_mul_FE', 'CW_mul_EL', 'AZ_mul_CU',\n",
    "                    'CW_mul_DY', 'DH_mul_DL', 'AX_mul_CU', 'BN_mul_DE', 'BN_mul_CW', \n",
    "                    'AZ_mul_EL', 'AZ_mul_DE']\n",
    "\n",
    "var1 = [v for v in var1 if v not in features_to_drop]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dict with WoE transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dic with WoE transformation\n",
    "list_dics = []\n",
    "\n",
    "for var in var1:\n",
    "  df_temp = b.loc[b['Variable']==var].reset_index()\n",
    "  # crieate dict\n",
    "  dict_var = {}\n",
    "  for x in range(len(df_temp)):\n",
    "    line = df_temp.iloc[x]\n",
    "    dict_var[line['Cutoff']] = line['WoE']\n",
    "  list_dics.append(dict_var)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test data\n",
    "df_original = ff[var1+[target_name] + ['k'] ]\n",
    "df_test2 = ff_teste[var1]\n",
    "names = var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this part there is some data leakage as the map is using the full dataset\n",
    "n = 0\n",
    "\n",
    "for var in var1:\n",
    "    df_original.loc[:,var] = df_original[var].map(list_dics[n])\n",
    "    df_test2.loc[:,var] = df_test2[var].map(list_dics[n])\n",
    "    n = n + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.loc[:,names] = df_original[names].fillna(df_original[names].mean())\n",
    "df_test2.loc[:,names] = df_test2[names].fillna(df_original[names].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original['DU FR'] = df_original['DU'] * df_original['FR']\n",
    "df_test2['DU FR'] = df_test2['DU'] * df_test2['FR']\n",
    "\n",
    "names = names + ['DU FR']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16272994848452088"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_LR = 0\n",
    "cv_score_LR = 0\n",
    "\n",
    "rr = [42, 21, 100, 45, 1, 228]\n",
    "\n",
    "oof_level2_LR = np.zeros([df_original['Class'].shape[0], len(rr)])\n",
    "oof_level2_LR_test = np.zeros([test_df.shape[0], len(rr)])\n",
    "\n",
    "for f, v_fold in enumerate(rr):\n",
    "    skf = StratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=3082023)\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(df_original[names], df_original['Class'])):\n",
    "\n",
    "            model = LogisticRegression(random_state=3082023+i, C=0.1, n_jobs=-1, max_iter=2000, class_weight='balanced')\n",
    "\n",
    "            df_train = df_original.iloc[train_index]\n",
    "            df_val = df_original.iloc[val_index]\n",
    "            \n",
    "            df_train1 = df_train[names].to_numpy()\n",
    "            df_val1 = df_val[names].to_numpy()            \n",
    "            \n",
    "            model.fit(df_train1, df_train['Class'])\n",
    "            \n",
    "            y_hat_val_LR = model.predict_proba(df_val1)[:,1]\n",
    "            val = balanced_log_loss(df_val[target_name], y_hat_val_LR.reshape(-1, ))\n",
    "            \n",
    "            try:\n",
    "                oof_level2_LR[val_index, f] = model.predict_proba(df_val1)[:,1]\n",
    "                oof_level2_LR_test[:,f] = model.predict_proba(df_test2[names])[:,1]\n",
    "            except:\n",
    "                oof_level2_LR[val_index, f] = np.zeros(len(val_index))\n",
    "                oof_level2_LR_test[:,f] = np.zeros(df_test2.shape[0])\n",
    "\n",
    "# Use Optuna to find the best ensemble weights\n",
    "optweights = OptunaWeights(random_state=10082023)\n",
    "y_val_pred = optweights.fit_predict(y, [oof_level2_LR[:,i] for i in range(oof_level2_LR.shape[1])])\n",
    "optuna_weights_LR = np.array(optweights.weights)\n",
    "display(balanced_log_loss(y, y_val_pred))\n",
    "\n",
    "# oof_level2_LR = (optuna_weights_LR * oof_level2_LR).sum(axis=1) / sum(optuna_weights_LR)\n",
    "# oof_level2_LR_test = (optuna_weights_LR * oof_level2_LR_test).sum(axis=1) / sum(optuna_weights_LR)\n",
    "\n",
    "oof_level2_LR = oof_level2_LR.mean(axis=1)\n",
    "oof_level2_LR_test = oof_level2_LR_test.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.16225423758252122"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =================================================================\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly_train = PolynomialFeatures()\n",
    "# data_transform = data_post.drop('Class', axis=1).copy()\n",
    "# data_poly = pd.DataFrame(poly_train.fit_transform(data_transform),\n",
    "#                          columns=poly_train.get_feature_names_out(), index=data_transform.index)\n",
    "# data_poly=data_poly.drop('1', axis=1)\n",
    "# data_poly=pd.concat([data_poly, data_post[['Class']]], axis=1)\n",
    "# data_poly.Class = data_poly.Class.astype('int64')\n",
    "\n",
    "# poly_test = PolynomialFeatures()\n",
    "# test_poly = pd.DataFrame(poly_test.fit_transform(new_test), columns=poly_test.get_feature_names_out())\n",
    "# test_poly = test_poly.drop('1', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from featurewiz import featurewiz\n",
    "# new_features, _ = featurewiz(data_poly, 'Class', corr_limit=0.5, verbose=2)\n",
    "\n",
    "# new_features = ['DI DU', 'DU FR', 'DA DE', 'AB GL', 'BQ CL', 'CC DA', 'AM FE', 'AB DA', \n",
    "#                 'CD DY', 'FI', 'CR DH', 'AF^2', 'DF GL', 'BQ EU', 'CR EE', 'CU DL',\n",
    "#                 'BQ FI', 'FE FL', 'CD^2', 'AF FE', 'DN FD', 'BC EB', 'BC FL', 'DN',\n",
    "#                 'AB FL', 'CR GI', 'DE DU', 'GE GL', 'BN FS', 'CC DF', 'CB DE', 'CR EP',\n",
    "#                 'CL EL', 'EJ GL', 'BN EL', 'EE GF', 'BR CR', 'AM GF', 'CR GL', 'AZ DI',\n",
    "#                 'DA EG', 'AB GI', 'FE GF', 'FC GL']\n",
    "\n",
    "# data_sel = data_poly[new_features]\n",
    "# data_sel['Class'] = data_poly['Class']\n",
    "\n",
    "# X = data_sel.drop('Class', axis=1)\n",
    "# y = data_sel['Class']\n",
    "# test = test_poly[new_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======================================================\n",
    "# Get ensemble predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7797487 , 0.25408906])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.13191636552726427"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_level2 = [oof_level2_LGBM, oof_level2_LR]\n",
    "oof_level2_test = [oof_level2_LGBM_test, oof_level2_LR_test]\n",
    "\n",
    "# Use Optuna to find the best ensemble weights\n",
    "optweights = OptunaWeights(random_state=19072023)\n",
    "y_val_pred = optweights.fit_predict(y, [oof_level2[i] for i in range(len(oof_level2))])\n",
    "optuna_weights = np.array(optweights.weights)\n",
    "# optuna_weights[optuna_weights < 0.05] = 0\n",
    "display(optuna_weights)\n",
    "balanced_log_loss(y, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([0.78904702, 0.60003746]) 0.14622005365208357"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.61074</td>\n",
       "      <td>0.38926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.61074</td>\n",
       "      <td>0.38926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.61074</td>\n",
       "      <td>0.38926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.61074</td>\n",
       "      <td>0.38926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.61074</td>\n",
       "      <td>0.38926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  class_0  class_1\n",
       "0  00eed32682bb  0.61074  0.38926\n",
       "1  010ebe33f668  0.61074  0.38926\n",
       "2  02fa521e1838  0.61074  0.38926\n",
       "3  040e15f562a2  0.61074  0.38926\n",
       "4  046e85c7cc7f  0.61074  0.38926"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(X):\n",
    "    y = np.zeros_like(X[0])\n",
    "    for i in range(len(X)):\n",
    "        # y += oof_level2_test[i]\n",
    "        y += optuna_weights[i] * X[i]\n",
    "    # return y / len(X)\n",
    "    return y / sum(optuna_weights)\n",
    "\n",
    "# def predict(X):\n",
    "#     pred = (X * (1 / np.maximum(oof_level2_val.mean(axis=0), 1e-15))).sum(axis=1) / (1 / np.maximum(oof_level2_val.mean(axis=0), 1e-15)).sum()\n",
    "#     return pred\n",
    "\n",
    "def lr_predict(X):\n",
    "    return lr.predict_proba(X)[:,1]\n",
    "\n",
    "predictions = predict(oof_level2_test)\n",
    "# predictions = lr_predict(oof_level2_test)\n",
    "\n",
    "if CFG.adjust_class_threshold:\n",
    "    _, predictions = inflate_preds(y, np.mean(X, axis=1), predictions)\n",
    "\n",
    "predictions = np.nan_to_num(predictions)\n",
    "test_df['class_1'] = np.round(predictions, 15)\n",
    "test_df['class_0'] = 1 - predictions\n",
    "\n",
    "sample_submission[['class_0', 'class_1']] = test_df[['class_0', 'class_1']]\n",
    "sample_submission.to_csv(r\"submission.csv\", index=False)\n",
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
