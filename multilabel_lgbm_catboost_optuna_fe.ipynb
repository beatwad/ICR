{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:23.665663Z",
     "iopub.status.busy": "2023-06-08T15:31:23.665223Z",
     "iopub.status.idle": "2023-06-08T15:31:35.997437Z",
     "shell.execute_reply": "2023-06-08T15:31:35.996163Z",
     "shell.execute_reply.started": "2023-06-08T15:31:23.665630Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "from catboost import Pool\n",
    "\n",
    "import itertools\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits, BaseShuffleSplit, _validate_shuffle_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import _num_samples, check_array\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import eli5\n",
    "from IPython.display import display\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "from colorama import Style, Fore\n",
    "\n",
    "palette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n",
    "           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n",
    "\n",
    "blk = Style.BRIGHT + Fore.BLACK\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "res = Style.RESET_ALL\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    feature_sel = False\n",
    "    n_feature_sel_folds = 5\n",
    "    \n",
    "    lgbm_optimize = True\n",
    "    cb_optimize = False\n",
    "    xgb_optimize = False\n",
    "    n_optimize_folds = 3\n",
    "    n_optimize_repeats = 5\n",
    "    \n",
    "    n_stacking_folds = 10\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.001085Z",
     "iopub.status.busy": "2023-06-08T15:31:35.999808Z",
     "iopub.status.idle": "2023-06-08T15:31:36.066222Z",
     "shell.execute_reply": "2023-06-08T15:31:36.064862Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.001050Z"
    }
   },
   "outputs": [],
   "source": [
    "# COMP_PATH = \"/kaggle/input/icr-identify-age-related-conditions\"\n",
    "COMP_PATH = \"icr-identify-age-related-conditions\"\n",
    "\n",
    "train_df = pd.read_csv(f'{COMP_PATH}//train.csv')\n",
    "test_df = pd.read_csv(f'{COMP_PATH}/test.csv')\n",
    "greeks = pd.read_csv(f\"{COMP_PATH}/greeks.csv\")\n",
    "sample_submission = pd.read_csv(f\"{COMP_PATH}/sample_submission.csv\")\n",
    "\n",
    "train_df['EJ'] = train_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "test_df['EJ'] = test_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "\n",
    "train_df.columns = train_df.columns.str.replace(' ', '')\n",
    "test_df.columns = test_df.columns.str.replace(' ', '')\n",
    "\n",
    "# train_df.drop('Id',axis=1, inplace=True)\n",
    "# train_df.fillna(train_df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.069293Z",
     "iopub.status.busy": "2023-06-08T15:31:36.068506Z",
     "iopub.status.idle": "2023-06-08T15:31:36.075275Z",
     "shell.execute_reply": "2023-06-08T15:31:36.074052Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.069253Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# new_num_cols = train_df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "# train_df[new_num_cols] = scaler.fit_transform(train_df[new_num_cols])\n",
    "# test_df[new_num_cols] = scaler.transform(test_df[new_num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine features in all possible ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi = pd.read_csv('feature_importances.csv', index_col = 'Unnamed: 0')\n",
    "# fi_cols = set(fi['Feature'].head(100).values)\n",
    "\n",
    "# perm = pd.read_csv('perm_df.csv', index_col = 'Unnamed: 0')\n",
    "# perm_cols = set(perm['importance'].head(100).index)\n",
    "\n",
    "# important_col = list(perm_cols.intersection(fi_cols))\n",
    "# print(important_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [fe for fe in train_df.columns if fe not in ['Id','CF', 'CB', 'DV', 'BR', 'DF', 'AR', 'GI', 'AY', 'GB',\n",
    "#                                                         'AH', 'CW', 'CL', 'Class', 'BP']]\n",
    "\n",
    "# for f in features:\n",
    "#     train_df[f] = np.floor(train_df[f]*1000)/1000 # quality decreases no significant result for LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log features (preserve sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in features:\n",
    "#     train_df[f] = np.sign(train_df[f]) * np.log1p(np.abs(train_df[f])) # no significant result for LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_outliers = [fe for fe in train_df.columns if fe not in ['BN', 'BQ', 'CW', 'EL', 'GH', \n",
    "                                                                      'GI', 'GL', 'Id', 'Class', 'EJ']]\n",
    "\n",
    "for f in features_with_outliers:\n",
    "    train_df[f] = train_df[f].clip(upper=train_df[f].quantile(0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.080972Z",
     "iopub.status.busy": "2023-06-08T15:31:36.079281Z",
     "iopub.status.idle": "2023-06-08T15:31:44.412385Z",
     "shell.execute_reply": "2023-06-08T15:31:44.411508Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.080912Z"
    }
   },
   "outputs": [],
   "source": [
    "# features = train_df.drop(['Class', 'Id'], axis=1).columns\n",
    "\n",
    "features = [fe for fe in train_df.columns if fe not in ['CF', 'CB', 'DV', 'BR', 'DF', 'GB', 'AH', \n",
    "                                                        'CW', 'CL', 'BP', 'BD', 'FC', 'GE', 'GF',\n",
    "                                                        'AR', 'GI', 'Id', 'Class', 'AX']]\n",
    "\n",
    "# features = [fe for fe in train_df.columns if fe not in ['Id', 'CF', 'CB', 'DV', 'BR', 'DF', 'AR', 'GI', \n",
    "#                                                         'AY', 'GB', 'AH', 'CW', 'CL', 'Class', 'BP', \n",
    "#                                                         'AX', 'BD', 'BZ', 'FC']]\n",
    "\n",
    "# def gen_features(features, df):\n",
    "#     generated_features = pd.DataFrame()\n",
    "\n",
    "#     for fe_a, fe_b in tqdm(itertools.combinations(features, 2), total=sum([1 for i in itertools.combinations(features, 2)])):\n",
    "\n",
    "# #         generated_features[f'{fe_a}_2']        = df[fe_a].pow(2)\n",
    "# #         generated_features[f'{fe_b}_2']        = df[fe_b].pow(2)\n",
    "# #         generated_features[f'{fe_a}*{fe_b}_2'] = df[fe_a] * df[fe_b].pow(2)\n",
    "# #         generated_features[f'{fe_a}_2*{fe_b}'] = df[fe_a].pow(2) * df[fe_b]\n",
    "\n",
    "# #         generated_features[f'{fe_a}_05'] = df[fe_a].pow(0.5)\n",
    "# #         generated_features[f'{fe_b}_05'] = df[fe_b].pow(0.5)\n",
    "# #         generated_features[f'{fe_a}*{fe_b}_05'] = df[fe_a] * df[fe_b].pow(0.5)\n",
    "# #         generated_features[f'{fe_a}_05*{fe_b}'] = df[fe_a].pow(0.5) * df[fe_b]\n",
    "\n",
    "# #         generated_features[f'{fe_a}_log'] = np.log(df[fe_a])\n",
    "# #         generated_features[f'{fe_b}_log'] = np.log(df[fe_b])\n",
    "# #         generated_features[f'{fe_a}*{fe_b}_log'] = df[fe_a] * np.log(df[fe_b])\n",
    "# #         generated_features[f'{fe_a}_log*{fe_b}'] = np.log(df[fe_a]) * df[fe_b]\n",
    "        \n",
    "#     generated_features = generated_features[selected]\n",
    "#     generated_features = pd.concat([generated_features, df[features]], axis=1)\n",
    "    \n",
    "#     # prevent inf\n",
    "#     for g in generated_features.columns:\n",
    "#         generated_features[g] = np.minimum(np.maximum(generated_features[g], -1e9), 1e9)\n",
    "    \n",
    "#     return generated_features\n",
    "\n",
    "# generated_features_train = gen_features(features, train_df)\n",
    "# generated_features_test = gen_features(features, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "\n",
    "# # cosine distance\n",
    "# knn = NearestNeighbors(n_neighbors=21, metric='cosine', n_jobs=-1)\n",
    "# knn.fit(train_df[features].fillna(0))\n",
    "\n",
    "# # train\n",
    "# dists, nears = knn.kneighbors(train_df[features].fillna(0), return_distance=True)\n",
    "# dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# train_df['class_cos'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# train_df['class_cos'] = train_df['class_cos'].astype(float)\n",
    "\n",
    "# # train_df['dists_cos_0'] = np.array([dists[i][classes[i] == 0].mean() for i in range(len(nears))])\n",
    "# # train_df['dists_cos_1'] = np.array([dists[i][classes[i] == 1].mean() for i in range(len(nears))])\n",
    "# # train_df['dists_cos_0'], train_df['dists_cos_1'] = train_df['dists_cos_0'].fillna(10), train_df['dists_cos_1'].fillna(10)\n",
    "\n",
    "# # test\n",
    "# dists, nears = knn.kneighbors(test_df[features].fillna(0), return_distance=True)\n",
    "# dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# test_df['class_cos'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# test_df['class_cos'] = test_df['class_cos'].astype(float)\n",
    "\n",
    "# # test_df['dists_cos_0'] = np.array([dists[i][classes[i] == 0].mean() for i in range(len(nears))])\n",
    "# # test_df['dists_cos_1'] = np.array([dists[i][classes[i] == 1].mean() for i in range(len(nears))])\n",
    "# # test_df['dists_cos_0'], test_df['dists_cos_1'] = test_df['dists_cos_0'].fillna(10), test_df['dists_cos_1'].fillna(10)\n",
    "\n",
    "# # # euclidean distance\n",
    "# # knn = NearestNeighbors(n_neighbors=21, metric='euclidean', n_jobs=-1)\n",
    "# # knn.fit(train_df[features].fillna(0))\n",
    "\n",
    "# # # train\n",
    "# # dists, nears = knn.kneighbors(train_df[features].fillna(0), return_distance=True)\n",
    "# # dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# # classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# # train_df['class_euc'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# # train_df['class_euc'] = train_df['class_euc'].astype(float)\n",
    "\n",
    "# # train_df['dists_euc_0'] = np.array([dists[i][classes[i] == 0].mean() for i in range(len(nears))])\n",
    "# # train_df['dists_euc_1'] = np.array([dists[i][classes[i] == 1].mean() for i in range(len(nears))])\n",
    "# # train_df['dists_euc_0'], train_df['dists_euc_1'] = train_df['dists_euc_0'].fillna(10), train_df['dists_euc_1'].fillna(10)\n",
    "\n",
    "# # # test\n",
    "# # dists, nears = knn.kneighbors(test_df[features].fillna(0), return_distance=True)\n",
    "# # dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# # classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# # test_df['class_euc'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# # test_df['class_euc'] = test_df['class_euc'].astype(float)\n",
    "\n",
    "# # test_df['dists_euc_0'] = np.array([dists[i][classes[i] == 0].mean() for i in range(len(nears))])\n",
    "# # test_df['dists_euc_1'] = np.array([dists[i][classes[i] == 1].mean() for i in range(len(nears))])\n",
    "# # test_df['dists_euc_0'], test_df['dists_euc_1'] = test_df['dists_euc_0'].fillna(10), test_df['dists_euc_1'].fillna(10)\n",
    "\n",
    "# # # manhattan distance\n",
    "# # knn = NearestNeighbors(n_neighbors=21, metric='manhattan', n_jobs=-1)\n",
    "# # knn.fit(train_df[features].fillna(0))\n",
    "\n",
    "# # # train\n",
    "# # dists, nears = knn.kneighbors(train_df[features].fillna(0), return_distance=True)\n",
    "# # dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# # classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# # train_df['class_man'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# # train_df['class_man'] = train_df['class_man'].astype(float)\n",
    "\n",
    "# # train_df['dists_man_0'] = np.array([dists[i][classes[i] == 0].mean() for i in range(len(nears))])\n",
    "# # train_df['dists_man_1'] = np.array([dists[i][classes[i] == 1].mean() for i in range(len(nears))])\n",
    "# # train_df['dists_man_0'], train_df['dists_man_1'] = train_df['dists_man_0'].fillna(10), train_df['dists_man_1'].fillna(10)\n",
    "\n",
    "# # # test\n",
    "# # dists, nears = knn.kneighbors(test_df[features].fillna(0), return_distance=True)\n",
    "# # dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# # classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# # test_df['class_man'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# # test_df['class_man'] = test_df['class_man'].astype(float)\n",
    "\n",
    "# # test_df['dists_man_0'] = np.array([dists[i][classes[i] == 0].mean() for i in range(len(nears))])\n",
    "# # test_df['dists_man_1'] = np.array([dists[i][classes[i] == 1].mean() for i in range(len(nears))])\n",
    "# # test_df['dists_man_0'], test_df['dists_man_1'] = test_df['dists_man_0'].fillna(10), test_df['dists_man_1'].fillna(10)\n",
    "\n",
    "# features = [fe for fe in train_df.columns if fe not in ['CF', 'CB', 'DV', 'BR', 'DF', 'GB', 'AH', \n",
    "#                                                         'CW', 'CL', 'BP', 'BD', 'FC', 'GE', 'GF',\n",
    "#                                                         'AR', 'GI', 'Id', 'Class', 'AX']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:44.414098Z",
     "iopub.status.busy": "2023-06-08T15:31:44.413784Z",
     "iopub.status.idle": "2023-06-08T15:31:44.461531Z",
     "shell.execute_reply": "2023-06-08T15:31:44.460184Z",
     "shell.execute_reply.started": "2023-06-08T15:31:44.414071Z"
    }
   },
   "outputs": [],
   "source": [
    "def IterativeStratification(labels, r, random_state):\n",
    "    \"\"\"This function implements the Iterative Stratification algorithm described\n",
    "    in the following paper:\n",
    "    Sechidis K., Tsoumakas G., Vlahavas I. (2011) On the Stratification of\n",
    "    Multi-Label Data. In: Gunopulos D., Hofmann T., Malerba D., Vazirgiannis M.\n",
    "    (eds) Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n",
    "    2011. Lecture Notes in Computer Science, vol 6913. Springer, Berlin,\n",
    "    Heidelberg.\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = labels.shape[0]\n",
    "    test_folds = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    # Calculate the desired number of examples at each subset\n",
    "    c_folds = r * n_samples\n",
    "\n",
    "    # Calculate the desired number of examples of each label at each subset\n",
    "    c_folds_labels = np.outer(r, labels.sum(axis=0))\n",
    "\n",
    "    labels_not_processed_mask = np.ones(n_samples, dtype=bool)\n",
    "\n",
    "    while np.any(labels_not_processed_mask):\n",
    "        # Find the label with the fewest (but at least one) remaining examples,\n",
    "        # breaking ties randomly\n",
    "        num_labels = labels[labels_not_processed_mask].sum(axis=0)\n",
    "\n",
    "        # Handle case where only all-zero labels are left by distributing\n",
    "        # across all folds as evenly as possible (not in original algorithm but\n",
    "        # mentioned in the text). (By handling this case separately, some\n",
    "        # code redundancy is introduced; however, this approach allows for\n",
    "        # decreased execution time when there are a relatively large number\n",
    "        # of all-zero labels.)\n",
    "        if num_labels.sum() == 0:\n",
    "            sample_idxs = np.where(labels_not_processed_mask)[0]\n",
    "\n",
    "            for sample_idx in sample_idxs:\n",
    "                fold_idx = np.where(c_folds == c_folds.max())[0]\n",
    "\n",
    "                if fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(fold_idx.shape[0])]\n",
    "\n",
    "                test_folds[sample_idx] = fold_idx\n",
    "                c_folds[fold_idx] -= 1\n",
    "\n",
    "            break\n",
    "\n",
    "        label_idx = np.where(num_labels == num_labels[np.nonzero(num_labels)].min())[0]\n",
    "        if label_idx.shape[0] > 1:\n",
    "            label_idx = label_idx[random_state.choice(label_idx.shape[0])]\n",
    "\n",
    "        sample_idxs = np.where(np.logical_and(labels[:, label_idx].flatten(), labels_not_processed_mask))[0]\n",
    "\n",
    "        for sample_idx in sample_idxs:\n",
    "            # Find the subset(s) with the largest number of desired examples\n",
    "            # for this label, breaking ties by considering the largest number\n",
    "            # of desired examples, breaking further ties randomly\n",
    "            label_folds = c_folds_labels[:, label_idx]\n",
    "            fold_idx = np.where(label_folds == label_folds.max())[0]\n",
    "\n",
    "            if fold_idx.shape[0] > 1:\n",
    "                temp_fold_idx = np.where(c_folds[fold_idx] ==\n",
    "                                         c_folds[fold_idx].max())[0]\n",
    "                fold_idx = fold_idx[temp_fold_idx]\n",
    "\n",
    "                if temp_fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(temp_fold_idx.shape[0])]\n",
    "\n",
    "            test_folds[sample_idx] = fold_idx\n",
    "            labels_not_processed_mask[sample_idx] = False\n",
    "\n",
    "            # Update desired number of examples\n",
    "            c_folds_labels[fold_idx, labels[sample_idx]] -= 1\n",
    "            c_folds[fold_idx] -= 1\n",
    "\n",
    "    return test_folds\n",
    "\n",
    "\n",
    "class MultilabelStratifiedKFold(_BaseKFold):\n",
    "    \"\"\"Multilabel stratified K-Folds cross-validator\n",
    "    Provides train/test indices to split multilabel data into train/test sets.\n",
    "    This cross-validation object is a variation of KFold that returns\n",
    "    stratified folds for multilabel data. The folds are made by preserving\n",
    "    the percentage of samples for each label.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=3\n",
    "        Number of folds. Must be at least 2.\n",
    "    shuffle : boolean, optional\n",
    "        Whether to shuffle each stratification of the data before splitting\n",
    "        into batches.\n",
    "    random_state : int, RandomState instance or None, optional, default=None\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedKFold that only uses random_state\n",
    "        when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> mskf = MultilabelStratifiedKFold(n_splits=2, random_state=0)\n",
    "    >>> mskf.get_n_splits(X, y)\n",
    "    2\n",
    "    >>> print(mskf)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    MultilabelStratifiedKFold(n_splits=2, random_state=0, shuffle=False)\n",
    "    >>> for train_index, test_index in mskf.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different in each fold.\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedMultilabelStratifiedKFold: Repeats Multilabel Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=3, *, shuffle=False, random_state=None):\n",
    "        super(MultilabelStratifiedKFold, self).__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def _make_test_folds(self, X, y):\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(type_of_target_y))\n",
    "\n",
    "        num_samples = y.shape[0]\n",
    "\n",
    "        rng = check_random_state(self.random_state)\n",
    "        indices = np.arange(num_samples)\n",
    "\n",
    "        if self.shuffle:\n",
    "            rng.shuffle(indices)\n",
    "            y = y[indices]\n",
    "\n",
    "        r = np.asarray([1 / self.n_splits] * self.n_splits)\n",
    "\n",
    "        test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "        return test_folds[np.argsort(indices)]\n",
    "\n",
    "    def _iter_test_masks(self, X=None, y=None, groups=None):\n",
    "        test_folds = self._make_test_folds(X, y)\n",
    "        for i in range(self.n_splits):\n",
    "            yield test_folds == i\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedKFold, self).split(X, y, groups)\n",
    "\n",
    "\n",
    "class RepeatedMultilabelStratifiedKFold(_RepeatedSplits):\n",
    "    \"\"\"Repeated Multilabel Stratified K-Fold cross validator.\n",
    "    Repeats Mulilabel Stratified K-Fold n times with different randomization\n",
    "    in each repetition.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of folds. Must be at least 2.\n",
    "    n_repeats : int, default=10\n",
    "        Number of times cross-validator needs to be repeated.\n",
    "    random_state : None, int or RandomState, default=None\n",
    "        Random state to be used to generate random state for each\n",
    "        repetition as well as randomly breaking ties within the iterative\n",
    "        stratification algorithm.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import RepeatedMultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> rmskf = RepeatedMultilabelStratifiedKFold(n_splits=2, n_repeats=2,\n",
    "    ...     random_state=0)\n",
    "    >>> for train_index, test_index in rmskf.split(X, y):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    ...\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [0 1 4 5] TEST: [2 3 6 7]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedStratifiedKFold: Repeats (Non-multilabel) Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=5, *, n_repeats=10, random_state=None):\n",
    "        super(RepeatedMultilabelStratifiedKFold, self).__init__(\n",
    "            MultilabelStratifiedKFold, n_repeats=n_repeats, random_state=random_state,\n",
    "            n_splits=n_splits)\n",
    "\n",
    "\n",
    "class MultilabelStratifiedShuffleSplit(BaseShuffleSplit):\n",
    "    \"\"\"Multilabel Stratified ShuffleSplit cross-validator\n",
    "    Provides train/test indices to split data into train/test sets.\n",
    "    This cross-validation object is a merge of MultilabelStratifiedKFold and\n",
    "    ShuffleSplit, which returns stratified randomized folds for multilabel\n",
    "    data. The folds are made by preserving the percentage of each label.\n",
    "    Note: like the ShuffleSplit strategy, multilabel stratified random splits\n",
    "    do not guarantee that all folds will be different, although this is\n",
    "    still very likely for sizeable datasets.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default 10\n",
    "        Number of re-shuffling & splitting iterations.\n",
    "    test_size : float, int, None, optional\n",
    "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
    "        of the dataset to include in the test split. If int, represents the\n",
    "        absolute number of test samples. If None, the value is set to the\n",
    "        complement of the train size. By default, the value is set to 0.1.\n",
    "        The default will change in version 0.21. It will remain 0.1 only\n",
    "        if ``train_size`` is unspecified, otherwise it will complement\n",
    "        the specified ``train_size``.\n",
    "    train_size : float, int, or None, default is None\n",
    "        If float, should be between 0.0 and 1.0 and represent the\n",
    "        proportion of the dataset to include in the train split. If\n",
    "        int, represents the absolute number of train samples. If None,\n",
    "        the value is automatically set to the complement of the test size.\n",
    "    random_state : int, RandomState instance or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedShuffleSplit that only uses\n",
    "        random_state when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> msss = MultilabelStratifiedShuffleSplit(n_splits=3, test_size=0.5,\n",
    "    ...    random_state=0)\n",
    "    >>> msss.get_n_splits(X, y)\n",
    "    3\n",
    "    >>> print(mss)       # doctest: +ELLIPSIS\n",
    "    MultilabelStratifiedShuffleSplit(n_splits=3, random_state=0, test_size=0.5,\n",
    "                                     train_size=None)\n",
    "    >>> for train_index, test_index in msss.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    TRAIN: [1 2 5 6] TEST: [0 3 4 7]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different from desired due to the\n",
    "    preference of stratification over perfectly sized folds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=10, *, test_size=\"default\", train_size=None,\n",
    "                 random_state=None):\n",
    "        super(MultilabelStratifiedShuffleSplit, self).__init__(\n",
    "            n_splits=n_splits, test_size=test_size, train_size=train_size, random_state=random_state)\n",
    "\n",
    "    def _iter_indices(self, X, y, groups=None):\n",
    "        n_samples = _num_samples(X)\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(\n",
    "                    type_of_target_y))\n",
    "\n",
    "        n_train, n_test = _validate_shuffle_split(n_samples, self.test_size,\n",
    "                                                  self.train_size)\n",
    "\n",
    "        n_samples = y.shape[0]\n",
    "        rng = check_random_state(self.random_state)\n",
    "        y_orig = y.copy()\n",
    "\n",
    "        r = np.array([n_train, n_test]) / (n_train + n_test)\n",
    "\n",
    "        for _ in range(self.n_splits):\n",
    "            indices = np.arange(n_samples)\n",
    "            rng.shuffle(indices)\n",
    "            y = y_orig[indices]\n",
    "\n",
    "            test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "            test_idx = test_folds[np.argsort(indices)] == 1\n",
    "            test = np.where(test_idx)[0]\n",
    "            train = np.where(~test_idx)[0]\n",
    "\n",
    "            yield train, test\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedShuffleSplit, self).split(X, y, groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:41.223344Z",
     "iopub.status.busy": "2023-06-08T15:32:41.222954Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from shaphypetune import BoostBoruta\n",
    "\n",
    "params = {\n",
    "        'boosting_type':'goss',\n",
    "        'learning_rate': 0.06733232950390658, \n",
    "        'n_estimators': 5000, \n",
    "        'early_stopping_round' : 100, \n",
    "        'subsample' : 0.7, # bagging_fraction\n",
    "        'colsample_bytree': 0.6, # feature_fraction\n",
    "        'num_leaves': 33,\n",
    "        'class_weight': 'balanced',\n",
    "        'metric': 'none', \n",
    "        'is_unbalance': True, \n",
    "        'random_state': 8062023,\n",
    "        'feature_fraction_seed': 8062023,\n",
    "        'bagging_seed': 8062023,\n",
    "        'max_depth': 6,\n",
    "        'reg_alpha': 2.025436e-04,  \n",
    "        'reg_lambda': 2.290193e-07,\n",
    "#         'bagging_freq': 6,\n",
    "        'max_bin': 198,\n",
    "        'min_child_samples': 32,\n",
    "        'importance_type': 'gain'\n",
    "        }\n",
    "\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability 𝑝 is replaced with max(min(𝑝,1−10−15),10−15)\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1 - y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2\n",
    "\n",
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def calc_log_loss_weight(y_true): \n",
    "    '''w0, w1 assign different weights to individual data points during training.'''\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    return w0, w1\n",
    "\n",
    "def lgbm_tuning(features, permut=False, boruta=False):\n",
    "    metric = balanced_log_loss\n",
    "    eval_results_ = {}\n",
    "\n",
    "    cv_scores = [] # store all cv scores of outer loop inference\n",
    "\n",
    "    perm_df_ = pd.DataFrame()\n",
    "    feature_importances_ = pd.DataFrame()\n",
    "    boruta_df_ = pd.DataFrame()\n",
    "    \n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "        \n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(train_df.shape[0])\n",
    "        \n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=8062023+i)\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=train_df[features], y=greeks.iloc[:,1:3]), start = 1): \n",
    "            X, y = train_df[features], train_df.Class\n",
    "#             X, y = generated_features_train, train_df.Class\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "\n",
    "            X_train = X_train.reset_index(drop=True)\n",
    "            y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "            # Store models here\n",
    "            models_ = [] \n",
    "\n",
    "            eval_results_[fold]= {}\n",
    "\n",
    "            clf = lgb.LGBMClassifier(**params)\n",
    "            clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "                    eval_metric=bll_metric, # eval_sample_weight=w_val, \n",
    "                    early_stopping_rounds=300, verbose=-1)\n",
    "\n",
    "            models_.append(clf)\n",
    "\n",
    "            val_preds = clf.predict_proba(X_val)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "\n",
    "            val_score = metric(y_val, val_preds)\n",
    "            best_iter = clf.best_iteration_\n",
    "\n",
    "            print(f'Fold: {blu}{fold:>3}{res}| {metric.__name__}: {blu}{val_score:.5f}{res}'\n",
    "                  f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "\n",
    "            # permutation importance\n",
    "            if permut:\n",
    "                perm = PermutationImportance(clf, scoring=None, n_iter=1, \n",
    "                                             random_state=42, cv=None, refit=False).fit(X_val, y_val)\n",
    "\n",
    "                perm_importance_df = pd.DataFrame({'importance': perm.feature_importances_}, \n",
    "                                                   index=X_val.columns).sort_index()\n",
    "\n",
    "                if perm_df_.shape[0] == 0:\n",
    "                    perm_df_ = perm_importance_df.copy()\n",
    "                else:\n",
    "                    perm_df_ += perm_importance_df\n",
    "\n",
    "            # tree feature importance\n",
    "            f_i = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns), \n",
    "                                              reverse=True, key=lambda x: x[1]), \n",
    "                               columns=['Value','Feature'])\n",
    "\n",
    "            if feature_importances_.shape[0] == 0:\n",
    "                feature_importances_ = f_i.copy()\n",
    "            else:\n",
    "\n",
    "                feature_importances_['Value'] += f_i['Value']\n",
    "\n",
    "            # Boruta SHAP importance\n",
    "            if boruta:\n",
    "                model = BoostBoruta(clf, importance_type='shap_importances', train_importance=False)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "                          eval_metric=bll_metric, early_stopping_rounds=300, verbose=-1)\n",
    "\n",
    "                boruta_importance_df = pd.DataFrame({'importance': model.ranking_}, \n",
    "                                                     index=X_train.columns).sort_index()\n",
    "                if boruta_df_.shape[0] == 0:\n",
    "                    boruta_df_ = boruta_importance_df.copy()\n",
    "                else:\n",
    "                    boruta_df_ += boruta_importance_df\n",
    "\n",
    "        fold_cv_score = metric(y, oof)\n",
    "        print(f'{red} CV score: {res} {metric.__name__}: {red}{fold_cv_score:.5f}{res}')\n",
    "        print(f'{\"*\" * 50}\\n')\n",
    "        cv_scores.append(fold_cv_score)\n",
    "\n",
    "\n",
    "    print(f'{red} Avg score {CFG.n_feature_sel_folds}-fold: {res} {metric.__name__}: {red}{np.mean(cv_scores):.5f}{res}')\n",
    "    print(f'{\"*\" * 50}\\n')\n",
    "    \n",
    "    if permut:\n",
    "        perm_df_ = perm_df_.sort_values('importance', ascending=False)\n",
    "        \n",
    "    if boruta:\n",
    "        boruta_df_ = boruta_df_.sort_values('importance')\n",
    "                                    \n",
    "    feature_importances_ = feature_importances_.sort_values('Value', ascending=False)\n",
    "    \n",
    "    return perm_df_, feature_importances_, boruta_df_, np.mean(cv_scores)\n",
    "\n",
    "if CFG.feature_sel:\n",
    "    perm_df_, feature_importances_, boruta_df_, cv_scores = lgbm_tuning(features, permut=True, boruta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check features correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    col = 'BZ'\n",
    "    x = train_df[train_df[col] <= train_df[col].quantile(0.99)]\n",
    "    cm = x[[c for c in train_df.columns if c not in ['Id', 'Class']]].corr()\n",
    "    display(np.abs(cm[col]).sort_values(ascending=False)[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.619184Z",
     "iopub.status.busy": "2023-06-08T15:32:11.618864Z",
     "iopub.status.idle": "2023-06-08T15:32:11.652915Z",
     "shell.execute_reply": "2023-06-08T15:32:11.652069Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.619157Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    perm_df_.to_csv('perm_df.csv')\n",
    "    perm_df_\n",
    "    perm_cols = set(perm_df_.index[-35:])\n",
    "    display(perm_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze tree gain feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.654626Z",
     "iopub.status.busy": "2023-06-08T15:32:11.654102Z",
     "iopub.status.idle": "2023-06-08T15:32:11.669674Z",
     "shell.execute_reply": "2023-06-08T15:32:11.668840Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.654583Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    feature_importances_.to_csv('feature_importances.csv')\n",
    "    feature_importances_\n",
    "    fi_cols = set(feature_importances_['Feature'].values[-23:])\n",
    "    display(fi_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze BORUTA importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    boruta_df_.to_csv('boruta_df_.csv')\n",
    "    boruta_df_\n",
    "    boruta_cols = set(boruta_df_.index[-35:])\n",
    "    display(boruta_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:02:28,985] A new study created in memory with name: no-name-db028d3f-e91e-4bc3-ade8-236536363696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:02:29,600] Trial 0 finished with value: 0.49965681650138294 and parameters: {'learning_rate': 0.07906933291818274, 'lambda_l1': 0.001989888455156882, 'lambda_l2': 2.0723760652367593, 'max_depth': 7, 'num_leaves': 20, 'feature_fraction': 0.4828167486424254, 'min_data_in_leaf': 62, 'max_bin': 196, 'bagging_freq': 7}. Best is trial 0 with value: 0.49965681650138294.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:02:52,667] Trial 1 finished with value: 0.27814741444548524 and parameters: {'learning_rate': 0.0012806528579538878, 'lambda_l1': 0.0017365045520677783, 'lambda_l2': 0.01567699147322794, 'max_depth': 6, 'num_leaves': 65, 'feature_fraction': 0.502563255967824, 'min_data_in_leaf': 10, 'max_bin': 238, 'bagging_freq': 2}. Best is trial 1 with value: 0.27814741444548524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:03:06,119] Trial 2 finished with value: 0.5099391511790693 and parameters: {'learning_rate': 0.0002879373593635219, 'lambda_l1': 1.5092228233289338e-08, 'lambda_l2': 2.8693602992452835e-06, 'max_depth': 9, 'num_leaves': 73, 'feature_fraction': 0.6041250337128694, 'min_data_in_leaf': 58, 'max_bin': 51, 'bagging_freq': 5}. Best is trial 1 with value: 0.27814741444548524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:03:24,575] Trial 3 finished with value: 0.4183707717132086 and parameters: {'learning_rate': 0.0006149199595871085, 'lambda_l1': 0.19707870578262418, 'lambda_l2': 8.40212200294717, 'max_depth': 6, 'num_leaves': 98, 'feature_fraction': 0.49714127527990126, 'min_data_in_leaf': 7, 'max_bin': 252, 'bagging_freq': 2}. Best is trial 1 with value: 0.27814741444548524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:03:35,760] Trial 4 finished with value: 0.3339615200805843 and parameters: {'learning_rate': 0.0011937129012089189, 'lambda_l1': 2.200675605847001, 'lambda_l2': 0.009654968429581873, 'max_depth': 9, 'num_leaves': 18, 'feature_fraction': 0.42062692559341863, 'min_data_in_leaf': 32, 'max_bin': 178, 'bagging_freq': 3}. Best is trial 1 with value: 0.27814741444548524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:03:57,591] Trial 5 finished with value: 0.30129606593932434 and parameters: {'learning_rate': 0.0011315568184059532, 'lambda_l1': 9.785876277511028e-08, 'lambda_l2': 1.3009370817650137, 'max_depth': 8, 'num_leaves': 81, 'feature_fraction': 0.3816896686182208, 'min_data_in_leaf': 5, 'max_bin': 122, 'bagging_freq': 5}. Best is trial 1 with value: 0.27814741444548524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:04:07,812] Trial 6 finished with value: 0.7147617884824192 and parameters: {'learning_rate': 0.00012101249292157099, 'lambda_l1': 3.796804221200942e-07, 'lambda_l2': 5.2827387202222456, 'max_depth': 10, 'num_leaves': 39, 'feature_fraction': 0.4784551488964589, 'min_data_in_leaf': 92, 'max_bin': 214, 'bagging_freq': 7}. Best is trial 1 with value: 0.27814741444548524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:04:08,222] Trial 7 finished with value: 0.5000730920870845 and parameters: {'learning_rate': 0.10169821605264205, 'lambda_l1': 3.639475904385742e-05, 'lambda_l2': 4.686733341576237e-06, 'max_depth': 6, 'num_leaves': 13, 'feature_fraction': 0.6857709826824565, 'min_data_in_leaf': 75, 'max_bin': 158, 'bagging_freq': 3}. Best is trial 1 with value: 0.27814741444548524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:04:09,095] Trial 8 finished with value: 0.27514589273759643 and parameters: {'learning_rate': 0.25334394936414856, 'lambda_l1': 6.042004620583114, 'lambda_l2': 1.7489835010600366e-08, 'max_depth': 7, 'num_leaves': 79, 'feature_fraction': 0.6253435868745287, 'min_data_in_leaf': 14, 'max_bin': 185, 'bagging_freq': 5}. Best is trial 8 with value: 0.27514589273759643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#5\n",
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:04:11,972] Trial 9 finished with value: 0.5489060987123968 and parameters: {'learning_rate': 0.0013102688227352632, 'lambda_l1': 9.430752449475138e-06, 'lambda_l2': 7.972471595781077, 'max_depth': 5, 'num_leaves': 38, 'feature_fraction': 0.321950368195982, 'min_data_in_leaf': 70, 'max_bin': 85, 'bagging_freq': 2}. Best is trial 8 with value: 0.27514589273759643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:04:12,888] Trial 10 finished with value: 0.282242702849027 and parameters: {'learning_rate': 0.29183573743029234, 'lambda_l1': 8.5672159891328, 'lambda_l2': 1.1979621978893713e-08, 'max_depth': 4, 'num_leaves': 121, 'feature_fraction': 0.61886740001447, 'min_data_in_leaf': 35, 'max_bin': 126, 'bagging_freq': 5}. Best is trial 8 with value: 0.27514589273759643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#5\n",
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:04:19,835] Trial 11 finished with value: 0.25039049134828156 and parameters: {'learning_rate': 0.007046385658330884, 'lambda_l1': 0.008659911397482272, 'lambda_l2': 0.0028358408107179663, 'max_depth': 7, 'num_leaves': 54, 'feature_fraction': 0.5590904260350609, 'min_data_in_leaf': 25, 'max_bin': 251, 'bagging_freq': 1}. Best is trial 11 with value: 0.25039049134828156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:04:23,957] Trial 12 finished with value: 0.25227993453315195 and parameters: {'learning_rate': 0.012106189724857922, 'lambda_l1': 0.07575014484907294, 'lambda_l2': 1.3250765369904643e-08, 'max_depth': 7, 'num_leaves': 53, 'feature_fraction': 0.576922135385355, 'min_data_in_leaf': 30, 'max_bin': 220, 'bagging_freq': 1}. Best is trial 11 with value: 0.25039049134828156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:04:29,355] Trial 13 finished with value: 0.25845563065373384 and parameters: {'learning_rate': 0.009373052566228796, 'lambda_l1': 0.033691337312518, 'lambda_l2': 0.00011041888417875357, 'max_depth': 8, 'num_leaves': 51, 'feature_fraction': 0.5586720412601682, 'min_data_in_leaf': 34, 'max_bin': 226, 'bagging_freq': 1}. Best is trial 11 with value: 0.25039049134828156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:04:35,171] Trial 14 finished with value: 0.28034404037575833 and parameters: {'learning_rate': 0.00943349202206778, 'lambda_l1': 0.042616142142248604, 'lambda_l2': 2.3534113925598092e-07, 'max_depth': 8, 'num_leaves': 52, 'feature_fraction': 0.5569782581726411, 'min_data_in_leaf': 44, 'max_bin': 246, 'bagging_freq': 1}. Best is trial 11 with value: 0.25039049134828156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:04:43,657] Trial 15 finished with value: 0.2466055125983106 and parameters: {'learning_rate': 0.005584627811040631, 'lambda_l1': 0.001943816880631794, 'lambda_l2': 0.00035087960266660527, 'max_depth': 5, 'num_leaves': 95, 'feature_fraction': 0.6944144783064857, 'min_data_in_leaf': 22, 'max_bin': 205, 'bagging_freq': 1}. Best is trial 15 with value: 0.2466055125983106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:04:54,233] Trial 16 finished with value: 0.2499391523082534 and parameters: {'learning_rate': 0.003608666385713122, 'lambda_l1': 0.0005487093128872008, 'lambda_l2': 0.0007637338706483805, 'max_depth': 4, 'num_leaves': 101, 'feature_fraction': 0.6951070689052459, 'min_data_in_leaf': 24, 'max_bin': 157, 'bagging_freq': 3}. Best is trial 15 with value: 0.2466055125983106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:05,675] Trial 17 finished with value: 0.2503807279356199 and parameters: {'learning_rate': 0.002900358029835656, 'lambda_l1': 0.00018495306229110477, 'lambda_l2': 0.0002249977699683299, 'max_depth': 4, 'num_leaves': 107, 'feature_fraction': 0.6959495462005744, 'min_data_in_leaf': 21, 'max_bin': 151, 'bagging_freq': 3}. Best is trial 15 with value: 0.2466055125983106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:14,824] Trial 18 finished with value: 0.3004170665181307 and parameters: {'learning_rate': 0.003955941562404312, 'lambda_l1': 0.00032127891317584374, 'lambda_l2': 0.0010999884125362752, 'max_depth': 5, 'num_leaves': 96, 'feature_fraction': 0.660805217683043, 'min_data_in_leaf': 47, 'max_bin': 102, 'bagging_freq': 4}. Best is trial 15 with value: 0.2466055125983106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:16,994] Trial 19 finished with value: 0.24767547108082227 and parameters: {'learning_rate': 0.024257920963966877, 'lambda_l1': 2.9915217385024425e-06, 'lambda_l2': 0.08523486277872903, 'max_depth': 5, 'num_leaves': 119, 'feature_fraction': 0.6579654508735808, 'min_data_in_leaf': 17, 'max_bin': 171, 'bagging_freq': 4}. Best is trial 15 with value: 0.2466055125983106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:18,948] Trial 20 finished with value: 0.2417345990692169 and parameters: {'learning_rate': 0.03115832148651431, 'lambda_l1': 2.7599052817333434e-06, 'lambda_l2': 0.193316511485645, 'max_depth': 5, 'num_leaves': 124, 'feature_fraction': 0.6512907520771459, 'min_data_in_leaf': 17, 'max_bin': 199, 'bagging_freq': 6}. Best is trial 20 with value: 0.2417345990692169.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:21,330] Trial 21 finished with value: 0.241419566843604 and parameters: {'learning_rate': 0.025520335514170805, 'lambda_l1': 6.732623958319072e-06, 'lambda_l2': 0.11356555878541012, 'max_depth': 5, 'num_leaves': 119, 'feature_fraction': 0.6600710008633793, 'min_data_in_leaf': 17, 'max_bin': 200, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:24,262] Trial 22 finished with value: 0.26586993715335633 and parameters: {'learning_rate': 0.024091165085911942, 'lambda_l1': 2.776594812236007e-06, 'lambda_l2': 0.2325595826114667, 'max_depth': 5, 'num_leaves': 126, 'feature_fraction': 0.6485379320459093, 'min_data_in_leaf': 42, 'max_bin': 198, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:26,543] Trial 23 finished with value: 0.2446320810132492 and parameters: {'learning_rate': 0.025081103442285282, 'lambda_l1': 6.118503700940046e-05, 'lambda_l2': 0.17064760851916413, 'max_depth': 6, 'num_leaves': 110, 'feature_fraction': 0.6516263855956328, 'min_data_in_leaf': 17, 'max_bin': 206, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:28,773] Trial 24 finished with value: 0.24920902632807465 and parameters: {'learning_rate': 0.02732902778542917, 'lambda_l1': 4.022001066298414e-05, 'lambda_l2': 0.2510723005518528, 'max_depth': 6, 'num_leaves': 111, 'feature_fraction': 0.6518821462012448, 'min_data_in_leaf': 12, 'max_bin': 224, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:30,255] Trial 25 finished with value: 0.24326433264579886 and parameters: {'learning_rate': 0.04740320897901774, 'lambda_l1': 8.970117280205433e-07, 'lambda_l2': 0.06024815156597756, 'max_depth': 6, 'num_leaves': 113, 'feature_fraction': 0.6000566645582488, 'min_data_in_leaf': 17, 'max_bin': 184, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:32,045] Trial 26 finished with value: 0.25769573296913956 and parameters: {'learning_rate': 0.050722481337024894, 'lambda_l1': 8.142952845315064e-07, 'lambda_l2': 0.033031210665831146, 'max_depth': 4, 'num_leaves': 126, 'feature_fraction': 0.5929065046985512, 'min_data_in_leaf': 40, 'max_bin': 135, 'bagging_freq': 7}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:32,475] Trial 27 finished with value: 0.5143418230057014 and parameters: {'learning_rate': 0.046184771351361266, 'lambda_l1': 1.0838175196683928e-05, 'lambda_l2': 0.6501245493252571, 'max_depth': 5, 'num_leaves': 116, 'feature_fraction': 0.6125169064752783, 'min_data_in_leaf': 95, 'max_bin': 169, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:36,151] Trial 28 finished with value: 0.29372555138416273 and parameters: {'learning_rate': 0.016566225411923235, 'lambda_l1': 1.3487347180302067e-07, 'lambda_l2': 0.06896188337212365, 'max_depth': 6, 'num_leaves': 90, 'feature_fraction': 0.6187738291420841, 'min_data_in_leaf': 52, 'max_bin': 189, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:37,231] Trial 29 finished with value: 0.2515972755689028 and parameters: {'learning_rate': 0.09608194525930362, 'lambda_l1': 1.6798815723446787e-06, 'lambda_l2': 1.052154570502152, 'max_depth': 5, 'num_leaves': 87, 'feature_fraction': 0.5873097650146134, 'min_data_in_leaf': 26, 'max_bin': 194, 'bagging_freq': 7}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:37,681] Trial 30 finished with value: 0.4948610262829882 and parameters: {'learning_rate': 0.03890595906798415, 'lambda_l1': 7.409048685621379e-06, 'lambda_l2': 0.006693269312919532, 'max_depth': 4, 'num_leaves': 127, 'feature_fraction': 0.6327113357209792, 'min_data_in_leaf': 81, 'max_bin': 172, 'bagging_freq': 7}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:40,895] Trial 31 finished with value: 0.241802667769404 and parameters: {'learning_rate': 0.015566417534460317, 'lambda_l1': 4.7587223832251315e-05, 'lambda_l2': 0.2345502702676608, 'max_depth': 6, 'num_leaves': 106, 'feature_fraction': 0.6699652567868676, 'min_data_in_leaf': 19, 'max_bin': 203, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:43,884] Trial 32 finished with value: 0.24708589623870136 and parameters: {'learning_rate': 0.015394369333611017, 'lambda_l1': 5.175026603287482e-07, 'lambda_l2': 0.032821754097757554, 'max_depth': 6, 'num_leaves': 105, 'feature_fraction': 0.671204840344519, 'min_data_in_leaf': 14, 'max_bin': 234, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:45,784] Trial 33 finished with value: 0.24581984200717252 and parameters: {'learning_rate': 0.06269660465343402, 'lambda_l1': 1.5794646924596976e-05, 'lambda_l2': 0.543344063360171, 'max_depth': 6, 'num_leaves': 116, 'feature_fraction': 0.6744278941003758, 'min_data_in_leaf': 9, 'max_bin': 208, 'bagging_freq': 5}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:50,161] Trial 34 finished with value: 0.24843304691800852 and parameters: {'learning_rate': 0.01682704442260625, 'lambda_l1': 0.00010312402390435548, 'lambda_l2': 2.8757469144006054, 'max_depth': 5, 'num_leaves': 4, 'feature_fraction': 0.6379567296939681, 'min_data_in_leaf': 18, 'max_bin': 42, 'bagging_freq': 5}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:53,028] Trial 35 finished with value: 0.2716781893773859 and parameters: {'learning_rate': 0.03342183891751386, 'lambda_l1': 4.7361173425348664e-06, 'lambda_l2': 0.027545970251611634, 'max_depth': 7, 'num_leaves': 113, 'feature_fraction': 0.6758813966733566, 'min_data_in_leaf': 5, 'max_bin': 185, 'bagging_freq': 7}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:54,647] Trial 36 finished with value: 0.25347944383441207 and parameters: {'learning_rate': 0.07552601248180542, 'lambda_l1': 2.0453670610603746e-05, 'lambda_l2': 1.5323762851018146, 'max_depth': 6, 'num_leaves': 102, 'feature_fraction': 0.6044805730242337, 'min_data_in_leaf': 29, 'max_bin': 231, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:55,809] Trial 37 finished with value: 0.2567514161930327 and parameters: {'learning_rate': 0.12910708442943838, 'lambda_l1': 3.0071713119848046e-08, 'lambda_l2': 0.009074567860366749, 'max_depth': 6, 'num_leaves': 71, 'feature_fraction': 0.6385982059388345, 'min_data_in_leaf': 37, 'max_bin': 198, 'bagging_freq': 5}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:57,962] Trial 38 finished with value: 0.30406744259681456 and parameters: {'learning_rate': 0.04478997055305725, 'lambda_l1': 1.2403491370396236e-06, 'lambda_l2': 0.11265289273457965, 'max_depth': 7, 'num_leaves': 88, 'feature_fraction': 0.6719576173457614, 'min_data_in_leaf': 56, 'max_bin': 216, 'bagging_freq': 7}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:05:59,424] Trial 39 finished with value: 0.2512385887452328 and parameters: {'learning_rate': 0.148172925103164, 'lambda_l1': 2.46124260326694e-07, 'lambda_l2': 0.42915254242531153, 'max_depth': 10, 'num_leaves': 118, 'feature_fraction': 0.5375331719969222, 'min_data_in_leaf': 10, 'max_bin': 178, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:00,014] Trial 40 finished with value: 0.49904274148390726 and parameters: {'learning_rate': 0.06616681400702087, 'lambda_l1': 9.042725033223983e-07, 'lambda_l2': 3.1346059281297527, 'max_depth': 5, 'num_leaves': 107, 'feature_fraction': 0.6320578037746679, 'min_data_in_leaf': 65, 'max_bin': 149, 'bagging_freq': 4}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:04,255] Trial 41 finished with value: 0.2446843446605019 and parameters: {'learning_rate': 0.02130743458645497, 'lambda_l1': 3.939864005722843e-06, 'lambda_l2': 0.18713887954801398, 'max_depth': 6, 'num_leaves': 111, 'feature_fraction': 0.6513430545581632, 'min_data_in_leaf': 17, 'max_bin': 207, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:06,439] Trial 42 finished with value: 0.24552632116752324 and parameters: {'learning_rate': 0.03610042366144901, 'lambda_l1': 4.735151052726937e-05, 'lambda_l2': 0.10918359476145036, 'max_depth': 6, 'num_leaves': 124, 'feature_fraction': 0.6047061526415175, 'min_data_in_leaf': 20, 'max_bin': 242, 'bagging_freq': 5}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:09,041] Trial 43 finished with value: 0.24808542726442334 and parameters: {'learning_rate': 0.02891493313631947, 'lambda_l1': 8.319807815808737e-05, 'lambda_l2': 1.1364280293909055, 'max_depth': 6, 'num_leaves': 110, 'feature_fraction': 0.6614619058901287, 'min_data_in_leaf': 13, 'max_bin': 212, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:13,502] Trial 44 finished with value: 0.24839119321942235 and parameters: {'learning_rate': 0.012620906683126919, 'lambda_l1': 2.6640945700174166e-05, 'lambda_l2': 0.047924280437551633, 'max_depth': 5, 'num_leaves': 119, 'feature_fraction': 0.6841519118018895, 'min_data_in_leaf': 28, 'max_bin': 161, 'bagging_freq': 7}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:16,385] Trial 45 finished with value: 0.2539635844534117 and parameters: {'learning_rate': 0.020310044336253937, 'lambda_l1': 1.925620814974944e-05, 'lambda_l2': 0.019566319570564435, 'max_depth': 7, 'num_leaves': 79, 'feature_fraction': 0.6220300108507335, 'min_data_in_leaf': 8, 'max_bin': 181, 'bagging_freq': 5}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:18,056] Trial 46 finished with value: 0.2515683080972927 and parameters: {'learning_rate': 0.05753336791477601, 'lambda_l1': 0.0006122779037583482, 'lambda_l2': 0.3446944294212586, 'max_depth': 6, 'num_leaves': 99, 'feature_fraction': 0.6439364541864496, 'min_data_in_leaf': 32, 'max_bin': 201, 'bagging_freq': 6}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:23,773] Trial 47 finished with value: 0.24616196887706307 and parameters: {'learning_rate': 0.0098772317247572, 'lambda_l1': 7.606557585715118e-06, 'lambda_l2': 2.912380743926129, 'max_depth': 7, 'num_leaves': 31, 'feature_fraction': 0.6807148947315158, 'min_data_in_leaf': 16, 'max_bin': 75, 'bagging_freq': 5}. Best is trial 21 with value: 0.241419566843604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:25,718] Trial 48 finished with value: 0.24035558909872287 and parameters: {'learning_rate': 0.03520872796164619, 'lambda_l1': 3.5318747692516025e-07, 'lambda_l2': 0.14497768651685086, 'max_depth': 5, 'num_leaves': 92, 'feature_fraction': 0.6223097317437103, 'min_data_in_leaf': 23, 'max_bin': 191, 'bagging_freq': 6}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:27,507] Trial 49 finished with value: 0.2457914556911992 and parameters: {'learning_rate': 0.035639276374668676, 'lambda_l1': 2.9711465326044255e-07, 'lambda_l2': 0.011352522384165625, 'max_depth': 4, 'num_leaves': 60, 'feature_fraction': 0.5874196642241447, 'min_data_in_leaf': 22, 'max_bin': 189, 'bagging_freq': 7}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:33,182] Trial 50 finished with value: 0.24842471564206955 and parameters: {'learning_rate': 0.013855288300433638, 'lambda_l1': 6.748476994272452e-08, 'lambda_l2': 7.077864065027542, 'max_depth': 5, 'num_leaves': 122, 'feature_fraction': 0.6232289164848047, 'min_data_in_leaf': 25, 'max_bin': 164, 'bagging_freq': 6}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:35,376] Trial 51 finished with value: 0.2491273092913065 and parameters: {'learning_rate': 0.027336712140936397, 'lambda_l1': 1.2163613940698923e-06, 'lambda_l2': 0.14506025610112983, 'max_depth': 5, 'num_leaves': 93, 'feature_fraction': 0.6594627261090046, 'min_data_in_leaf': 12, 'max_bin': 219, 'bagging_freq': 6}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:38,700] Trial 52 finished with value: 0.26907492568018726 and parameters: {'learning_rate': 0.01833128550124184, 'lambda_l1': 1.7958183181910366e-06, 'lambda_l2': 0.06134734071330732, 'max_depth': 6, 'num_leaves': 104, 'feature_fraction': 0.698082201435103, 'min_data_in_leaf': 5, 'max_bin': 193, 'bagging_freq': 6}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:40,304] Trial 53 finished with value: 0.2446865136182047 and parameters: {'learning_rate': 0.05070325005840153, 'lambda_l1': 5.831851569375922e-06, 'lambda_l2': 0.4833516030761883, 'max_depth': 5, 'num_leaves': 113, 'feature_fraction': 0.643338193099779, 'min_data_in_leaf': 20, 'max_bin': 180, 'bagging_freq': 5}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:47,230] Trial 54 finished with value: 0.2537823634557581 and parameters: {'learning_rate': 0.00750548075557905, 'lambda_l1': 4.58417329189249e-07, 'lambda_l2': 0.19271125794075092, 'max_depth': 9, 'num_leaves': 98, 'feature_fraction': 0.6122209300120485, 'min_data_in_leaf': 31, 'max_bin': 230, 'bagging_freq': 7}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:49,793] Trial 55 finished with value: 0.24288545230185168 and parameters: {'learning_rate': 0.021771655971415383, 'lambda_l1': 2.477901101854827e-06, 'lambda_l2': 1.0078776124274524, 'max_depth': 4, 'num_leaves': 122, 'feature_fraction': 0.6282459922965978, 'min_data_in_leaf': 24, 'max_bin': 205, 'bagging_freq': 6}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:51,041] Trial 56 finished with value: 0.25691695003363335 and parameters: {'learning_rate': 0.08092841869820683, 'lambda_l1': 3.183619647757471e-06, 'lambda_l2': 0.9459371664089948, 'max_depth': 4, 'num_leaves': 122, 'feature_fraction': 0.5749487267803233, 'min_data_in_leaf': 37, 'max_bin': 139, 'bagging_freq': 5}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#5\n",
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:55,574] Trial 57 finished with value: 0.24864905412759775 and parameters: {'learning_rate': 0.011710246033806613, 'lambda_l1': 6.126878121583463e-07, 'lambda_l2': 1.6772426288099704, 'max_depth': 4, 'num_leaves': 84, 'feature_fraction': 0.6311802843037728, 'min_data_in_leaf': 28, 'max_bin': 213, 'bagging_freq': 6}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:56,091] Trial 58 finished with value: 0.5033544593615914 and parameters: {'learning_rate': 0.0204323461147558, 'lambda_l1': 1.4603776408712162e-07, 'lambda_l2': 0.004425914440571807, 'max_depth': 4, 'num_leaves': 127, 'feature_fraction': 0.6092426130296925, 'min_data_in_leaf': 86, 'max_bin': 198, 'bagging_freq': 2}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:06:58,405] Trial 59 finished with value: 0.24726644995270827 and parameters: {'learning_rate': 0.03256780712745667, 'lambda_l1': 2.071173034318759e-06, 'lambda_l2': 5.034989587654178, 'max_depth': 5, 'num_leaves': 128, 'feature_fraction': 0.6645941140557208, 'min_data_in_leaf': 21, 'max_bin': 250, 'bagging_freq': 7}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:00,027] Trial 60 finished with value: 0.24143609000344254 and parameters: {'learning_rate': 0.04465956948588482, 'lambda_l1': 2.993300590279812e-07, 'lambda_l2': 0.06320190678095748, 'max_depth': 4, 'num_leaves': 117, 'feature_fraction': 0.6832604997656961, 'min_data_in_leaf': 25, 'max_bin': 222, 'bagging_freq': 4}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:01,691] Trial 61 finished with value: 0.24080944301533563 and parameters: {'learning_rate': 0.04194451087791019, 'lambda_l1': 3.387348705929449e-07, 'lambda_l2': 0.01942147437414727, 'max_depth': 4, 'num_leaves': 116, 'feature_fraction': 0.6887819528839589, 'min_data_in_leaf': 24, 'max_bin': 221, 'bagging_freq': 4}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:03,381] Trial 62 finished with value: 0.2447354931738167 and parameters: {'learning_rate': 0.040054191885776434, 'lambda_l1': 2.3572209483023167e-07, 'lambda_l2': 0.014427876179324456, 'max_depth': 4, 'num_leaves': 116, 'feature_fraction': 0.6876141449951076, 'min_data_in_leaf': 24, 'max_bin': 226, 'bagging_freq': 4}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:05,865] Trial 63 finished with value: 0.24871172078079876 and parameters: {'learning_rate': 0.027646001020836426, 'lambda_l1': 5.5290457340189976e-08, 'lambda_l2': 0.24261011401856575, 'max_depth': 4, 'num_leaves': 120, 'feature_fraction': 0.6839873495976422, 'min_data_in_leaf': 33, 'max_bin': 240, 'bagging_freq': 3}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:08,424] Trial 64 finished with value: 0.24587197728821636 and parameters: {'learning_rate': 0.021710037445458224, 'lambda_l1': 1.4838568817945744e-08, 'lambda_l2': 0.08190160161976241, 'max_depth': 4, 'num_leaves': 107, 'feature_fraction': 0.695494395311244, 'min_data_in_leaf': 24, 'max_bin': 222, 'bagging_freq': 4}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:10,145] Trial 65 finished with value: 0.2532606468304052 and parameters: {'learning_rate': 0.0440707633750119, 'lambda_l1': 5.040594839627543e-07, 'lambda_l2': 0.6604015256930696, 'max_depth': 4, 'num_leaves': 122, 'feature_fraction': 0.6609514372767316, 'min_data_in_leaf': 36, 'max_bin': 236, 'bagging_freq': 4}. Best is trial 48 with value: 0.24035558909872287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:13,307] Trial 66 finished with value: 0.2398050865348944 and parameters: {'learning_rate': 0.01581136630572977, 'lambda_l1': 1.048600407770766e-05, 'lambda_l2': 0.024808604385268718, 'max_depth': 4, 'num_leaves': 116, 'feature_fraction': 0.6753600850388041, 'min_data_in_leaf': 14, 'max_bin': 204, 'bagging_freq': 3}. Best is trial 66 with value: 0.2398050865348944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:14,654] Trial 67 finished with value: 0.2436959137481855 and parameters: {'learning_rate': 0.05866705765143581, 'lambda_l1': 1.0491566073500405e-05, 'lambda_l2': 0.020871268605805578, 'max_depth': 5, 'num_leaves': 115, 'feature_fraction': 0.6724906112104307, 'min_data_in_leaf': 14, 'max_bin': 217, 'bagging_freq': 3}. Best is trial 66 with value: 0.2398050865348944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:17,575] Trial 68 finished with value: 0.24430123991356237 and parameters: {'learning_rate': 0.017362241985367417, 'lambda_l1': 1.4664827556203857e-07, 'lambda_l2': 0.03275138547080315, 'max_depth': 5, 'num_leaves': 108, 'feature_fraction': 0.6996648906432232, 'min_data_in_leaf': 11, 'max_bin': 110, 'bagging_freq': 2}. Best is trial 66 with value: 0.2398050865348944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:20,994] Trial 69 finished with value: 0.24186355130260662 and parameters: {'learning_rate': 0.013794284265299913, 'lambda_l1': 4.975720463379651e-06, 'lambda_l2': 0.002842563709547889, 'max_depth': 4, 'num_leaves': 102, 'feature_fraction': 0.6510042570960585, 'min_data_in_leaf': 19, 'max_bin': 191, 'bagging_freq': 3}. Best is trial 66 with value: 0.2398050865348944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:22,989] Trial 70 finished with value: 0.2505198351787107 and parameters: {'learning_rate': 0.030395533604641166, 'lambda_l1': 2.9697731352149266e-05, 'lambda_l2': 0.046381975141049255, 'max_depth': 5, 'num_leaves': 74, 'feature_fraction': 0.6837527706147798, 'min_data_in_leaf': 27, 'max_bin': 211, 'bagging_freq': 3}. Best is trial 66 with value: 0.2398050865348944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:26,456] Trial 71 finished with value: 0.239247557021549 and parameters: {'learning_rate': 0.014362062844715685, 'lambda_l1': 1.2521069822475656e-05, 'lambda_l2': 0.004400882706723021, 'max_depth': 4, 'num_leaves': 103, 'feature_fraction': 0.6510034260212366, 'min_data_in_leaf': 15, 'max_bin': 189, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:31,038] Trial 72 finished with value: 0.24249551073737327 and parameters: {'learning_rate': 0.00860033398754586, 'lambda_l1': 1.7116246477673886e-05, 'lambda_l2': 0.015202270609073438, 'max_depth': 4, 'num_leaves': 92, 'feature_fraction': 0.6706419589538628, 'min_data_in_leaf': 15, 'max_bin': 175, 'bagging_freq': 4}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:34,266] Trial 73 finished with value: 0.24512908804124772 and parameters: {'learning_rate': 0.015595557142736569, 'lambda_l1': 1.1760143589848339e-05, 'lambda_l2': 0.005645821406860304, 'max_depth': 4, 'num_leaves': 96, 'feature_fraction': 0.6434319732240769, 'min_data_in_leaf': 10, 'max_bin': 199, 'bagging_freq': 2}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:38,809] Trial 74 finished with value: 0.2422773638398908 and parameters: {'learning_rate': 0.010778673888118059, 'lambda_l1': 1.0982471416336293e-06, 'lambda_l2': 0.13469474003702425, 'max_depth': 5, 'num_leaves': 103, 'feature_fraction': 0.6654066745614893, 'min_data_in_leaf': 22, 'max_bin': 203, 'bagging_freq': 4}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:47,151] Trial 75 finished with value: 0.24416345939883394 and parameters: {'learning_rate': 0.0055480486771133436, 'lambda_l1': 6.451707828691003e-06, 'lambda_l2': 0.03499179214269106, 'max_depth': 4, 'num_leaves': 117, 'feature_fraction': 0.652838565713039, 'min_data_in_leaf': 19, 'max_bin': 225, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:49,033] Trial 76 finished with value: 0.25929019964714173 and parameters: {'learning_rate': 0.036729489434709085, 'lambda_l1': 4.680557164864571e-05, 'lambda_l2': 0.08314126732963877, 'max_depth': 5, 'num_leaves': 112, 'feature_fraction': 0.6879566904986528, 'min_data_in_leaf': 7, 'max_bin': 168, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:55,080] Trial 77 finished with value: 0.24317106943460354 and parameters: {'learning_rate': 0.007100647920515475, 'lambda_l1': 1.4697204372573256e-06, 'lambda_l2': 0.00992267007266982, 'max_depth': 4, 'num_leaves': 108, 'feature_fraction': 0.6756019427052964, 'min_data_in_leaf': 16, 'max_bin': 193, 'bagging_freq': 4}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:07:57,605] Trial 78 finished with value: 0.2743582132889884 and parameters: {'learning_rate': 0.02707923956289102, 'lambda_l1': 0.00013176782852192766, 'lambda_l2': 0.36064868668362804, 'max_depth': 4, 'num_leaves': 115, 'feature_fraction': 0.639682913337767, 'min_data_in_leaf': 45, 'max_bin': 186, 'bagging_freq': 2}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:01,123] Trial 79 finished with value: 0.25039494213718966 and parameters: {'learning_rate': 0.013406257770727032, 'lambda_l1': 2.286868019900746e-06, 'lambda_l2': 0.055541937452678235, 'max_depth': 8, 'num_leaves': 99, 'feature_fraction': 0.6565519245649561, 'min_data_in_leaf': 13, 'max_bin': 212, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:03,793] Trial 80 finished with value: 0.2593006164127166 and parameters: {'learning_rate': 0.024189337086602005, 'lambda_l1': 3.41408646195875e-06, 'lambda_l2': 0.02110066109205018, 'max_depth': 5, 'num_leaves': 105, 'feature_fraction': 0.6882891055903569, 'min_data_in_leaf': 7, 'max_bin': 229, 'bagging_freq': 4}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:06,940] Trial 81 finished with value: 0.2418264503260385 and parameters: {'learning_rate': 0.015281845532242572, 'lambda_l1': 4.532981851407892e-06, 'lambda_l2': 0.0036492519988774977, 'max_depth': 4, 'num_leaves': 101, 'feature_fraction': 0.6497429672019807, 'min_data_in_leaf': 19, 'max_bin': 189, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:09,669] Trial 82 finished with value: 0.24156471515325026 and parameters: {'learning_rate': 0.01763810630563021, 'lambda_l1': 6.809637293576118e-07, 'lambda_l2': 0.002685052888771702, 'max_depth': 4, 'num_leaves': 124, 'feature_fraction': 0.6668305977398181, 'min_data_in_leaf': 18, 'max_bin': 203, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:11,482] Trial 83 finished with value: 0.24581112466017094 and parameters: {'learning_rate': 0.043519612232748875, 'lambda_l1': 7.241768763747473e-07, 'lambda_l2': 0.001948231321962992, 'max_depth': 4, 'num_leaves': 126, 'feature_fraction': 0.6674806814188506, 'min_data_in_leaf': 30, 'max_bin': 206, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:14,132] Trial 84 finished with value: 0.24189763926728441 and parameters: {'learning_rate': 0.019190102416631605, 'lambda_l1': 3.684414581186844e-07, 'lambda_l2': 0.11647013816895742, 'max_depth': 4, 'num_leaves': 124, 'feature_fraction': 0.6777793871872468, 'min_data_in_leaf': 22, 'max_bin': 216, 'bagging_freq': 2}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:16,105] Trial 85 finished with value: 0.24937325823337192 and parameters: {'learning_rate': 0.029500451769292002, 'lambda_l1': 1.3722692771839372e-05, 'lambda_l2': 0.007402028410752022, 'max_depth': 4, 'num_leaves': 118, 'feature_fraction': 0.6321180909040626, 'min_data_in_leaf': 10, 'max_bin': 198, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:17,536] Trial 86 finished with value: 0.24552930374563733 and parameters: {'learning_rate': 0.050972010070785424, 'lambda_l1': 8.21998156964178e-07, 'lambda_l2': 0.30791988298309897, 'max_depth': 5, 'num_leaves': 109, 'feature_fraction': 0.6638700591025314, 'min_data_in_leaf': 17, 'max_bin': 209, 'bagging_freq': 4}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:21,298] Trial 87 finished with value: 0.24088358118861486 and parameters: {'learning_rate': 0.011123288542803256, 'lambda_l1': 2.713504974185273e-05, 'lambda_l2': 0.0014885660933872972, 'max_depth': 4, 'num_leaves': 124, 'feature_fraction': 0.6771566436276552, 'min_data_in_leaf': 15, 'max_bin': 221, 'bagging_freq': 5}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:23,774] Trial 88 finished with value: 0.2410488985604586 and parameters: {'learning_rate': 0.02405273171087351, 'lambda_l1': 1.4127053999045908e-06, 'lambda_l2': 0.0011597405783604956, 'max_depth': 4, 'num_leaves': 124, 'feature_fraction': 0.6796631846120772, 'min_data_in_leaf': 14, 'max_bin': 221, 'bagging_freq': 5}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:27,547] Trial 89 finished with value: 0.24311018622768907 and parameters: {'learning_rate': 0.011241604982706793, 'lambda_l1': 2.534611791155461e-07, 'lambda_l2': 0.0010530838465676712, 'max_depth': 4, 'num_leaves': 120, 'feature_fraction': 0.6926330209991901, 'min_data_in_leaf': 14, 'max_bin': 246, 'bagging_freq': 5}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:32,998] Trial 90 finished with value: 0.24667858561232764 and parameters: {'learning_rate': 0.008498316727814594, 'lambda_l1': 1.669202701222904e-06, 'lambda_l2': 0.0004743348744664685, 'max_depth': 4, 'num_leaves': 124, 'feature_fraction': 0.6792436084777799, 'min_data_in_leaf': 26, 'max_bin': 233, 'bagging_freq': 4}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:35,722] Trial 91 finished with value: 0.2471281364968726 and parameters: {'learning_rate': 0.01872547341228629, 'lambda_l1': 8.789433621722173e-06, 'lambda_l2': 0.001589520945024193, 'max_depth': 4, 'num_leaves': 124, 'feature_fraction': 0.6987346940434898, 'min_data_in_leaf': 12, 'max_bin': 222, 'bagging_freq': 5}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:37,950] Trial 92 finished with value: 0.24381026368303776 and parameters: {'learning_rate': 0.024336483212370433, 'lambda_l1': 2.6357819711701787e-05, 'lambda_l2': 0.00596254550168809, 'max_depth': 4, 'num_leaves': 128, 'feature_fraction': 0.6594115707667141, 'min_data_in_leaf': 16, 'max_bin': 238, 'bagging_freq': 5}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:39,885] Trial 93 finished with value: 0.24427305204520924 and parameters: {'learning_rate': 0.03848952380104193, 'lambda_l1': 3.2046452800530155e-06, 'lambda_l2': 0.0023729196481560096, 'max_depth': 4, 'num_leaves': 114, 'feature_fraction': 0.6791813399987174, 'min_data_in_leaf': 23, 'max_bin': 219, 'bagging_freq': 4}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:41,770] Trial 94 finished with value: 0.2525812485699178 and parameters: {'learning_rate': 0.03298341527381571, 'lambda_l1': 1.1563207724924917e-06, 'lambda_l2': 0.0042100478126033455, 'max_depth': 4, 'num_leaves': 118, 'feature_fraction': 0.6450504342873096, 'min_data_in_leaf': 8, 'max_bin': 227, 'bagging_freq': 5}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:44,130] Trial 95 finished with value: 0.24296034847698753 and parameters: {'learning_rate': 0.023131711604451526, 'lambda_l1': 5.185264275023022e-07, 'lambda_l2': 0.011219130461194436, 'max_depth': 4, 'num_leaves': 111, 'feature_fraction': 0.6200341950475382, 'min_data_in_leaf': 18, 'max_bin': 203, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:44,798] Trial 96 finished with value: 0.4872779162591763 and parameters: {'learning_rate': 0.01215106622996868, 'lambda_l1': 6.795439430887983e-06, 'lambda_l2': 0.0008038483000231404, 'max_depth': 4, 'num_leaves': 121, 'feature_fraction': 0.6900335306435839, 'min_data_in_leaf': 71, 'max_bin': 195, 'bagging_freq': 6}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#5\n",
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:47,944] Trial 97 finished with value: 0.28947548781458854 and parameters: {'learning_rate': 0.017785943337204013, 'lambda_l1': 2.1937982016631732e-06, 'lambda_l2': 0.0014589084597490776, 'max_depth': 5, 'num_leaves': 125, 'feature_fraction': 0.6685664407449988, 'min_data_in_leaf': 50, 'max_bin': 185, 'bagging_freq': 4}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:52,445] Trial 98 finished with value: 0.24339184431964436 and parameters: {'learning_rate': 0.009921742230011408, 'lambda_l1': 3.535656193744476e-07, 'lambda_l2': 0.024514504704631655, 'max_depth': 4, 'num_leaves': 119, 'feature_fraction': 0.6538889784581418, 'min_data_in_leaf': 21, 'max_bin': 211, 'bagging_freq': 6}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:54,316] Trial 99 finished with value: 0.24423814310425496 and parameters: {'learning_rate': 0.03252928743825666, 'lambda_l1': 8.656113124575204e-07, 'lambda_l2': 0.0030699977229283444, 'max_depth': 4, 'num_leaves': 113, 'feature_fraction': 0.6376044746719755, 'min_data_in_leaf': 15, 'max_bin': 254, 'bagging_freq': 5}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:08:56,427] Trial 100 finished with value: 0.24728329296542048 and parameters: {'learning_rate': 0.027211338197376596, 'lambda_l1': 4.1815584241245535e-06, 'lambda_l2': 0.014308602868735209, 'max_depth': 5, 'num_leaves': 116, 'feature_fraction': 0.6800029482609999, 'min_data_in_leaf': 12, 'max_bin': 243, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:01,449] Trial 101 finished with value: 0.2435373408708808 and parameters: {'learning_rate': 0.015610000420725561, 'lambda_l1': 6.558467153057115e-05, 'lambda_l2': 0.1846826995668235, 'max_depth': 5, 'num_leaves': 47, 'feature_fraction': 0.6704485412595361, 'min_data_in_leaf': 19, 'max_bin': 202, 'bagging_freq': 6}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:04,961] Trial 102 finished with value: 0.2477501001479552 and parameters: {'learning_rate': 0.020621030087479075, 'lambda_l1': 3.342052449167477e-05, 'lambda_l2': 0.04566460648572659, 'max_depth': 4, 'num_leaves': 122, 'feature_fraction': 0.6637151696330128, 'min_data_in_leaf': 26, 'max_bin': 216, 'bagging_freq': 6}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:10,319] Trial 103 finished with value: 0.26529417248035025 and parameters: {'learning_rate': 0.014153119031274057, 'lambda_l1': 1.7031952587559167e-05, 'lambda_l2': 0.11704155572826998, 'max_depth': 5, 'num_leaves': 125, 'feature_fraction': 0.647973559616001, 'min_data_in_leaf': 5, 'max_bin': 208, 'bagging_freq': 6}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:12,180] Trial 104 finished with value: 0.2438572920360185 and parameters: {'learning_rate': 0.03880847931142563, 'lambda_l1': 1.0212211985143135e-05, 'lambda_l2': 0.07376883074251248, 'max_depth': 4, 'num_leaves': 106, 'feature_fraction': 0.6885572717619763, 'min_data_in_leaf': 14, 'max_bin': 222, 'bagging_freq': 6}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:14,875] Trial 105 finished with value: 0.261680282783283 and parameters: {'learning_rate': 0.024246094617019265, 'lambda_l1': 2.1945237319844156e-05, 'lambda_l2': 0.007361256164641807, 'max_depth': 5, 'num_leaves': 128, 'feature_fraction': 0.6744236956959895, 'min_data_in_leaf': 40, 'max_bin': 182, 'bagging_freq': 5}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:18,033] Trial 106 finished with value: 0.3115226206225919 and parameters: {'learning_rate': 0.017335465696961906, 'lambda_l1': 1.7694436311359958e-07, 'lambda_l2': 0.036372148037603635, 'max_depth': 4, 'num_leaves': 110, 'feature_fraction': 0.6561440534982974, 'min_data_in_leaf': 60, 'max_bin': 195, 'bagging_freq': 6}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:19,413] Trial 107 finished with value: 0.2495589713870325 and parameters: {'learning_rate': 0.051069547098764975, 'lambda_l1': 9.258441918587589e-08, 'lambda_l2': 0.2851824780630029, 'max_depth': 6, 'num_leaves': 117, 'feature_fraction': 0.6914601187494042, 'min_data_in_leaf': 20, 'max_bin': 174, 'bagging_freq': 4}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:23,801] Trial 108 finished with value: 0.24298802388379448 and parameters: {'learning_rate': 0.010995920534688583, 'lambda_l1': 5.804329983138875e-07, 'lambda_l2': 0.024942303044526694, 'max_depth': 4, 'num_leaves': 120, 'feature_fraction': 0.6822100221487026, 'min_data_in_leaf': 23, 'max_bin': 233, 'bagging_freq': 5}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:28,464] Trial 109 finished with value: 0.24524681402087908 and parameters: {'learning_rate': 0.01242361097145083, 'lambda_l1': 1.5979139205563745e-06, 'lambda_l2': 0.09025334486500015, 'max_depth': 5, 'num_leaves': 113, 'feature_fraction': 0.6359532353847085, 'min_data_in_leaf': 17, 'max_bin': 214, 'bagging_freq': 7}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:28,986] Trial 110 finished with value: 0.5025669293276879 and parameters: {'learning_rate': 0.021445870450425134, 'lambda_l1': 4.348394727516872e-05, 'lambda_l2': 0.1775592313762776, 'max_depth': 4, 'num_leaves': 24, 'feature_fraction': 0.658264126383429, 'min_data_in_leaf': 100, 'max_bin': 201, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:33,050] Trial 111 finished with value: 0.24414651992469252 and parameters: {'learning_rate': 0.015220597645721942, 'lambda_l1': 4.909859386567531e-06, 'lambda_l2': 0.003787337131989526, 'max_depth': 4, 'num_leaves': 103, 'feature_fraction': 0.6273763264847476, 'min_data_in_leaf': 19, 'max_bin': 191, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:35,434] Trial 112 finished with value: 0.24605568899261104 and parameters: {'learning_rate': 0.030510605280675795, 'lambda_l1': 7.181729799309239e-06, 'lambda_l2': 0.0021504690273174564, 'max_depth': 4, 'num_leaves': 96, 'feature_fraction': 0.6453613357223993, 'min_data_in_leaf': 28, 'max_bin': 188, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:39,225] Trial 113 finished with value: 0.2413915441435189 and parameters: {'learning_rate': 0.016908711769790148, 'lambda_l1': 2.687540557355371e-06, 'lambda_l2': 0.0004929037451730821, 'max_depth': 4, 'num_leaves': 100, 'feature_fraction': 0.665639885512378, 'min_data_in_leaf': 11, 'max_bin': 68, 'bagging_freq': 3}. Best is trial 71 with value: 0.239247557021549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:42,132] Trial 114 finished with value: 0.23885453797726744 and parameters: {'learning_rate': 0.01857299601451916, 'lambda_l1': 2.3402625593004643e-06, 'lambda_l2': 0.00018067261938641306, 'max_depth': 4, 'num_leaves': 93, 'feature_fraction': 0.669130005630527, 'min_data_in_leaf': 11, 'max_bin': 35, 'bagging_freq': 4}. Best is trial 114 with value: 0.23885453797726744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:44,629] Trial 115 finished with value: 0.24389878580188376 and parameters: {'learning_rate': 0.025619671361019693, 'lambda_l1': 2.078545245726449e-06, 'lambda_l2': 9.576359194082646e-05, 'max_depth': 4, 'num_leaves': 85, 'feature_fraction': 0.6682226999376664, 'min_data_in_leaf': 9, 'max_bin': 70, 'bagging_freq': 4}. Best is trial 114 with value: 0.23885453797726744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:47,779] Trial 116 finished with value: 0.24435378003912042 and parameters: {'learning_rate': 0.01942197771800701, 'lambda_l1': 1.2020838141647471e-06, 'lambda_l2': 0.00031074660681036984, 'max_depth': 4, 'num_leaves': 93, 'feature_fraction': 0.6739403101853457, 'min_data_in_leaf': 11, 'max_bin': 40, 'bagging_freq': 4}. Best is trial 114 with value: 0.23885453797726744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:49,582] Trial 117 finished with value: 0.24360341091117332 and parameters: {'learning_rate': 0.044421017316499806, 'lambda_l1': 2.6872354137496486e-06, 'lambda_l2': 0.0006253074742252637, 'max_depth': 4, 'num_leaves': 83, 'feature_fraction': 0.6996217468517337, 'min_data_in_leaf': 15, 'max_bin': 56, 'bagging_freq': 4}. Best is trial 114 with value: 0.23885453797726744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:51,727] Trial 118 finished with value: 0.2514867475453243 and parameters: {'learning_rate': 0.0351498678151367, 'lambda_l1': 3.2780021502500404e-07, 'lambda_l2': 0.0001893501779945991, 'max_depth': 4, 'num_leaves': 100, 'feature_fraction': 0.6839513508090882, 'min_data_in_leaf': 7, 'max_bin': 94, 'bagging_freq': 3}. Best is trial 114 with value: 0.23885453797726744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:55,870] Trial 119 finished with value: 0.24641301741386185 and parameters: {'learning_rate': 0.013040143427029246, 'lambda_l1': 8.632490672877616e-07, 'lambda_l2': 0.0013715351654263823, 'max_depth': 10, 'num_leaves': 122, 'feature_fraction': 0.6606062254298902, 'min_data_in_leaf': 12, 'max_bin': 33, 'bagging_freq': 3}. Best is trial 114 with value: 0.23885453797726744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:57,127] Trial 120 finished with value: 0.24807717305162133 and parameters: {'learning_rate': 0.06743423502224628, 'lambda_l1': 3.3866504156866887e-06, 'lambda_l2': 0.0008974639665714938, 'max_depth': 4, 'num_leaves': 90, 'feature_fraction': 0.6393387083307601, 'min_data_in_leaf': 13, 'max_bin': 127, 'bagging_freq': 4}. Best is trial 114 with value: 0.23885453797726744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:09:59,924] Trial 121 finished with value: 0.24149838734820467 and parameters: {'learning_rate': 0.018346939339614066, 'lambda_l1': 1.2918657273632509e-05, 'lambda_l2': 0.05687660764386134, 'max_depth': 4, 'num_leaves': 105, 'feature_fraction': 0.6659136872803915, 'min_data_in_leaf': 17, 'max_bin': 56, 'bagging_freq': 2}. Best is trial 114 with value: 0.23885453797726744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:10:02,634] Trial 122 finished with value: 0.2382063559961316 and parameters: {'learning_rate': 0.017610460148166734, 'lambda_l1': 1.008240832685802e-05, 'lambda_l2': 0.05299739146684706, 'max_depth': 4, 'num_leaves': 96, 'feature_fraction': 0.6520364127720234, 'min_data_in_leaf': 16, 'max_bin': 50, 'bagging_freq': 1}. Best is trial 122 with value: 0.2382063559961316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:10:05,457] Trial 123 finished with value: 0.23912763467873893 and parameters: {'learning_rate': 0.01786271443428246, 'lambda_l1': 8.940559355576779e-06, 'lambda_l2': 0.017271926806038715, 'max_depth': 4, 'num_leaves': 96, 'feature_fraction': 0.6672760167298569, 'min_data_in_leaf': 9, 'max_bin': 59, 'bagging_freq': 1}. Best is trial 122 with value: 0.2382063559961316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:10:10,031] Trial 124 finished with value: 0.2416979110246194 and parameters: {'learning_rate': 0.00923425249280154, 'lambda_l1': 1.2003298498540245e-05, 'lambda_l2': 0.05343115278284007, 'max_depth': 4, 'num_leaves': 96, 'feature_fraction': 0.654267230772744, 'min_data_in_leaf': 10, 'max_bin': 54, 'bagging_freq': 1}. Best is trial 122 with value: 0.2382063559961316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:10:12,503] Trial 125 finished with value: 0.24429551414459738 and parameters: {'learning_rate': 0.022613793780267927, 'lambda_l1': 6.985916261020443e-06, 'lambda_l2': 0.017556583625480026, 'max_depth': 4, 'num_leaves': 89, 'feature_fraction': 0.6751522290258332, 'min_data_in_leaf': 8, 'max_bin': 48, 'bagging_freq': 1}. Best is trial 122 with value: 0.2382063559961316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:10:15,609] Trial 126 finished with value: 0.23687010253668225 and parameters: {'learning_rate': 0.01441625141271959, 'lambda_l1': 1.3411746769503539e-05, 'lambda_l2': 0.010389414905226655, 'max_depth': 4, 'num_leaves': 93, 'feature_fraction': 0.6911924633903674, 'min_data_in_leaf': 15, 'max_bin': 68, 'bagging_freq': 1}. Best is trial 126 with value: 0.23687010253668225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:10:18,883] Trial 127 finished with value: 0.25097358255311636 and parameters: {'learning_rate': 0.014059712131912566, 'lambda_l1': 2.2259258704990744e-05, 'lambda_l2': 0.009248436804327898, 'max_depth': 4, 'num_leaves': 92, 'feature_fraction': 0.6913820429914233, 'min_data_in_leaf': 6, 'max_bin': 70, 'bagging_freq': 1}. Best is trial 126 with value: 0.23687010253668225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:10:25,332] Trial 128 finished with value: 0.24292562889192185 and parameters: {'learning_rate': 0.00621889958193122, 'lambda_l1': 4.223215299118723e-06, 'lambda_l2': 0.005059221469117029, 'max_depth': 4, 'num_leaves': 79, 'feature_fraction': 0.6825032191511267, 'min_data_in_leaf': 15, 'max_bin': 62, 'bagging_freq': 1}. Best is trial 126 with value: 0.23687010253668225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:10:31,134] Trial 129 finished with value: 0.24137727428777075 and parameters: {'learning_rate': 0.008331688434448625, 'lambda_l1': 9.12211505911701e-06, 'lambda_l2': 0.015078472737750741, 'max_depth': 4, 'num_leaves': 86, 'feature_fraction': 0.6990696557021863, 'min_data_in_leaf': 10, 'max_bin': 46, 'bagging_freq': 1}. Best is trial 126 with value: 0.23687010253668225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:10:35,906] Trial 130 finished with value: 0.24015231155706537 and parameters: {'learning_rate': 0.008291382603437715, 'lambda_l1': 1.5789964855332587e-05, 'lambda_l2': 0.014224458863030165, 'max_depth': 4, 'num_leaves': 93, 'feature_fraction': 0.6947962592298305, 'min_data_in_leaf': 10, 'max_bin': 46, 'bagging_freq': 1}. Best is trial 126 with value: 0.23687010253668225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-14 13:10:39,529] Trial 131 finished with value: 0.24340487007325654 and parameters: {'learning_rate': 0.011034601143687877, 'lambda_l1': 1.7724368666353262e-05, 'lambda_l2': 0.015364967529704301, 'max_depth': 4, 'num_leaves': 87, 'feature_fraction': 0.6947250568981187, 'min_data_in_leaf': 11, 'max_bin': 40, 'bagging_freq': 1}. Best is trial 126 with value: 0.23687010253668225.\n"
     ]
    }
   ],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability 𝑝 is replaced with max(min(𝑝,1−10−15),10−15)\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1 - y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2\n",
    "\n",
    "def bll_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def calc_log_loss_weight(y_true): \n",
    "    '''w0, w1 assign different weights to individual data points during training.'''\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    return w0, w1\n",
    "\n",
    "def lgbm_opt(features, boosting_type, n_trials):\n",
    "    X, y = train_df[features], train_df.Class\n",
    "#     X, y = generated_features_train, train_df.Class\n",
    "    \n",
    "    def objective(trial):\n",
    "        bll_list = list()\n",
    "        \n",
    "        param = {\n",
    "            # Main parameters\n",
    "#                     'device': 'gpu',\n",
    "#                     'gpu_platform_id': 0,\n",
    "#                     'gpu_device_id': 0,\n",
    "            'objective': 'binary',\n",
    "            'metric': 'none',\n",
    "            'is_unbalance': True,\n",
    "            'boosting_type': boosting_type, # trial.suggest_categorical('boosting_type', ['goss', 'gbdt', 'dart']),   \n",
    "            # Hyperparamters (in order of importance decreasing)\n",
    "            'n_estimators': 3000, # trial.suggest_int('n_estimators', 500, 1500),  # max number of trees in model\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 3e-1),\n",
    "            'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True), # L1,  alias: reg_alpha\n",
    "            'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True), # L2, alias: reg_lambda\n",
    "             # decrease to deal with overfit\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 10),   # tree max depth \n",
    "             # decrease to deal with overfit\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 4, 128),  # Max number of leaves in one tree\n",
    "                                                                   # should be ~ 2**(max_depth-1)\n",
    "            'bagging_fraction': None, # Randomly select part of data without \n",
    "                                      # resampling if bagging_fraction < 1.0\n",
    "                                      # alias: subsample\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.3, 0.7), # Randomly select a subset of features \n",
    "                                                                       # if feature_fraction < 1.0\n",
    "                                                                       # alias: colsample_bytree\n",
    "            # decrease to deal with overfit\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                               # aliases: min_child_samples, \n",
    "#             # decrease to deat with overfit\n",
    "#             'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-4, 1e-1), # Stop trying to split \n",
    "#                                                                                                    # leave if sum of it's\n",
    "#                                                                                                    # hessian less than k\n",
    "#                                                                                                    # alias: min_child_weight\n",
    "            \n",
    "            # increase for accuracy, decrease to deal with overfit\n",
    "            'max_bin': trial.suggest_int('max_bin', 32, 255), # Max number of bins that feature values will be bucketed in\n",
    "            # increase to deal with overfit\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7), # Perform bagging at every k iteration\n",
    "            'early_stopping_round': 100, \n",
    "            \n",
    "#           'subsample_for_bin': 200000, # Number of data that sampled to construct feature discrete bins; setting this \n",
    "                                         # to larger value will give better training result but may increase train time \n",
    "#           'cat_smooth': trial.suggest_float('cat_smooth', 10.0, 100.0),  # this can reduce the effect of noises in \n",
    "                                                                           # categorical features, especially for \n",
    "                                                                           # categories with few data\n",
    "            'verbose': -1\n",
    "        }\n",
    "\n",
    "        if boosting_type != 'goss':\n",
    "            param['bagging_fraction'] = trial.suggest_float('bagging_fraction', 0.3, 0.7)\n",
    "        \n",
    "        for i in range(CFG.n_optimize_repeats):\n",
    "            print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "            kf = MultilabelStratifiedKFold(n_splits=CFG.n_optimize_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "            # Stratify based on Class and Alpha (3 types of conditions)\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(X=train_df[features], y=greeks.iloc[:,1:3]), start = 1): \n",
    "\n",
    "                # Split the dataset according to the fold indexes.\n",
    "                X_train = X.iloc[train_idx]\n",
    "                X_val = X.iloc[val_idx]\n",
    "                y_train = y.iloc[train_idx]\n",
    "                y_val = y.iloc[val_idx]\n",
    "\n",
    "                dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "                dvalid = lgb.Dataset(X_val, label=y_val)\n",
    "                \n",
    "                # Add a callback for pruning\n",
    "                pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'balanced_log_loss')\n",
    "                \n",
    "                gbm = lgb.train(\n",
    "                    param, dtrain, valid_sets=[dvalid], # callbacks=[pruning_callback], \n",
    "                    feval=bll_metric, verbose_eval=0\n",
    "                )\n",
    "\n",
    "                preds = gbm.predict(X_val)\n",
    "                bll = balanced_log_loss(y_val, preds)\n",
    "                bll_list.append(bll)\n",
    "        \n",
    "        return np.mean(bll_list)\n",
    "            \n",
    "#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df.to_csv(f'optuna_lgbm_{boosting_type}.csv')\n",
    "            \n",
    "if CFG.lgbm_optimize:\n",
    "    for bt in ['goss', 'gbdt']:\n",
    "        lgbm_opt(features, bt, n_trials=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LGBM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "param_list = glob.glob(\"optuna_lgbm*.csv\")\n",
    "models = list()\n",
    "best_lgbm_params = list()\n",
    "\n",
    "lgbm_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    gb_type = [f.split('_')][0][2][:-4]\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    tmp['params_boosting_type'] = gb_type\n",
    "    if lgbm_params.shape[0] == 0:\n",
    "        lgbm_params = tmp\n",
    "    else:\n",
    "        lgbm_params = pd.concat([lgbm_params, tmp])\n",
    "        \n",
    "lgbm_params = lgbm_params.sort_values('value').head(20)\n",
    "param_cols = [c for c in lgbm_params.columns if c.startswith('params_')]\n",
    "lgbm_params = lgbm_params[param_cols]\n",
    "\n",
    "for idx, row in lgbm_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['objective'] = 'binary'\n",
    "    row_dict['metric'] = 'none'\n",
    "#     row_dict['subsample_for_bin'] = 300000\n",
    "    row_dict['force_col_wise'] = False\n",
    "    row_dict['early_stopping_rounds'] = 50\n",
    "    row_dict['verbose'] = -1\n",
    "    row_dict['max_bin'] = 255\n",
    "    row_dict['bagging_freq'] = int(row_dict['bagging_freq'])\n",
    "    if row_dict['bagging_fraction'] != row_dict['bagging_fraction']:\n",
    "        row_dict['bagging_fraction'] = None\n",
    "    row_dict['min_data_in_leaf'] = int(row_dict['min_data_in_leaf'])\n",
    "    row_dict['n_estimators'] = 3000 # int(row_dict['n_estimators'])\n",
    "    \n",
    "    row_dict['learning_rate'] = 0.06433232950390658 # float(row_dict['learning_rate'])\n",
    "    row_dict['num_leaves'] = int(row_dict['num_leaves'])\n",
    "    row_dict['max_depth'] = int(row_dict['max_depth'])\n",
    "    row_dict['is_unbalance'] = True\n",
    "    row_dict['class_weight'] = 'balanced'\n",
    "    row_dict['verbose'] = -1\n",
    "    \n",
    "    best_lgbm_params.append(row_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.672883Z",
     "iopub.status.busy": "2023-06-08T15:32:11.672350Z",
     "iopub.status.idle": "2023-06-08T15:32:38.349383Z",
     "shell.execute_reply": "2023-06-08T15:32:38.347823Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.672854Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def lgbm_training():\n",
    "    models_ = list()\n",
    "    bll_list = list()\n",
    "    weights_ = list()\n",
    "    \n",
    "    X, y = train_df[features], train_df.Class\n",
    "#     X, y = generated_features_train, train_df.Class\n",
    "     \n",
    "    kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=8062023+20)\n",
    "    metric = balanced_log_loss\n",
    "    eval_results_ = {}     # used to store evaluation results for each fold\n",
    "\n",
    "    oof_level2 = np.zeros([y.shape[0], len(best_lgbm_params) + 1])\n",
    "    oof_level2[:, len(best_lgbm_params)] = y\n",
    "\n",
    "    print(f\"Training with {blu}{X.shape[1]}{res} features\")\n",
    "\n",
    "    for fold, (fit_idx, val_idx) in tqdm(enumerate(kf.split(X=train_df, y=greeks.iloc[:,1:3]), start = 1),\n",
    "                                         total=CFG.n_stacking_folds):\n",
    "        \n",
    "        # Split the dataset according to the fold indexes.\n",
    "        X_train = X.iloc[fit_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_train = y.iloc[fit_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        for i, params in enumerate(best_lgbm_params):\n",
    "            \n",
    "            clf = lgb.LGBMClassifier(**params)\n",
    "            clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                    eval_metric=bll_metric, verbose=-1)\n",
    "            models_.append(clf)\n",
    "\n",
    "            val_preds = clf.predict_proba(X_val)[:,1]\n",
    "            oof_level2[val_idx, i] = val_preds\n",
    "\n",
    "            val_score = balanced_log_loss(y_val, val_preds)\n",
    "            best_iter = clf.best_iteration_\n",
    "\n",
    "            print(clf.best_iteration_)\n",
    "            \n",
    "            print(f'Fold: {blu}{fold:>3}{res}| bll_metric: {blu}{val_score:.5f}{res}'\n",
    "                  f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "        \n",
    "    return oof_level2, models_\n",
    "\n",
    "oof_level2_lgbm, models_lgbm = lgbm_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import CatBoostPruningCallback\n",
    "\n",
    "def catboost_opt(features, n_trials):\n",
    "    X, y = train_df[features], train_df.Class\n",
    "    \n",
    "    def objective(trial):\n",
    "        bll_list = list()\n",
    "        \n",
    "        # Parameters\n",
    "        params = {\n",
    "            'task_type': 'CPU', # GPU\n",
    "            'auto_class_weights': 'Balanced',\n",
    "            'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "            'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'Poisson', 'No']),\n",
    "            'eval_metric': 'Logloss',\n",
    "            'loss_function': 'Logloss', \n",
    "            'random_seed': 10062023,\n",
    "            'od_type': 'Iter', # Type of overfitting detector - stop after k iteraions\n",
    "            'od_wait': 100, # Overfitting detector - stop training after k iterations without metric improvement\n",
    "#             'metric_period': 100, # Show metric each k iterations\n",
    "            'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "             # Hyperparamters (in order of importance decreasing)\n",
    "            'iterations' : 5000, # trial.suggest_int('iterations', 300, 1200),        \n",
    "            'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-3, 3e-1),    \n",
    "            'l2_leaf_reg': trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
    "            'depth' : trial.suggest_int('depth', 4, 10),  # Max tree depth         \n",
    "             # decrease to deal with overfit\n",
    "            'subsample': trial.suggest_float('subsample', 0.3, 1), # randomly select part of data without return\n",
    "            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.3, 1), # the percentage of features to use at each \n",
    "                                                                                   # split selection\n",
    "                                                                                   # alias: rsm\n",
    "                                                                                   # not supported in GPU mode\n",
    "             # decrease to deal with overfit\n",
    "             'max_leaves': trial.suggest_int('max_leaves', 4, 128), # Max number of leaves in one tree                                                 \n",
    "             # increase to deal with overfit\n",
    "            'random_strength': trial.suggest_float('random_strength', 0, 100), # The amount of randomness to use \n",
    "                                                                               # for scoring splits when the tree structure\n",
    "                                                                               # is selected. Helps to avoid overfitting\n",
    "            'bagging_temperature' : trial.suggest_float('bagging_temperature', 0, 100),     # Assigns random \n",
    "                                                                                            # weights to objects\n",
    "                                                                                            # works only with Bayesian bootstrap\n",
    "            # this feature value can be increased to 1024 for important features:\n",
    "            # per_float_feature_quantization='0:border_count=1024'\n",
    "            'border_count': 254, # trial.suggest_categorical('border_count', [128, 254]), # The number of splits for numerical features\n",
    "                                                                                          # bigger is better but slowly\n",
    "                                                                                          # alias: max_bin\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                               # aliases: min_child_samples, \n",
    "            \n",
    "        }\n",
    "        \n",
    "        if params['grow_policy'] != 'SymmetricTree': \n",
    "            params['boosting_type'] = 'Plain'\n",
    "            \n",
    "        if params['grow_policy'] != 'Lossguide': \n",
    "            params['max_leaves'] = None\n",
    "        \n",
    "#         if params['bootstrap_type'] == 'Bayesian':\n",
    "#             params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 100)\n",
    "#             params['subsample'] = None\n",
    "#         else:\n",
    "#             params['bagging_temperature'] = None\n",
    "#             params['subsample'] = trial.suggest_float('subsample', 0.3, 1)\n",
    "        \n",
    "        if params['task_type'] != 'CPU':\n",
    "            params['colsample_bylevel'] = None\n",
    "        \n",
    "        for i in range(CFG.n_optimize_repeats):\n",
    "            print(f'{blu}Repeat #{i+1}')\n",
    "\n",
    "            # Create an oof array for inner loop\n",
    "            oof = np.zeros(train_df.shape[0])\n",
    "\n",
    "            kf = MultilabelStratifiedKFold(n_splits=CFG.n_optimize_folds, shuffle=True, random_state=8062023+i)\n",
    "\n",
    "            # Stratify based on Class and Alpha (3 types of conditions)\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(X=train_df[features], y=greeks.iloc[:,1:3]), start = 1): \n",
    "\n",
    "                # Split the dataset according to the fold indexes.\n",
    "                X_train = X.iloc[train_idx]\n",
    "                X_val = X.iloc[val_idx]\n",
    "                y_train = y.iloc[train_idx]\n",
    "                y_val = y.iloc[val_idx]\n",
    "          \n",
    "                train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "                val_pool = Pool(X_val, y_val, cat_features=['EJ'])\n",
    "\n",
    "                # Learning\n",
    "                model = cat.CatBoostClassifier(**params)     \n",
    "                # Add a callback for pruning\n",
    "#                 pruning_callback = optuna.integration.CatBoostPruningCallback(trial, \"Logloss\")\n",
    "                model.fit(train_pool, eval_set=val_pool, verbose=0)#, callbacks=[pruning_callback])\n",
    "                # Evoke pruning manually\n",
    "#                 pruning_callback.check_pruned()\n",
    "                # Predict\n",
    "                preds = model.predict_proba(val_pool)[:,1]\n",
    "                # Evaluation\n",
    "                bll = balanced_log_loss(y_val, preds)\n",
    "                bll_list.append(bll)\n",
    "                \n",
    "        \n",
    "        return np.mean(bll_list)\n",
    "            \n",
    "#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe()\n",
    "    df.sort_values('value').iloc[:, [1] + list(range(5, 14))]\n",
    "    df.to_csv(f'optuna_catboost_fold_.csv')\n",
    "            \n",
    "if CFG.cb_optimize:\n",
    "    catboost_opt(features, n_trials=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CatBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "param_list = glob.glob(\"optuna_catboost*.csv\")\n",
    "models = list()\n",
    "best_cb_params = list()\n",
    "\n",
    "cb_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if cb_params.shape[0] == 0:\n",
    "        cb_params = tmp\n",
    "    else:\n",
    "        cb_params = pd.concat([cb_params, tmp])\n",
    "        \n",
    "cb_params = cb_params.sort_values('value').head(10)\n",
    "param_cols = [c for c in cb_params.columns if c.startswith('params_')]\n",
    "cb_params = cb_params[param_cols]\n",
    "\n",
    "\n",
    "for idx, row in cb_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['task_type'] = 'CPU'\n",
    "    row_dict['auto_class_weights'] = 'Balanced'\n",
    "    row_dict['eval_metric'] = 'Logloss'\n",
    "    row_dict['loss_function'] = 'Logloss'\n",
    "    row_dict['random_seed'] = 13062023\n",
    "    row_dict['verbose'] = 0\n",
    "    row_dict['od_type'] = 'Iter'\n",
    "    row_dict['od_wait'] = 100\n",
    "    row_dict['border_count'] = 254\n",
    "    row_dict['iterations'] = 10000\n",
    "    row_dict['bagging_temperature'] = float(row_dict['bagging_temperature'])\n",
    "    row_dict['subsample'] = 0.7 # float(row_dict['subsample'])\n",
    "    row_dict['learning_rate'] = float(row_dict['learning_rate'])\n",
    "    row_dict['l2_leaf_reg'] = float(row_dict['l2_leaf_reg'])\n",
    "    row_dict['depth'] = int(row_dict['depth'])\n",
    "    row_dict['random_strength'] = float(row_dict['random_strength'])\n",
    "    row_dict['min_data_in_leaf'] = int(row_dict['min_data_in_leaf'])\n",
    "    \n",
    "    if row_dict['grow_policy'] == 'Lossguide':\n",
    "        row_dict['max_leaves'] = int(row_dict['max_leaves'])\n",
    "    else:\n",
    "        del row_dict['max_leaves']\n",
    "    \n",
    "    if row_dict['grow_policy'] == 'SymmetricTree':\n",
    "        row_dict['boosting_type'] = 'Plain'\n",
    "    else:\n",
    "        del row_dict['boosting_type']\n",
    "        \n",
    "    if row_dict['task_type'] == 'CPU':\n",
    "        row_dict['colsample_bylevel'] = 0.6 # float(row_dict['colsample_bylevel'])\n",
    "    else:\n",
    "        del row_dict['colsample_bylevel']\n",
    "    \n",
    "    best_cb_params.append(row_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def cb_training():\n",
    "    models_ = list()\n",
    "    bll_list = list()\n",
    "    weights_ = list()\n",
    "    \n",
    "    X, y = train_df[features], train_df.Class\n",
    "#     X, y = generated_features_train, train_df.Class\n",
    "     \n",
    "    kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=8062023+20)\n",
    "    metric = balanced_log_loss\n",
    "    eval_results_ = {}     # used to store evaluation results for each fold\n",
    "\n",
    "    oof_level2 = np.zeros([y.shape[0], len(best_cb_params) + 1])\n",
    "    oof_level2[:, len(best_cb_params)] = y\n",
    "\n",
    "    print(f\"Training with {blu}{X.shape[1]}{res} features\")\n",
    "\n",
    "    for fold, (fit_idx, val_idx) in tqdm(enumerate(kf.split(X=train_df, y=greeks.iloc[:,1:3]), start = 1),\n",
    "                                         total=CFG.n_stacking_folds):\n",
    "        \n",
    "        # Split the dataset according to the fold indexes.\n",
    "        X_train = X.iloc[fit_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_train = y.iloc[fit_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "        val_pool = Pool(X_val, y_val, cat_features=['EJ'])\n",
    "        \n",
    "        for i, params in enumerate(best_cb_params):\n",
    "            \n",
    "            model = cat.CatBoostClassifier(**params)\n",
    "            model.fit(train_pool, eval_set=val_pool, verbose=0)\n",
    "            models_.append(model)\n",
    "\n",
    "            val_preds = model.predict_proba(val_pool)[:,1]\n",
    "            oof_level2[val_idx, i] = val_preds\n",
    "\n",
    "            val_score = balanced_log_loss(y_val, val_preds)\n",
    "            best_iter = model.best_iteration_\n",
    "\n",
    "            print(model.best_iteration_)\n",
    "            \n",
    "            print(f'Fold: {blu}{fold:>3}{res}| bll_metric: {blu}{val_score:.5f}{res}'\n",
    "                  f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "        \n",
    "    return oof_level2, models_\n",
    "\n",
    "# oof_level2_cb, models_cb = cb_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# oof_level2 = np.concatenate([oof_level2_lgbm[:,:-1] , oof_level2_cb[:,:-1]], axis=1)\n",
    "X = oof_level2_lgbm[:,:-1]\n",
    "y = oof_level2_lgbm[:,-1]\n",
    "\n",
    "# mean bll\n",
    "print(balanced_log_loss(y, np.mean(X, axis=1)))\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "lr.fit(X, y)\n",
    "\n",
    "pred = lr.predict_proba(X)[:,1]\n",
    "\n",
    "# lr bll\n",
    "print(balanced_log_loss(y, pred))\n",
    "\n",
    "weights = lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.16616213477809366\n",
    "# 0.162813150781854"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-08T15:32:38.350522Z",
     "iopub.status.idle": "2023-06-08T15:32:38.351460Z",
     "shell.execute_reply": "2023-06-08T15:32:38.351239Z",
     "shell.execute_reply.started": "2023-06-08T15:32:38.351217Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Model Evaluation\n",
    "# metric_score_folds = pd.DataFrame.from_dict(all_eval_results_)\n",
    "# fit_logloss = []\n",
    "# val_logloss = []\n",
    "\n",
    "# for seed in CFG.seeds:\n",
    "#     for fold in range(1,CFG.n_folds+1):\n",
    "#         fit_logloss.append(metric_score_folds[seed][fold]['training']['balanced_log_loss'])\n",
    "#         val_logloss.append(metric_score_folds[seed][fold]['valid_1']['balanced_log_loss'])\n",
    "\n",
    "# fig, axes = plt.subplots(math.ceil(CFG.n_folds*len(CFG.seeds)/CFG.n_folds), CFG.n_folds, figsize=(20, 20), dpi=150)\n",
    "# ax = axes.flatten()\n",
    "# for i, (f, v, m) in enumerate(zip(fit_logloss, val_logloss, models_), start = 1): \n",
    "#     sns.lineplot(f, color='#B90000', ax=ax[i-1], label='fit')\n",
    "#     sns.lineplot(v, color='#048BA8', ax=ax[i-1], label='val')\n",
    "#     ax[i-1].legend()\n",
    "#     ax[i-1].spines['top'].set_visible(False);\n",
    "#     ax[i-1].spines['right'].set_visible(False)\n",
    "#     ax[i-1].set_title(f'Seed {CFG.seeds[(i-1)//CFG.n_folds]} Fold {CFG.n_folds if i%CFG.n_folds==0 else i%CFG.n_folds}', fontdict={'fontweight': 'bold'})\n",
    "\n",
    "#     color =  ['#048BA8', palette[-3]]\n",
    "#     best_iter = m.best_iteration_\n",
    "#     span_range = [[0, best_iter], [best_iter + 10, best_iter + CFG.num_boost_round]]\n",
    "\n",
    "#     for idx, sub_title in enumerate([f'Best\\nIteration: {best_iter}', f'Early\\n Stopping: 2000']):\n",
    "#         ax[i-1].annotate(sub_title,\n",
    "#                     xy=(sum(span_range[idx])/2 , 0.5),\n",
    "#                     xytext=(0,0), textcoords='offset points',\n",
    "#                     va=\"center\", ha=\"center\",\n",
    "#                     color=\"w\", fontsize=16, fontweight='bold',\n",
    "#                     bbox=dict(boxstyle='round4', pad=0.4, color=color[idx], alpha=0.6))\n",
    "#         ax[i-1].axvspan(span_range[idx][0]-0.4,span_range[idx][1]+0.4,  color=color[idx], alpha=0.07)\n",
    "\n",
    "#     ax[i-1].set_xlim(0, best_iter + 20 + 2000)\n",
    "#     ax[i-1].legend(bbox_to_anchor=(0.95, 1), loc='upper right', title='logloss')\n",
    "\n",
    "# plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-08T15:32:38.352845Z",
     "iopub.status.idle": "2023-06-08T15:32:38.353222Z",
     "shell.execute_reply": "2023-06-08T15:32:38.353059Z",
     "shell.execute_reply.started": "2023-06-08T15:32:38.353042Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = models_lgbm # + models_cb\n",
    "\n",
    "def predict(X):\n",
    "    y = np.zeros(len(X))\n",
    "    for i, model in enumerate(models):\n",
    "#         y += weights[i] * model.predict_proba(X)[:,1]\n",
    "        y += model.predict_proba(X)[:,1]\n",
    "#     return y / sum(weights)\n",
    "    return y / len(models)\n",
    "\n",
    "predictions = predict(test_df[features])\n",
    "# predictions = predict(generated_features_test)\n",
    "\n",
    "test_df['class_1'] = predictions\n",
    "test_df['class_0'] = 1 - predictions\n",
    "\n",
    "sample_submission[['class_0', 'class_1']] = test_df[['class_0', 'class_1']]\n",
    "sample_submission.to_csv(r\"submission.csv\", index=False)\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a lot of resulting features. I have already identified a few important once. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
