{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:23.665663Z",
     "iopub.status.busy": "2023-06-08T15:31:23.665223Z",
     "iopub.status.idle": "2023-06-08T15:31:35.997437Z",
     "shell.execute_reply": "2023-06-08T15:31:35.996163Z",
     "shell.execute_reply.started": "2023-06-08T15:31:23.665630Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "from catboost import Pool\n",
    "import xgboost as xgb\n",
    "\n",
    "import itertools\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits, BaseShuffleSplit, _validate_shuffle_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import _num_samples, check_array\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import eli5\n",
    "from IPython.display import display\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "from colorama import Style, Fore\n",
    "\n",
    "palette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n",
    "           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n",
    "\n",
    "blk = Style.BRIGHT + Fore.BLACK\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "res = Style.RESET_ALL\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    undersample = True\n",
    "    \n",
    "    feature_sel = False\n",
    "    n_feature_sel_folds = 5\n",
    "    \n",
    "    lgbm_optimize = True\n",
    "    cb_optimize = True\n",
    "    xgb_optimize = True\n",
    "    n_trials = 1000\n",
    "    n_optimize_folds = 3\n",
    "    n_optimize_repeats = 5\n",
    "    \n",
    "    stacking = False\n",
    "    n_stacking_folds = 10\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.001085Z",
     "iopub.status.busy": "2023-06-08T15:31:35.999808Z",
     "iopub.status.idle": "2023-06-08T15:31:36.066222Z",
     "shell.execute_reply": "2023-06-08T15:31:36.064862Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.001050Z"
    }
   },
   "outputs": [],
   "source": [
    "# COMP_PATH = \"/kaggle/input/icr-identify-age-related-conditions\"\n",
    "COMP_PATH = \"icr-identify-age-related-conditions\"\n",
    "\n",
    "train_df = pd.read_csv(f'{COMP_PATH}//train.csv')\n",
    "test_df = pd.read_csv(f'{COMP_PATH}/test.csv')\n",
    "greeks = pd.read_csv(f\"{COMP_PATH}/greeks.csv\")\n",
    "sample_submission = pd.read_csv(f\"{COMP_PATH}/sample_submission.csv\")\n",
    "\n",
    "train_df['EJ'] = train_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "test_df['EJ'] = test_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "\n",
    "train_df.columns = train_df.columns.str.replace(' ', '')\n",
    "test_df.columns = test_df.columns.str.replace(' ', '')\n",
    "\n",
    "# train_df.drop('Id',axis=1, inplace=True)\n",
    "# train_df.fillna(train_df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.069293Z",
     "iopub.status.busy": "2023-06-08T15:31:36.068506Z",
     "iopub.status.idle": "2023-06-08T15:31:36.075275Z",
     "shell.execute_reply": "2023-06-08T15:31:36.074052Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.069253Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# new_num_cols = train_df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "# train_df[new_num_cols] = scaler.fit_transform(train_df[new_num_cols])\n",
    "# test_df[new_num_cols] = scaler.transform(test_df[new_num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine features in all possible ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi = pd.read_csv('feature_importances.csv', index_col = 'Unnamed: 0')\n",
    "# fi_cols = set(fi['Feature'].head(100).values)\n",
    "\n",
    "# perm = pd.read_csv('perm_df.csv', index_col = 'Unnamed: 0')\n",
    "# perm_cols = set(perm['importance'].head(100).index)\n",
    "\n",
    "# important_col = list(perm_cols.intersection(fi_cols))\n",
    "# print(important_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = [fe for fe in train_df.columns if fe not in ['Id','CF', 'CB', 'DV', 'BR', 'DF', 'AR', 'GI', 'AY', 'GB',\n",
    "#                                                         'AH', 'CW', 'CL', 'Class', 'BP']]\n",
    "\n",
    "# for f in features:\n",
    "#     train_df[f] = np.floor(train_df[f]*1000)/1000 # quality decreases no significant result for LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log features (preserve sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in features:\n",
    "#     train_df[f] = np.sign(train_df[f]) * np.log1p(np.abs(train_df[f])) # no significant result for LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_outliers = [fe for fe in train_df.columns if fe not in ['BN', 'BQ', 'CW', 'EL', 'GH', \n",
    "                                                                      'GI', 'GL', 'Id', 'Class', 'EJ']]\n",
    "\n",
    "for f in features_with_outliers:\n",
    "    train_df[f] = train_df[f].clip(upper=train_df[f].quantile(0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.080972Z",
     "iopub.status.busy": "2023-06-08T15:31:36.079281Z",
     "iopub.status.idle": "2023-06-08T15:31:44.412385Z",
     "shell.execute_reply": "2023-06-08T15:31:44.411508Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.080912Z"
    }
   },
   "outputs": [],
   "source": [
    "features = train_df.drop(['Class', 'Id'], axis=1).columns\n",
    "\n",
    "# features = [fe for fe in train_df.columns if fe not in ['CF', 'CB', 'DV', 'BR', 'DF', 'GB', 'AH', \n",
    "#                                                         'CW', 'CL', 'BP', 'BD', 'FC', 'GE', 'GF',\n",
    "#                                                         'AR', 'GI', 'Id', 'Class', 'AX']]\n",
    "\n",
    "# def gen_features(features, df):\n",
    "#     generated_features = pd.DataFrame()\n",
    "\n",
    "#     for fe_a, fe_b in tqdm(itertools.combinations(features, 2), total=sum([1 for i in itertools.combinations(features, 2)])):\n",
    "\n",
    "# #         generated_features[f'{fe_a}_2']        = df[fe_a].pow(2)\n",
    "# #         generated_features[f'{fe_b}_2']        = df[fe_b].pow(2)\n",
    "# #         generated_features[f'{fe_a}*{fe_b}_2'] = df[fe_a] * df[fe_b].pow(2)\n",
    "# #         generated_features[f'{fe_a}_2*{fe_b}'] = df[fe_a].pow(2) * df[fe_b]\n",
    "\n",
    "# #         generated_features[f'{fe_a}_05'] = df[fe_a].pow(0.5)\n",
    "# #         generated_features[f'{fe_b}_05'] = df[fe_b].pow(0.5)\n",
    "# #         generated_features[f'{fe_a}*{fe_b}_05'] = df[fe_a] * df[fe_b].pow(0.5)\n",
    "# #         generated_features[f'{fe_a}_05*{fe_b}'] = df[fe_a].pow(0.5) * df[fe_b]\n",
    "\n",
    "# #         generated_features[f'{fe_a}_log'] = np.log(df[fe_a])\n",
    "# #         generated_features[f'{fe_b}_log'] = np.log(df[fe_b])\n",
    "# #         generated_features[f'{fe_a}*{fe_b}_log'] = df[fe_a] * np.log(df[fe_b])\n",
    "# #         generated_features[f'{fe_a}_log*{fe_b}'] = np.log(df[fe_a]) * df[fe_b]\n",
    "        \n",
    "#     generated_features = generated_features[selected]\n",
    "#     generated_features = pd.concat([generated_features, df[features]], axis=1)\n",
    "    \n",
    "#     # prevent inf\n",
    "#     for g in generated_features.columns:\n",
    "#         generated_features[g] = np.minimum(np.maximum(generated_features[g], -1e9), 1e9)\n",
    "    \n",
    "#     return generated_features\n",
    "\n",
    "# generated_features_train = gen_features(features, train_df)\n",
    "# generated_features_test = gen_features(features, test_df)\n",
    "\n",
    "# features = generated_features_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "\n",
    "class_imbalance = train_df[train_df['Class'] == 0].shape[0] / train_df[train_df['Class'] == 1].shape[0]\n",
    "\n",
    "# average label of 20 Nearest Neighbours (colsine distance)\n",
    "knn = NearestNeighbors(n_neighbors=21, metric='cosine', n_jobs=-1)\n",
    "knn.fit(train_df[features].fillna(0))\n",
    "\n",
    "# train\n",
    "dists, nears = knn.kneighbors(train_df[features].fillna(0), return_distance=True)\n",
    "dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "train_df['class_cos'] = np.array(classes[i].mean() * class_imbalance for i in range(len(nears)))\n",
    "train_df['class_cos'] = train_df['class_cos'].astype(float)\n",
    "\n",
    "# test\n",
    "dists, nears = knn.kneighbors(test_df[features].fillna(0), return_distance=True)\n",
    "dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "test_df['class_cos'] = np.array(classes[i].mean()  * class_imbalance for i in range(len(nears)))\n",
    "test_df['class_cos'] = test_df['class_cos'].astype(float)\n",
    "\n",
    "\n",
    "# features = [fe for fe in train_df.columns if fe not in ['CF', 'CB', 'DV', 'BR', 'DF', 'GB', 'AH', \n",
    "#                                                         'CW', 'CL', 'BP', 'BD', 'FC', 'GE', 'GF',\n",
    "#                                                         'AR', 'GI', 'Id', 'Class', 'AX']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:44.414098Z",
     "iopub.status.busy": "2023-06-08T15:31:44.413784Z",
     "iopub.status.idle": "2023-06-08T15:31:44.461531Z",
     "shell.execute_reply": "2023-06-08T15:31:44.460184Z",
     "shell.execute_reply.started": "2023-06-08T15:31:44.414071Z"
    }
   },
   "outputs": [],
   "source": [
    "def IterativeStratification(labels, r, random_state):\n",
    "    \"\"\"This function implements the Iterative Stratification algorithm described\n",
    "    in the following paper:\n",
    "    Sechidis K., Tsoumakas G., Vlahavas I. (2011) On the Stratification of\n",
    "    Multi-Label Data. In: Gunopulos D., Hofmann T., Malerba D., Vazirgiannis M.\n",
    "    (eds) Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n",
    "    2011. Lecture Notes in Computer Science, vol 6913. Springer, Berlin,\n",
    "    Heidelberg.\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = labels.shape[0]\n",
    "    test_folds = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    # Calculate the desired number of examples at each subset\n",
    "    c_folds = r * n_samples\n",
    "\n",
    "    # Calculate the desired number of examples of each label at each subset\n",
    "    c_folds_labels = np.outer(r, labels.sum(axis=0))\n",
    "\n",
    "    labels_not_processed_mask = np.ones(n_samples, dtype=bool)\n",
    "\n",
    "    while np.any(labels_not_processed_mask):\n",
    "        # Find the label with the fewest (but at least one) remaining examples,\n",
    "        # breaking ties randomly\n",
    "        num_labels = labels[labels_not_processed_mask].sum(axis=0)\n",
    "\n",
    "        # Handle case where only all-zero labels are left by distributing\n",
    "        # across all folds as evenly as possible (not in original algorithm but\n",
    "        # mentioned in the text). (By handling this case separately, some\n",
    "        # code redundancy is introduced; however, this approach allows for\n",
    "        # decreased execution time when there are a relatively large number\n",
    "        # of all-zero labels.)\n",
    "        if num_labels.sum() == 0:\n",
    "            sample_idxs = np.where(labels_not_processed_mask)[0]\n",
    "\n",
    "            for sample_idx in sample_idxs:\n",
    "                fold_idx = np.where(c_folds == c_folds.max())[0]\n",
    "\n",
    "                if fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(fold_idx.shape[0])]\n",
    "\n",
    "                test_folds[sample_idx] = fold_idx\n",
    "                c_folds[fold_idx] -= 1\n",
    "\n",
    "            break\n",
    "\n",
    "        label_idx = np.where(num_labels == num_labels[np.nonzero(num_labels)].min())[0]\n",
    "        if label_idx.shape[0] > 1:\n",
    "            label_idx = label_idx[random_state.choice(label_idx.shape[0])]\n",
    "\n",
    "        sample_idxs = np.where(np.logical_and(labels[:, label_idx].flatten(), labels_not_processed_mask))[0]\n",
    "\n",
    "        for sample_idx in sample_idxs:\n",
    "            # Find the subset(s) with the largest number of desired examples\n",
    "            # for this label, breaking ties by considering the largest number\n",
    "            # of desired examples, breaking further ties randomly\n",
    "            label_folds = c_folds_labels[:, label_idx]\n",
    "            fold_idx = np.where(label_folds == label_folds.max())[0]\n",
    "\n",
    "            if fold_idx.shape[0] > 1:\n",
    "                temp_fold_idx = np.where(c_folds[fold_idx] ==\n",
    "                                         c_folds[fold_idx].max())[0]\n",
    "                fold_idx = fold_idx[temp_fold_idx]\n",
    "\n",
    "                if temp_fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(temp_fold_idx.shape[0])]\n",
    "\n",
    "            test_folds[sample_idx] = fold_idx\n",
    "            labels_not_processed_mask[sample_idx] = False\n",
    "\n",
    "            # Update desired number of examples\n",
    "            c_folds_labels[fold_idx, labels[sample_idx]] -= 1\n",
    "            c_folds[fold_idx] -= 1\n",
    "\n",
    "    return test_folds\n",
    "\n",
    "\n",
    "class MultilabelStratifiedKFold(_BaseKFold):\n",
    "    \"\"\"Multilabel stratified K-Folds cross-validator\n",
    "    Provides train/test indices to split multilabel data into train/test sets.\n",
    "    This cross-validation object is a variation of KFold that returns\n",
    "    stratified folds for multilabel data. The folds are made by preserving\n",
    "    the percentage of samples for each label.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=3\n",
    "        Number of folds. Must be at least 2.\n",
    "    shuffle : boolean, optional\n",
    "        Whether to shuffle each stratification of the data before splitting\n",
    "        into batches.\n",
    "    random_state : int, RandomState instance or None, optional, default=None\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedKFold that only uses random_state\n",
    "        when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> mskf = MultilabelStratifiedKFold(n_splits=2, random_state=0)\n",
    "    >>> mskf.get_n_splits(X, y)\n",
    "    2\n",
    "    >>> print(mskf)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    MultilabelStratifiedKFold(n_splits=2, random_state=0, shuffle=False)\n",
    "    >>> for train_index, test_index in mskf.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different in each fold.\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedMultilabelStratifiedKFold: Repeats Multilabel Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=3, *, shuffle=False, random_state=None):\n",
    "        super(MultilabelStratifiedKFold, self).__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def _make_test_folds(self, X, y):\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(type_of_target_y))\n",
    "\n",
    "        num_samples = y.shape[0]\n",
    "\n",
    "        rng = check_random_state(self.random_state)\n",
    "        indices = np.arange(num_samples)\n",
    "\n",
    "        if self.shuffle:\n",
    "            rng.shuffle(indices)\n",
    "            y = y[indices]\n",
    "\n",
    "        r = np.asarray([1 / self.n_splits] * self.n_splits)\n",
    "\n",
    "        test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "        return test_folds[np.argsort(indices)]\n",
    "\n",
    "    def _iter_test_masks(self, X=None, y=None, groups=None):\n",
    "        test_folds = self._make_test_folds(X, y)\n",
    "        for i in range(self.n_splits):\n",
    "            yield test_folds == i\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedKFold, self).split(X, y, groups)\n",
    "\n",
    "\n",
    "class RepeatedMultilabelStratifiedKFold(_RepeatedSplits):\n",
    "    \"\"\"Repeated Multilabel Stratified K-Fold cross validator.\n",
    "    Repeats Mulilabel Stratified K-Fold n times with different randomization\n",
    "    in each repetition.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of folds. Must be at least 2.\n",
    "    n_repeats : int, default=10\n",
    "        Number of times cross-validator needs to be repeated.\n",
    "    random_state : None, int or RandomState, default=None\n",
    "        Random state to be used to generate random state for each\n",
    "        repetition as well as randomly breaking ties within the iterative\n",
    "        stratification algorithm.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import RepeatedMultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> rmskf = RepeatedMultilabelStratifiedKFold(n_splits=2, n_repeats=2,\n",
    "    ...     random_state=0)\n",
    "    >>> for train_index, test_index in rmskf.split(X, y):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    ...\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [0 1 4 5] TEST: [2 3 6 7]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedStratifiedKFold: Repeats (Non-multilabel) Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=5, *, n_repeats=10, random_state=None):\n",
    "        super(RepeatedMultilabelStratifiedKFold, self).__init__(\n",
    "            MultilabelStratifiedKFold, n_repeats=n_repeats, random_state=random_state,\n",
    "            n_splits=n_splits)\n",
    "\n",
    "\n",
    "class MultilabelStratifiedShuffleSplit(BaseShuffleSplit):\n",
    "    \"\"\"Multilabel Stratified ShuffleSplit cross-validator\n",
    "    Provides train/test indices to split data into train/test sets.\n",
    "    This cross-validation object is a merge of MultilabelStratifiedKFold and\n",
    "    ShuffleSplit, which returns stratified randomized folds for multilabel\n",
    "    data. The folds are made by preserving the percentage of each label.\n",
    "    Note: like the ShuffleSplit strategy, multilabel stratified random splits\n",
    "    do not guarantee that all folds will be different, although this is\n",
    "    still very likely for sizeable datasets.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default 10\n",
    "        Number of re-shuffling & splitting iterations.\n",
    "    test_size : float, int, None, optional\n",
    "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
    "        of the dataset to include in the test split. If int, represents the\n",
    "        absolute number of test samples. If None, the value is set to the\n",
    "        complement of the train size. By default, the value is set to 0.1.\n",
    "        The default will change in version 0.21. It will remain 0.1 only\n",
    "        if ``train_size`` is unspecified, otherwise it will complement\n",
    "        the specified ``train_size``.\n",
    "    train_size : float, int, or None, default is None\n",
    "        If float, should be between 0.0 and 1.0 and represent the\n",
    "        proportion of the dataset to include in the train split. If\n",
    "        int, represents the absolute number of train samples. If None,\n",
    "        the value is automatically set to the complement of the test size.\n",
    "    random_state : int, RandomState instance or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedShuffleSplit that only uses\n",
    "        random_state when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> msss = MultilabelStratifiedShuffleSplit(n_splits=3, test_size=0.5,\n",
    "    ...    random_state=0)\n",
    "    >>> msss.get_n_splits(X, y)\n",
    "    3\n",
    "    >>> print(mss)       # doctest: +ELLIPSIS\n",
    "    MultilabelStratifiedShuffleSplit(n_splits=3, random_state=0, test_size=0.5,\n",
    "                                     train_size=None)\n",
    "    >>> for train_index, test_index in msss.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    TRAIN: [1 2 5 6] TEST: [0 3 4 7]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different from desired due to the\n",
    "    preference of stratification over perfectly sized folds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=10, *, test_size=\"default\", train_size=None,\n",
    "                 random_state=None):\n",
    "        super(MultilabelStratifiedShuffleSplit, self).__init__(\n",
    "            n_splits=n_splits, test_size=test_size, train_size=train_size, random_state=random_state)\n",
    "\n",
    "    def _iter_indices(self, X, y, groups=None):\n",
    "        n_samples = _num_samples(X)\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(\n",
    "                    type_of_target_y))\n",
    "\n",
    "        n_train, n_test = _validate_shuffle_split(n_samples, self.test_size,\n",
    "                                                  self.train_size)\n",
    "\n",
    "        n_samples = y.shape[0]\n",
    "        rng = check_random_state(self.random_state)\n",
    "        y_orig = y.copy()\n",
    "\n",
    "        r = np.array([n_train, n_test]) / (n_train + n_test)\n",
    "\n",
    "        for _ in range(self.n_splits):\n",
    "            indices = np.arange(n_samples)\n",
    "            rng.shuffle(indices)\n",
    "            y = y_orig[indices]\n",
    "\n",
    "            test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "            test_idx = test_folds[np.argsort(indices)] == 1\n",
    "            test = np.where(test_idx)[0]\n",
    "            train = np.where(~test_idx)[0]\n",
    "\n",
    "            yield train, test\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedShuffleSplit, self).split(X, y, groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:41.223344Z",
     "iopub.status.busy": "2023-06-08T15:32:41.222954Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[1]\tvalid_0's balanced_log_loss: 0.675494\n",
      "[2]\tvalid_0's balanced_log_loss: 0.663652\n",
      "[3]\tvalid_0's balanced_log_loss: 0.652625\n",
      "[4]\tvalid_0's balanced_log_loss: 0.623198\n",
      "[5]\tvalid_0's balanced_log_loss: 0.607029\n",
      "[6]\tvalid_0's balanced_log_loss: 0.581928\n",
      "[7]\tvalid_0's balanced_log_loss: 0.564768\n",
      "[8]\tvalid_0's balanced_log_loss: 0.546604\n",
      "[9]\tvalid_0's balanced_log_loss: 0.537501\n",
      "[10]\tvalid_0's balanced_log_loss: 0.518296\n",
      "[11]\tvalid_0's balanced_log_loss: 0.505712\n",
      "[12]\tvalid_0's balanced_log_loss: 0.503956\n",
      "[13]\tvalid_0's balanced_log_loss: 0.492748\n",
      "[14]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[15]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[16]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[17]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[18]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[19]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[20]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[21]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[22]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[23]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[24]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[25]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[26]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[27]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[28]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[29]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[30]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[31]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[32]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[33]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[34]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[35]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[36]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[37]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[38]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[39]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[40]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[41]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[42]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[43]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[44]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[45]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[46]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[47]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[48]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[49]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[50]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[51]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[52]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[53]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[54]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[55]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[56]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[57]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[58]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[59]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[60]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[61]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[62]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[63]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[64]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[65]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[66]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[67]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[68]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[69]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[70]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[71]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[72]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[73]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[74]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[75]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[76]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[77]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[78]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[79]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[80]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[81]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[82]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[83]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[84]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[85]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[86]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[87]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[88]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[89]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[90]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[91]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[92]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[93]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[94]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[95]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[96]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[97]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[98]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[99]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[100]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[101]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[102]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[103]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[104]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[105]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[106]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[107]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[108]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[109]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[110]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[111]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[112]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[113]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[114]\tvalid_0's balanced_log_loss: 0.483312\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.48331\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.662738\n",
      "[2]\tvalid_0's balanced_log_loss: 0.635869\n",
      "[3]\tvalid_0's balanced_log_loss: 0.619088\n",
      "[4]\tvalid_0's balanced_log_loss: 0.597007\n",
      "[5]\tvalid_0's balanced_log_loss: 0.581439\n",
      "[6]\tvalid_0's balanced_log_loss: 0.563013\n",
      "[7]\tvalid_0's balanced_log_loss: 0.550424\n",
      "[8]\tvalid_0's balanced_log_loss: 0.535307\n",
      "[9]\tvalid_0's balanced_log_loss: 0.523956\n",
      "[10]\tvalid_0's balanced_log_loss: 0.510996\n",
      "[11]\tvalid_0's balanced_log_loss: 0.504203\n",
      "[12]\tvalid_0's balanced_log_loss: 0.499266\n",
      "[13]\tvalid_0's balanced_log_loss: 0.489284\n",
      "[14]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[15]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[16]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[17]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[18]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[19]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[20]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[21]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[22]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[23]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[24]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[25]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[26]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[27]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[28]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[29]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[30]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[31]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[32]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[33]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[34]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[35]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[36]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[37]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[38]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[39]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[40]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[41]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[42]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[43]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[44]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[45]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[46]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[47]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[48]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[49]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[50]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[51]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[52]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[53]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[54]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[55]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[56]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[57]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[58]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[59]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[60]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[61]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[62]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[63]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[64]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[65]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[66]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[67]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[68]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[69]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[70]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[71]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[72]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[73]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[74]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[75]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[76]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[77]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[78]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[79]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[80]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[81]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[82]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[83]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[84]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[85]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[86]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[87]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[88]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[89]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[90]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[91]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[92]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[93]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[94]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[95]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[96]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[97]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[98]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[99]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[100]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[101]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[102]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[103]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[104]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[105]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[106]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[107]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[108]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[109]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[110]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[111]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[112]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[113]\tvalid_0's balanced_log_loss: 0.478167\n",
      "[114]\tvalid_0's balanced_log_loss: 0.478167\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.47817\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.673559\n",
      "[2]\tvalid_0's balanced_log_loss: 0.657083\n",
      "[3]\tvalid_0's balanced_log_loss: 0.643998\n",
      "[4]\tvalid_0's balanced_log_loss: 0.631373\n",
      "[5]\tvalid_0's balanced_log_loss: 0.619198\n",
      "[6]\tvalid_0's balanced_log_loss: 0.608373\n",
      "[7]\tvalid_0's balanced_log_loss: 0.598981\n",
      "[8]\tvalid_0's balanced_log_loss: 0.589837\n",
      "[9]\tvalid_0's balanced_log_loss: 0.58272\n",
      "[10]\tvalid_0's balanced_log_loss: 0.575737\n",
      "[11]\tvalid_0's balanced_log_loss: 0.562674\n",
      "[12]\tvalid_0's balanced_log_loss: 0.560411\n",
      "[13]\tvalid_0's balanced_log_loss: 0.549227\n",
      "[14]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[15]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[16]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[17]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[18]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[19]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[20]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[21]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[22]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[23]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[24]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[25]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[26]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[27]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[28]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[29]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[30]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[31]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[32]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[33]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[34]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[35]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[36]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[37]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[38]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[39]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[40]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[41]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[42]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[43]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[44]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[45]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[46]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[47]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[48]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[49]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[50]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[51]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[52]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[53]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[54]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[55]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[56]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[57]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[58]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[59]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[60]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[61]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[62]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[63]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[64]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[65]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[66]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[67]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[68]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[69]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[70]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[71]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[72]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[73]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[74]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[75]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[76]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[77]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[78]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[79]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[80]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[81]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[82]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[83]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[84]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[85]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[86]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[87]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[88]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[89]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[90]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[91]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[92]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[93]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[94]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[95]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[96]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[97]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[98]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[99]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[100]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[101]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[102]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[103]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[104]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[105]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[106]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[107]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[108]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[109]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[110]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[111]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[112]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[113]\tvalid_0's balanced_log_loss: 0.544669\n",
      "[114]\tvalid_0's balanced_log_loss: 0.544669\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.54467\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.660416\n",
      "[2]\tvalid_0's balanced_log_loss: 0.629376\n",
      "[3]\tvalid_0's balanced_log_loss: 0.609061\n",
      "[4]\tvalid_0's balanced_log_loss: 0.584515\n",
      "[5]\tvalid_0's balanced_log_loss: 0.563271\n",
      "[6]\tvalid_0's balanced_log_loss: 0.542869\n",
      "[7]\tvalid_0's balanced_log_loss: 0.529057\n",
      "[8]\tvalid_0's balanced_log_loss: 0.509365\n",
      "[9]\tvalid_0's balanced_log_loss: 0.498147\n",
      "[10]\tvalid_0's balanced_log_loss: 0.487515\n",
      "[11]\tvalid_0's balanced_log_loss: 0.471704\n",
      "[12]\tvalid_0's balanced_log_loss: 0.468299\n",
      "[13]\tvalid_0's balanced_log_loss: 0.460251\n",
      "[14]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[15]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[16]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[17]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[18]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[19]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[20]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[21]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[22]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[23]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[24]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[25]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[26]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[27]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[28]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[29]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[30]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[31]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[32]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[33]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[34]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[35]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[36]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[37]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[38]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[39]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[40]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[41]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[42]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[43]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[44]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[45]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[46]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[47]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[48]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[49]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[50]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[51]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[52]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[53]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[54]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[55]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[56]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[57]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[58]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[59]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[60]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[61]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[62]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[63]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[64]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[65]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[66]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[67]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[68]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[69]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[70]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[71]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[72]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[73]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[74]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[75]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[76]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[77]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[78]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[79]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[80]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[81]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[82]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[83]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[84]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[85]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[86]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[87]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[88]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[89]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[90]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[91]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[92]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[93]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[94]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[95]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[96]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[97]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[98]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[99]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[100]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[101]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[102]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[103]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[104]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[105]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[106]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[107]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[108]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[109]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[110]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[111]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[112]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[113]\tvalid_0's balanced_log_loss: 0.445917\n",
      "[114]\tvalid_0's balanced_log_loss: 0.445917\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.44592\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.668705\n",
      "[2]\tvalid_0's balanced_log_loss: 0.649252\n",
      "[3]\tvalid_0's balanced_log_loss: 0.628114\n",
      "[4]\tvalid_0's balanced_log_loss: 0.611433\n",
      "[5]\tvalid_0's balanced_log_loss: 0.599755\n",
      "[6]\tvalid_0's balanced_log_loss: 0.574208\n",
      "[7]\tvalid_0's balanced_log_loss: 0.555044\n",
      "[8]\tvalid_0's balanced_log_loss: 0.548407\n",
      "[9]\tvalid_0's balanced_log_loss: 0.539205\n",
      "[10]\tvalid_0's balanced_log_loss: 0.520666\n",
      "[11]\tvalid_0's balanced_log_loss: 0.506596\n",
      "[12]\tvalid_0's balanced_log_loss: 0.501746\n",
      "[13]\tvalid_0's balanced_log_loss: 0.486293\n",
      "[14]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[15]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[16]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[17]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[18]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[19]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[20]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[21]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[22]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[23]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[24]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[25]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[26]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[27]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[28]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[29]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[30]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[31]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[32]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[33]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[34]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[35]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[36]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[37]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[38]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[39]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[40]\tvalid_0's balanced_log_loss: 0.476896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[42]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[43]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[44]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[45]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[46]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[47]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[48]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[49]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[50]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[51]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[52]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[53]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[54]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[55]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[56]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[57]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[58]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[59]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[60]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[61]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[62]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[63]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[64]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[65]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[66]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[67]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[68]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[69]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[70]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[71]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[72]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[73]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[74]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[75]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[76]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[77]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[78]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[79]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[80]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[81]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[82]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[83]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[84]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[85]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[86]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[87]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[88]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[89]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[90]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[91]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[92]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[93]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[94]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[95]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[96]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[97]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[98]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[99]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[100]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[101]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[102]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[103]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[104]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[105]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[106]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[107]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[108]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[109]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[110]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[111]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[112]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[113]\tvalid_0's balanced_log_loss: 0.476896\n",
      "[114]\tvalid_0's balanced_log_loss: 0.476896\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.47690\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "\u001b[1m\u001b[31m CV score: \u001b[0m balanced_log_loss: \u001b[1m\u001b[31m0.48551\u001b[0m\n",
      "**************************************************\n",
      "\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[1]\tvalid_0's balanced_log_loss: 0.656139\n",
      "[2]\tvalid_0's balanced_log_loss: 0.622741\n",
      "[3]\tvalid_0's balanced_log_loss: 0.592034\n",
      "[4]\tvalid_0's balanced_log_loss: 0.561213\n",
      "[5]\tvalid_0's balanced_log_loss: 0.547812\n",
      "[6]\tvalid_0's balanced_log_loss: 0.520008\n",
      "[7]\tvalid_0's balanced_log_loss: 0.498974\n",
      "[8]\tvalid_0's balanced_log_loss: 0.487644\n",
      "[9]\tvalid_0's balanced_log_loss: 0.479237\n",
      "[10]\tvalid_0's balanced_log_loss: 0.4636\n",
      "[11]\tvalid_0's balanced_log_loss: 0.450575\n",
      "[12]\tvalid_0's balanced_log_loss: 0.436057\n",
      "[13]\tvalid_0's balanced_log_loss: 0.421026\n",
      "[14]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[15]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[16]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[17]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[18]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[19]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[20]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[21]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[22]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[23]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[24]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[25]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[26]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[27]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[28]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[29]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[30]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[31]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[32]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[33]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[34]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[35]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[36]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[37]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[38]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[39]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[40]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[41]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[42]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[43]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[44]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[45]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[46]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[47]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[48]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[49]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[50]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[51]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[52]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[53]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[54]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[55]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[56]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[57]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[58]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[59]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[60]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[61]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[62]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[63]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[64]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[65]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[66]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[67]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[68]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[69]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[70]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[71]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[72]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[73]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[74]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[75]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[76]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[77]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[78]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[79]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[80]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[81]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[82]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[83]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[84]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[85]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[86]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[87]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[88]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[89]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[90]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[91]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[92]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[93]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[94]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[95]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[96]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[97]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[98]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[99]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[100]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[101]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[102]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[103]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[104]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[105]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[106]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[107]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[108]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[109]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[110]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[111]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[112]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[113]\tvalid_0's balanced_log_loss: 0.406394\n",
      "[114]\tvalid_0's balanced_log_loss: 0.406394\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.40639\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.664066\n",
      "[2]\tvalid_0's balanced_log_loss: 0.639082\n",
      "[3]\tvalid_0's balanced_log_loss: 0.622754\n",
      "[4]\tvalid_0's balanced_log_loss: 0.60255\n",
      "[5]\tvalid_0's balanced_log_loss: 0.595854\n",
      "[6]\tvalid_0's balanced_log_loss: 0.579417\n",
      "[7]\tvalid_0's balanced_log_loss: 0.567123\n",
      "[8]\tvalid_0's balanced_log_loss: 0.556187\n",
      "[9]\tvalid_0's balanced_log_loss: 0.543268\n",
      "[10]\tvalid_0's balanced_log_loss: 0.528448\n",
      "[11]\tvalid_0's balanced_log_loss: 0.5182\n",
      "[12]\tvalid_0's balanced_log_loss: 0.519331\n",
      "[13]\tvalid_0's balanced_log_loss: 0.509599\n",
      "[14]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[15]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[16]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[17]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[18]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[19]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[20]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[21]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[22]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[23]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[24]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[25]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[26]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[27]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[28]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[29]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[30]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[31]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[32]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[33]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[34]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[35]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[36]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[37]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[38]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[39]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[40]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[41]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[42]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[43]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[44]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[45]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[46]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[47]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[48]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[49]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[50]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[51]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[52]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[53]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[54]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[55]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[56]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[57]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[58]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[59]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[60]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[61]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[62]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[63]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[64]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[65]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[66]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[67]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[68]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[69]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[70]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[71]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[72]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[73]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[74]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[75]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[76]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[77]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[78]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[79]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[80]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[81]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[82]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[83]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[84]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[85]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[86]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[87]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[88]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[89]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[90]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[91]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[92]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[93]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[94]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[95]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[96]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[97]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[98]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[99]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[100]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[101]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[102]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[103]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[104]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[105]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[106]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[107]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[108]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[109]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[110]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[111]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[112]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[113]\tvalid_0's balanced_log_loss: 0.496183\n",
      "[114]\tvalid_0's balanced_log_loss: 0.496183\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.49618\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.660165\n",
      "[2]\tvalid_0's balanced_log_loss: 0.630385\n",
      "[3]\tvalid_0's balanced_log_loss: 0.615819\n",
      "[4]\tvalid_0's balanced_log_loss: 0.599576\n",
      "[5]\tvalid_0's balanced_log_loss: 0.585748\n",
      "[6]\tvalid_0's balanced_log_loss: 0.561737\n",
      "[7]\tvalid_0's balanced_log_loss: 0.542606\n",
      "[8]\tvalid_0's balanced_log_loss: 0.532834\n",
      "[9]\tvalid_0's balanced_log_loss: 0.513045\n",
      "[10]\tvalid_0's balanced_log_loss: 0.497206\n",
      "[11]\tvalid_0's balanced_log_loss: 0.482174\n",
      "[12]\tvalid_0's balanced_log_loss: 0.478968\n",
      "[13]\tvalid_0's balanced_log_loss: 0.467891\n",
      "[14]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[15]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[16]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[17]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[18]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[19]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[20]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[21]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[22]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[23]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[24]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[25]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[26]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[27]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[28]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[29]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[30]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[31]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[32]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[33]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[34]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[35]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[36]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[37]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[38]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[39]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[40]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[41]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[42]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[43]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[44]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[45]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[46]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[47]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[48]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[49]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[50]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[51]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[52]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[53]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[54]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[55]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[56]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[57]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[58]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[59]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[60]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[61]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[62]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[63]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[64]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[65]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[66]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[67]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[68]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[69]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[70]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[71]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[72]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[73]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[74]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[75]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[76]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[77]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[78]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[79]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[80]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[81]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[82]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[83]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[84]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[85]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[86]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[87]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[88]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[89]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[90]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[91]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[92]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[93]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[94]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[95]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[96]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[97]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[98]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[99]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[100]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[101]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[102]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[103]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[104]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[105]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[106]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[107]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[108]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[109]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[110]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[111]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[112]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[113]\tvalid_0's balanced_log_loss: 0.457315\n",
      "[114]\tvalid_0's balanced_log_loss: 0.457315\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.45731\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.662504\n",
      "[2]\tvalid_0's balanced_log_loss: 0.635679\n",
      "[3]\tvalid_0's balanced_log_loss: 0.6082\n",
      "[4]\tvalid_0's balanced_log_loss: 0.576413\n",
      "[5]\tvalid_0's balanced_log_loss: 0.567092\n",
      "[6]\tvalid_0's balanced_log_loss: 0.541823\n",
      "[7]\tvalid_0's balanced_log_loss: 0.521942\n",
      "[8]\tvalid_0's balanced_log_loss: 0.510603\n",
      "[9]\tvalid_0's balanced_log_loss: 0.494167\n",
      "[10]\tvalid_0's balanced_log_loss: 0.479122\n",
      "[11]\tvalid_0's balanced_log_loss: 0.458351\n",
      "[12]\tvalid_0's balanced_log_loss: 0.451882\n",
      "[13]\tvalid_0's balanced_log_loss: 0.433738\n",
      "[14]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[15]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[16]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[17]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[18]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[19]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[20]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[21]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[22]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[23]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[24]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[25]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[26]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[27]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[28]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[29]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[30]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[31]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[32]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[33]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[34]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[35]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[36]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[37]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[38]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[39]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[40]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[41]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[42]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[43]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[44]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[45]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[46]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[47]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[48]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[49]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[50]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[51]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[52]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[53]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[54]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[55]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[56]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[57]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[58]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[59]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[60]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[61]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[62]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[63]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[64]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[65]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[66]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[67]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[68]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[69]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[70]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[71]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[72]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[73]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[74]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[75]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[76]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[77]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[78]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[79]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[80]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[81]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[82]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[83]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[84]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[85]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[86]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[87]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[88]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[89]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[90]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[91]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[92]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[93]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[94]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[95]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[96]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[97]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[98]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[99]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[100]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[101]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[102]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[103]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[104]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[105]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[106]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[107]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[108]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[109]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[110]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[111]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[112]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[113]\tvalid_0's balanced_log_loss: 0.417209\n",
      "[114]\tvalid_0's balanced_log_loss: 0.417209\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.41721\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's balanced_log_loss: 0.661572\n",
      "[2]\tvalid_0's balanced_log_loss: 0.633734\n",
      "[3]\tvalid_0's balanced_log_loss: 0.622212\n",
      "[4]\tvalid_0's balanced_log_loss: 0.599433\n",
      "[5]\tvalid_0's balanced_log_loss: 0.590956\n",
      "[6]\tvalid_0's balanced_log_loss: 0.554559\n",
      "[7]\tvalid_0's balanced_log_loss: 0.528836\n",
      "[8]\tvalid_0's balanced_log_loss: 0.506323\n",
      "[9]\tvalid_0's balanced_log_loss: 0.492589\n",
      "[10]\tvalid_0's balanced_log_loss: 0.478391\n",
      "[11]\tvalid_0's balanced_log_loss: 0.465595\n",
      "[12]\tvalid_0's balanced_log_loss: 0.447033\n",
      "[13]\tvalid_0's balanced_log_loss: 0.436092\n",
      "[14]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[15]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[16]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[17]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[18]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[19]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[20]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[21]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[22]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[23]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[24]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[25]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[26]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[27]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[28]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[29]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[30]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[31]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[32]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[33]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[34]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[35]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[36]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[37]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[38]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[39]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[40]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[41]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[42]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[43]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[44]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[45]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[46]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[47]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[48]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[49]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[50]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[51]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[52]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[53]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[54]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[55]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[56]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[57]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[58]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[59]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[60]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[61]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[62]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[63]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[64]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[65]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[66]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[67]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[68]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[69]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[70]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[71]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[72]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[73]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[74]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[75]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[76]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[77]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[78]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[79]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[80]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[81]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[82]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[83]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[84]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[85]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[86]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[87]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[88]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[89]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[90]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[91]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[92]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[93]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[94]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[95]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[96]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[97]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[98]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[99]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[100]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[101]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[102]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[103]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[104]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[105]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[106]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[107]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[108]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[109]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[110]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[111]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[112]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[113]\tvalid_0's balanced_log_loss: 0.414396\n",
      "[114]\tvalid_0's balanced_log_loss: 0.414396\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.41440\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "\u001b[1m\u001b[31m CV score: \u001b[0m balanced_log_loss: \u001b[1m\u001b[31m0.43850\u001b[0m\n",
      "**************************************************\n",
      "\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[1]\tvalid_0's balanced_log_loss: 0.673541\n",
      "[2]\tvalid_0's balanced_log_loss: 0.656802\n",
      "[3]\tvalid_0's balanced_log_loss: 0.640403\n",
      "[4]\tvalid_0's balanced_log_loss: 0.626625\n",
      "[5]\tvalid_0's balanced_log_loss: 0.610919\n",
      "[6]\tvalid_0's balanced_log_loss: 0.599789\n",
      "[7]\tvalid_0's balanced_log_loss: 0.585353\n",
      "[8]\tvalid_0's balanced_log_loss: 0.577571\n",
      "[9]\tvalid_0's balanced_log_loss: 0.556997\n",
      "[10]\tvalid_0's balanced_log_loss: 0.549232\n",
      "[11]\tvalid_0's balanced_log_loss: 0.539458\n",
      "[12]\tvalid_0's balanced_log_loss: 0.518356\n",
      "[13]\tvalid_0's balanced_log_loss: 0.511205\n",
      "[14]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[15]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[16]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[17]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[18]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[19]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[20]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[21]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[22]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[23]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[24]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[25]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[26]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[27]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[28]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[29]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[30]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[31]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[32]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[33]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[34]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[35]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[36]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[37]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[38]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[39]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[40]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[41]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[42]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[43]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[44]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[45]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[46]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[47]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[48]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[49]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[50]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[51]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[52]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[53]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[54]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[55]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[56]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[57]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[58]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[59]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[60]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[61]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[62]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[63]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[64]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[65]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[66]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[67]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[68]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[69]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[70]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[71]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[72]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[73]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[74]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[75]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[76]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[77]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[78]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[79]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[80]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[81]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[82]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[83]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[84]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[85]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[86]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[87]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[88]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[89]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[90]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[91]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[92]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[93]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[94]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[95]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[96]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[97]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[98]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[99]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[100]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[101]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[102]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[103]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[104]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[105]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[106]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[107]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[108]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[109]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[110]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[111]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[112]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[113]\tvalid_0's balanced_log_loss: 0.506414\n",
      "[114]\tvalid_0's balanced_log_loss: 0.506414\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.50641\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.66459\n",
      "[2]\tvalid_0's balanced_log_loss: 0.644849\n",
      "[3]\tvalid_0's balanced_log_loss: 0.62978\n",
      "[4]\tvalid_0's balanced_log_loss: 0.61093\n",
      "[5]\tvalid_0's balanced_log_loss: 0.59296\n",
      "[6]\tvalid_0's balanced_log_loss: 0.582323\n",
      "[7]\tvalid_0's balanced_log_loss: 0.56482\n",
      "[8]\tvalid_0's balanced_log_loss: 0.550988\n",
      "[9]\tvalid_0's balanced_log_loss: 0.548338\n",
      "[10]\tvalid_0's balanced_log_loss: 0.53407\n",
      "[11]\tvalid_0's balanced_log_loss: 0.525078\n",
      "[12]\tvalid_0's balanced_log_loss: 0.524259\n",
      "[13]\tvalid_0's balanced_log_loss: 0.513812\n",
      "[14]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[15]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[16]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[17]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[18]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[19]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[20]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[21]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[22]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[23]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[24]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[25]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[26]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[27]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[28]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[29]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[30]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[31]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[32]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[33]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[34]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[35]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[36]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[37]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[38]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[39]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[40]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[41]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[42]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[43]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[44]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[45]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[46]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[47]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[48]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[49]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[50]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[51]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[52]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[53]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[54]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[55]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[56]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[57]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[58]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[59]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[60]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[61]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[62]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[63]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[64]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[65]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[66]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[67]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[68]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[69]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[70]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[71]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[72]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[73]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[74]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[75]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[76]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[77]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[78]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[79]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[80]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[81]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[82]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[83]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[84]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[85]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[86]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[87]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[88]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[89]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[90]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[91]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[92]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[93]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[94]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[95]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[96]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[97]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[98]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[99]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[100]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[101]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[102]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[103]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[104]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[105]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[106]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[107]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[108]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[109]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[110]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[111]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[112]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[113]\tvalid_0's balanced_log_loss: 0.502556\n",
      "[114]\tvalid_0's balanced_log_loss: 0.502556\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.50256\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.672073\n",
      "[2]\tvalid_0's balanced_log_loss: 0.653544\n",
      "[3]\tvalid_0's balanced_log_loss: 0.643759\n",
      "[4]\tvalid_0's balanced_log_loss: 0.612039\n",
      "[5]\tvalid_0's balanced_log_loss: 0.599381\n",
      "[6]\tvalid_0's balanced_log_loss: 0.572405\n",
      "[7]\tvalid_0's balanced_log_loss: 0.570252\n",
      "[8]\tvalid_0's balanced_log_loss: 0.56116\n",
      "[9]\tvalid_0's balanced_log_loss: 0.549536\n",
      "[10]\tvalid_0's balanced_log_loss: 0.527498\n",
      "[11]\tvalid_0's balanced_log_loss: 0.512671\n",
      "[12]\tvalid_0's balanced_log_loss: 0.507899\n",
      "[13]\tvalid_0's balanced_log_loss: 0.504647\n",
      "[14]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[15]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[16]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[17]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[18]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[19]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[20]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[21]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[22]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[23]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[24]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[25]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[26]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[27]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[28]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[29]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[30]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[31]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[32]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[33]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[34]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[35]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[36]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[37]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[38]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[39]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[40]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[41]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[42]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[43]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[44]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[45]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[46]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[47]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[48]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[49]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[50]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[51]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[52]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[53]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[54]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[55]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[56]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[57]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[58]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[59]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[60]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[61]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[62]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[63]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[64]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[65]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[66]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[67]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[68]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[69]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[70]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[71]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[72]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[73]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[74]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[75]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[76]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[77]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[78]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[79]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[80]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[81]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[82]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[83]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[84]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[85]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[86]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[87]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[88]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[89]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[90]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[91]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[92]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[93]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[94]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[95]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[96]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[97]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[98]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[99]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[100]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[101]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[102]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[103]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[104]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[105]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[106]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[107]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[108]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[109]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[110]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[111]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[112]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[113]\tvalid_0's balanced_log_loss: 0.490102\n",
      "[114]\tvalid_0's balanced_log_loss: 0.490102\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.49010\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.660746\n",
      "[2]\tvalid_0's balanced_log_loss: 0.632626\n",
      "[3]\tvalid_0's balanced_log_loss: 0.617329\n",
      "[4]\tvalid_0's balanced_log_loss: 0.583569\n",
      "[5]\tvalid_0's balanced_log_loss: 0.566093\n",
      "[6]\tvalid_0's balanced_log_loss: 0.538124\n",
      "[7]\tvalid_0's balanced_log_loss: 0.523214\n",
      "[8]\tvalid_0's balanced_log_loss: 0.515133\n",
      "[9]\tvalid_0's balanced_log_loss: 0.501771\n",
      "[10]\tvalid_0's balanced_log_loss: 0.487437\n",
      "[11]\tvalid_0's balanced_log_loss: 0.476423\n",
      "[12]\tvalid_0's balanced_log_loss: 0.4672\n",
      "[13]\tvalid_0's balanced_log_loss: 0.451241\n",
      "[14]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[15]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[16]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[17]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[18]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[19]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[20]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[21]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[22]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[23]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[24]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[25]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[26]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[27]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[28]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[29]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[30]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[31]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[32]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[33]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[34]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[35]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[36]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[37]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[38]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[39]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[40]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[41]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[42]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[43]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[44]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[45]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[46]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[47]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[48]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[49]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[50]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[51]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[52]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[53]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[54]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[55]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[56]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[57]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[58]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[59]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[60]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[61]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[62]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[63]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[64]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[65]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[66]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[67]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[68]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[69]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[70]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[71]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[72]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[73]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[74]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[75]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[76]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[77]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[78]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[79]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[80]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[81]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[82]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[83]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[84]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[85]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[86]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[87]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[88]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[89]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[90]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[91]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[92]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[93]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[94]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[95]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[96]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[97]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[98]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[99]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[100]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[101]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[102]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[103]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[104]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[105]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[106]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[107]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[108]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[109]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[110]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[111]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[112]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[113]\tvalid_0's balanced_log_loss: 0.434786\n",
      "[114]\tvalid_0's balanced_log_loss: 0.434786\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.43479\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.659508\n",
      "[2]\tvalid_0's balanced_log_loss: 0.636037\n",
      "[3]\tvalid_0's balanced_log_loss: 0.621338\n",
      "[4]\tvalid_0's balanced_log_loss: 0.596526\n",
      "[5]\tvalid_0's balanced_log_loss: 0.58425\n",
      "[6]\tvalid_0's balanced_log_loss: 0.563071\n",
      "[7]\tvalid_0's balanced_log_loss: 0.55054\n",
      "[8]\tvalid_0's balanced_log_loss: 0.544325\n",
      "[9]\tvalid_0's balanced_log_loss: 0.535839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's balanced_log_loss: 0.524836\n",
      "[11]\tvalid_0's balanced_log_loss: 0.507324\n",
      "[12]\tvalid_0's balanced_log_loss: 0.495464\n",
      "[13]\tvalid_0's balanced_log_loss: 0.483312\n",
      "[14]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[15]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[16]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[17]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[18]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[19]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[20]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[21]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[22]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[23]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[24]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[25]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[26]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[27]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[28]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[29]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[30]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[31]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[32]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[33]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[34]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[35]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[36]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[37]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[38]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[39]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[40]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[41]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[42]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[43]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[44]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[45]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[46]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[47]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[48]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[49]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[50]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[51]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[52]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[53]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[54]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[55]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[56]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[57]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[58]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[59]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[60]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[61]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[62]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[63]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[64]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[65]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[66]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[67]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[68]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[69]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[70]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[71]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[72]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[73]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[74]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[75]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[76]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[77]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[78]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[79]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[80]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[81]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[82]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[83]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[84]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[85]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[86]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[87]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[88]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[89]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[90]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[91]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[92]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[93]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[94]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[95]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[96]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[97]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[98]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[99]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[100]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[101]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[102]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[103]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[104]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[105]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[106]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[107]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[108]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[109]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[110]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[111]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[112]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[113]\tvalid_0's balanced_log_loss: 0.47058\n",
      "[114]\tvalid_0's balanced_log_loss: 0.47058\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.47058\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "\u001b[1m\u001b[31m CV score: \u001b[0m balanced_log_loss: \u001b[1m\u001b[31m0.48073\u001b[0m\n",
      "**************************************************\n",
      "\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[1]\tvalid_0's balanced_log_loss: 0.669142\n",
      "[2]\tvalid_0's balanced_log_loss: 0.646188\n",
      "[3]\tvalid_0's balanced_log_loss: 0.619062\n",
      "[4]\tvalid_0's balanced_log_loss: 0.588117\n",
      "[5]\tvalid_0's balanced_log_loss: 0.559888\n",
      "[6]\tvalid_0's balanced_log_loss: 0.542658\n",
      "[7]\tvalid_0's balanced_log_loss: 0.52341\n",
      "[8]\tvalid_0's balanced_log_loss: 0.51945\n",
      "[9]\tvalid_0's balanced_log_loss: 0.513151\n",
      "[10]\tvalid_0's balanced_log_loss: 0.504214\n",
      "[11]\tvalid_0's balanced_log_loss: 0.485374\n",
      "[12]\tvalid_0's balanced_log_loss: 0.48031\n",
      "[13]\tvalid_0's balanced_log_loss: 0.474278\n",
      "[14]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[15]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[16]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[17]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[18]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[19]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[20]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[21]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[22]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[23]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[24]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[25]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[26]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[27]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[28]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[29]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[30]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[31]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[32]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[33]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[34]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[35]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[36]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[37]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[38]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[39]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[40]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[41]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[42]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[43]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[44]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[45]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[46]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[47]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[48]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[49]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[50]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[51]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[52]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[53]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[54]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[55]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[56]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[57]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[58]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[59]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[60]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[61]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[62]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[63]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[64]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[65]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[66]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[67]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[68]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[69]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[70]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[71]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[72]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[73]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[74]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[75]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[76]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[77]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[78]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[79]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[80]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[81]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[82]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[83]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[84]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[85]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[86]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[87]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[88]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[89]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[90]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[91]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[92]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[93]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[94]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[95]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[96]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[97]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[98]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[99]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[100]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[101]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[102]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[103]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[104]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[105]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[106]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[107]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[108]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[109]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[110]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[111]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[112]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[113]\tvalid_0's balanced_log_loss: 0.466963\n",
      "[114]\tvalid_0's balanced_log_loss: 0.466963\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.46696\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.660741\n",
      "[2]\tvalid_0's balanced_log_loss: 0.63859\n",
      "[3]\tvalid_0's balanced_log_loss: 0.620687\n",
      "[4]\tvalid_0's balanced_log_loss: 0.592764\n",
      "[5]\tvalid_0's balanced_log_loss: 0.585129\n",
      "[6]\tvalid_0's balanced_log_loss: 0.563593\n",
      "[7]\tvalid_0's balanced_log_loss: 0.550066\n",
      "[8]\tvalid_0's balanced_log_loss: 0.538841\n",
      "[9]\tvalid_0's balanced_log_loss: 0.534906\n",
      "[10]\tvalid_0's balanced_log_loss: 0.516797\n",
      "[11]\tvalid_0's balanced_log_loss: 0.501149\n",
      "[12]\tvalid_0's balanced_log_loss: 0.496751\n",
      "[13]\tvalid_0's balanced_log_loss: 0.486435\n",
      "[14]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[15]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[16]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[17]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[18]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[19]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[20]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[21]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[22]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[23]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[24]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[25]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[26]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[27]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[28]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[29]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[30]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[31]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[32]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[33]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[34]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[35]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[36]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[37]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[38]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[39]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[40]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[41]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[42]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[43]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[44]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[45]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[46]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[47]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[48]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[49]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[50]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[51]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[52]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[53]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[54]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[55]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[56]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[57]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[58]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[59]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[60]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[61]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[62]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[63]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[64]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[65]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[66]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[67]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[68]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[69]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[70]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[71]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[72]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[73]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[74]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[75]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[76]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[77]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[78]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[79]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[80]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[81]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[82]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[83]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[84]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[85]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[86]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[87]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[88]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[89]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[90]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[91]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[92]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[93]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[94]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[95]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[96]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[97]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[98]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[99]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[100]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[101]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[102]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[103]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[104]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[105]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[106]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[107]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[108]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[109]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[110]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[111]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[112]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[113]\tvalid_0's balanced_log_loss: 0.472467\n",
      "[114]\tvalid_0's balanced_log_loss: 0.472467\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.47247\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.657473\n",
      "[2]\tvalid_0's balanced_log_loss: 0.625076\n",
      "[3]\tvalid_0's balanced_log_loss: 0.618214\n",
      "[4]\tvalid_0's balanced_log_loss: 0.591593\n",
      "[5]\tvalid_0's balanced_log_loss: 0.575252\n",
      "[6]\tvalid_0's balanced_log_loss: 0.552819\n",
      "[7]\tvalid_0's balanced_log_loss: 0.538973\n",
      "[8]\tvalid_0's balanced_log_loss: 0.530854\n",
      "[9]\tvalid_0's balanced_log_loss: 0.517003\n",
      "[10]\tvalid_0's balanced_log_loss: 0.496256\n",
      "[11]\tvalid_0's balanced_log_loss: 0.481702\n",
      "[12]\tvalid_0's balanced_log_loss: 0.465586\n",
      "[13]\tvalid_0's balanced_log_loss: 0.452175\n",
      "[14]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[15]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[16]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[17]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[18]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[19]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[20]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[21]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[22]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[23]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[24]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[25]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[26]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[27]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[28]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[29]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[30]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[31]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[32]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[33]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[34]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[35]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[36]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[37]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[38]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[39]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[40]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[41]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[42]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[43]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[44]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[45]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[46]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[47]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[48]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[49]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[50]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[51]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[52]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[53]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[54]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[55]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[56]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[57]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[58]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[59]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[60]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[61]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[62]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[63]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[64]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[65]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[66]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[67]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[68]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[69]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[70]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[71]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[72]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[73]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[74]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[75]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[76]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[77]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[78]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[79]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[80]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[81]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[82]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[83]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[84]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[85]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[86]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[87]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[88]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[89]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[90]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[91]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[92]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[93]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[94]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[95]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[96]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[97]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[98]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[99]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[100]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[101]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[102]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[103]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[104]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[105]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[106]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[107]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[108]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[109]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[110]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[111]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[112]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[113]\tvalid_0's balanced_log_loss: 0.4429\n",
      "[114]\tvalid_0's balanced_log_loss: 0.4429\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.44290\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.660801\n",
      "[2]\tvalid_0's balanced_log_loss: 0.634607\n",
      "[3]\tvalid_0's balanced_log_loss: 0.614481\n",
      "[4]\tvalid_0's balanced_log_loss: 0.592058\n",
      "[5]\tvalid_0's balanced_log_loss: 0.579019\n",
      "[6]\tvalid_0's balanced_log_loss: 0.555914\n",
      "[7]\tvalid_0's balanced_log_loss: 0.540307\n",
      "[8]\tvalid_0's balanced_log_loss: 0.524857\n",
      "[9]\tvalid_0's balanced_log_loss: 0.511633\n",
      "[10]\tvalid_0's balanced_log_loss: 0.494647\n",
      "[11]\tvalid_0's balanced_log_loss: 0.47966\n",
      "[12]\tvalid_0's balanced_log_loss: 0.469108\n",
      "[13]\tvalid_0's balanced_log_loss: 0.45881\n",
      "[14]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[15]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[16]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[17]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[18]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[19]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[20]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[21]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[22]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[23]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[24]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[25]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[26]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[27]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[28]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[29]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[30]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[31]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[32]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[33]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[34]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[35]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[36]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[37]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[38]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[39]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[40]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[41]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[42]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[43]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[44]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[45]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[46]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[47]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[48]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[49]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[50]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[51]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[52]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[53]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[54]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[55]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[56]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[57]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[58]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[59]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[60]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[61]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[62]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[63]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[64]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[65]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[66]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[67]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[68]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[69]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[70]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[71]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[72]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[73]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[74]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[75]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[76]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[77]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[78]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[79]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[80]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[81]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[82]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[83]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[84]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[85]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[86]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[87]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[88]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[89]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[90]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[91]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[92]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[93]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[94]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[95]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[96]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[97]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[98]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[99]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[100]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[101]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[102]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[103]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[104]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[105]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[106]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[107]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[108]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[109]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[110]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[111]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[112]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[113]\tvalid_0's balanced_log_loss: 0.451291\n",
      "[114]\tvalid_0's balanced_log_loss: 0.451291\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.45129\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's balanced_log_loss: 0.660084\n",
      "[2]\tvalid_0's balanced_log_loss: 0.632845\n",
      "[3]\tvalid_0's balanced_log_loss: 0.614469\n",
      "[4]\tvalid_0's balanced_log_loss: 0.591348\n",
      "[5]\tvalid_0's balanced_log_loss: 0.570386\n",
      "[6]\tvalid_0's balanced_log_loss: 0.551285\n",
      "[7]\tvalid_0's balanced_log_loss: 0.536158\n",
      "[8]\tvalid_0's balanced_log_loss: 0.52579\n",
      "[9]\tvalid_0's balanced_log_loss: 0.516911\n",
      "[10]\tvalid_0's balanced_log_loss: 0.50592\n",
      "[11]\tvalid_0's balanced_log_loss: 0.494012\n",
      "[12]\tvalid_0's balanced_log_loss: 0.48363\n",
      "[13]\tvalid_0's balanced_log_loss: 0.476049\n",
      "[14]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[15]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[16]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[17]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[18]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[19]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[20]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[21]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[22]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[23]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[24]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[25]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[26]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[27]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[28]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[29]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[30]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[31]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[32]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[33]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[34]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[35]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[36]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[37]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[38]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[39]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[40]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[41]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[42]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[43]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[44]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[45]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[46]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[47]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[48]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[49]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[50]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[51]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[52]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[53]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[54]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[55]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[56]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[57]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[58]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[59]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[60]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[61]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[62]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[63]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[64]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[65]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[66]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[67]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[68]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[69]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[70]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[71]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[72]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[73]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[74]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[75]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[76]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[77]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[78]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[79]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[80]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[81]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[82]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[83]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[84]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[85]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[86]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[87]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[88]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[89]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[90]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[91]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[92]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[93]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[94]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[95]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[96]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[97]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[98]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[99]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[100]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[101]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[102]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[103]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[104]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[105]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[106]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[107]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[108]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[109]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[110]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[111]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[112]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[113]\tvalid_0's balanced_log_loss: 0.469509\n",
      "[114]\tvalid_0's balanced_log_loss: 0.469509\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.46951\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "\u001b[1m\u001b[31m CV score: \u001b[0m balanced_log_loss: \u001b[1m\u001b[31m0.46259\u001b[0m\n",
      "**************************************************\n",
      "\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[1]\tvalid_0's balanced_log_loss: 0.64773\n",
      "[2]\tvalid_0's balanced_log_loss: 0.61567\n",
      "[3]\tvalid_0's balanced_log_loss: 0.592656\n",
      "[4]\tvalid_0's balanced_log_loss: 0.560769\n",
      "[5]\tvalid_0's balanced_log_loss: 0.546413\n",
      "[6]\tvalid_0's balanced_log_loss: 0.523424\n",
      "[7]\tvalid_0's balanced_log_loss: 0.504202\n",
      "[8]\tvalid_0's balanced_log_loss: 0.487708\n",
      "[9]\tvalid_0's balanced_log_loss: 0.477939\n",
      "[10]\tvalid_0's balanced_log_loss: 0.456773\n",
      "[11]\tvalid_0's balanced_log_loss: 0.442846\n",
      "[12]\tvalid_0's balanced_log_loss: 0.434141\n",
      "[13]\tvalid_0's balanced_log_loss: 0.41962\n",
      "[14]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[15]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[16]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[17]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[18]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[19]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[20]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[21]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[22]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[23]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[24]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[25]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[26]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[27]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[28]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[29]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[30]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[31]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[32]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[33]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[34]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[35]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[36]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[37]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[38]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[39]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[40]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[41]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[42]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[43]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[44]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[45]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[46]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[47]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[48]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[49]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[50]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[51]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[52]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[53]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[54]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[55]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[56]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[57]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[58]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[59]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[60]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[61]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[62]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[63]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[64]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[65]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[66]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[67]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[68]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[69]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[70]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[71]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[72]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[73]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[74]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[75]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[76]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[77]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[78]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[79]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[80]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[81]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[82]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[83]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[84]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[85]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[86]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[87]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[88]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[89]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[90]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[91]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[92]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[93]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[94]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[95]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[96]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[97]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[98]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[99]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[100]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[101]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[102]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[103]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[104]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[105]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[106]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[107]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[108]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[109]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[110]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[111]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[112]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[113]\tvalid_0's balanced_log_loss: 0.405152\n",
      "[114]\tvalid_0's balanced_log_loss: 0.405152\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.40515\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.669434\n",
      "[2]\tvalid_0's balanced_log_loss: 0.649777\n",
      "[3]\tvalid_0's balanced_log_loss: 0.635653\n",
      "[4]\tvalid_0's balanced_log_loss: 0.619833\n",
      "[5]\tvalid_0's balanced_log_loss: 0.589155\n",
      "[6]\tvalid_0's balanced_log_loss: 0.576798\n",
      "[7]\tvalid_0's balanced_log_loss: 0.551336\n",
      "[8]\tvalid_0's balanced_log_loss: 0.531932\n",
      "[9]\tvalid_0's balanced_log_loss: 0.510662\n",
      "[10]\tvalid_0's balanced_log_loss: 0.493428\n",
      "[11]\tvalid_0's balanced_log_loss: 0.47775\n",
      "[12]\tvalid_0's balanced_log_loss: 0.461075\n",
      "[13]\tvalid_0's balanced_log_loss: 0.447605\n",
      "[14]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[15]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[16]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[17]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[18]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[19]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[20]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[21]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[22]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[23]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[24]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[25]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[26]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[27]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[28]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[29]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[30]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[31]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[32]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[33]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[34]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[35]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[36]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[37]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[38]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[39]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[40]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[41]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[42]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[43]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[44]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[45]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[46]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[47]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[48]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[49]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[50]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[51]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[52]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[53]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[54]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[55]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[56]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[57]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[58]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[59]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[60]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[61]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[62]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[63]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[64]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[65]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[66]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[67]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[68]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[69]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[70]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[71]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[72]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[73]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[74]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[75]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[76]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[77]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[78]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[79]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[80]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[81]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[82]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[83]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[84]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[85]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[86]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[87]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[88]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[89]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[90]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[91]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[92]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[93]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[94]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[95]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[96]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[97]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[98]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[99]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[100]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[101]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[102]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[103]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[104]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[105]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[106]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[107]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[108]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[109]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[110]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[111]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[112]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[113]\tvalid_0's balanced_log_loss: 0.436916\n",
      "[114]\tvalid_0's balanced_log_loss: 0.436916\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.43692\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.669013\n",
      "[2]\tvalid_0's balanced_log_loss: 0.646189\n",
      "[3]\tvalid_0's balanced_log_loss: 0.629999\n",
      "[4]\tvalid_0's balanced_log_loss: 0.604273\n",
      "[5]\tvalid_0's balanced_log_loss: 0.586412\n",
      "[6]\tvalid_0's balanced_log_loss: 0.569944\n",
      "[7]\tvalid_0's balanced_log_loss: 0.554133\n",
      "[8]\tvalid_0's balanced_log_loss: 0.548813\n",
      "[9]\tvalid_0's balanced_log_loss: 0.545793\n",
      "[10]\tvalid_0's balanced_log_loss: 0.528406\n",
      "[11]\tvalid_0's balanced_log_loss: 0.519566\n",
      "[12]\tvalid_0's balanced_log_loss: 0.51039\n",
      "[13]\tvalid_0's balanced_log_loss: 0.506385\n",
      "[14]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[15]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[16]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[17]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[18]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[19]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[20]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[21]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[22]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[23]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[24]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[25]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[26]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[27]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[28]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[29]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[30]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[31]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[32]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[33]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[34]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[35]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[36]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[37]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[38]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[39]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[40]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[41]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[42]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[43]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[44]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[45]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[46]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[47]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[48]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[49]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[50]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[51]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[52]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[53]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[54]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[55]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[56]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[57]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[58]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[59]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[60]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[61]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[62]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[63]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[64]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[65]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[66]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[67]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[68]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[69]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[70]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[71]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[72]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[73]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[74]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[75]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[76]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[77]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[78]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[79]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[80]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[81]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[82]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[83]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[84]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[85]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[86]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[87]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[88]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[89]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[90]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[91]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[92]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[93]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[94]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[95]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[96]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[97]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[98]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[99]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[100]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[101]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[102]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[103]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[104]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[105]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[106]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[107]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[108]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[109]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[110]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[111]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[112]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[113]\tvalid_0's balanced_log_loss: 0.500829\n",
      "[114]\tvalid_0's balanced_log_loss: 0.500829\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.50083\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.664255\n",
      "[2]\tvalid_0's balanced_log_loss: 0.635275\n",
      "[3]\tvalid_0's balanced_log_loss: 0.625776\n",
      "[4]\tvalid_0's balanced_log_loss: 0.601958\n",
      "[5]\tvalid_0's balanced_log_loss: 0.580817\n",
      "[6]\tvalid_0's balanced_log_loss: 0.555293\n",
      "[7]\tvalid_0's balanced_log_loss: 0.533067\n",
      "[8]\tvalid_0's balanced_log_loss: 0.518681\n",
      "[9]\tvalid_0's balanced_log_loss: 0.510199\n",
      "[10]\tvalid_0's balanced_log_loss: 0.488533\n",
      "[11]\tvalid_0's balanced_log_loss: 0.480483\n",
      "[12]\tvalid_0's balanced_log_loss: 0.467656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\tvalid_0's balanced_log_loss: 0.45206\n",
      "[14]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[15]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[16]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[17]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[18]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[19]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[20]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[21]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[22]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[23]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[24]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[25]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[26]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[27]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[28]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[29]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[30]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[31]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[32]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[33]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[34]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[35]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[36]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[37]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[38]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[39]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[40]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[41]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[42]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[43]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[44]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[45]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[46]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[47]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[48]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[49]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[50]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[51]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[52]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[53]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[54]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[55]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[56]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[57]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[58]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[59]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[60]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[61]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[62]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[63]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[64]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[65]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[66]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[67]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[68]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[69]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[70]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[71]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[72]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[73]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[74]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[75]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[76]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[77]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[78]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[79]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[80]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[81]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[82]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[83]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[84]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[85]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[86]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[87]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[88]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[89]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[90]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[91]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[92]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[93]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[94]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[95]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[96]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[97]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[98]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[99]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[100]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[101]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[102]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[103]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[104]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[105]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[106]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[107]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[108]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[109]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[110]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[111]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[112]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[113]\tvalid_0's balanced_log_loss: 0.440944\n",
      "[114]\tvalid_0's balanced_log_loss: 0.440944\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.44094\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "[1]\tvalid_0's balanced_log_loss: 0.661504\n",
      "[2]\tvalid_0's balanced_log_loss: 0.635035\n",
      "[3]\tvalid_0's balanced_log_loss: 0.613878\n",
      "[4]\tvalid_0's balanced_log_loss: 0.591125\n",
      "[5]\tvalid_0's balanced_log_loss: 0.570132\n",
      "[6]\tvalid_0's balanced_log_loss: 0.547656\n",
      "[7]\tvalid_0's balanced_log_loss: 0.527565\n",
      "[8]\tvalid_0's balanced_log_loss: 0.513254\n",
      "[9]\tvalid_0's balanced_log_loss: 0.498137\n",
      "[10]\tvalid_0's balanced_log_loss: 0.488166\n",
      "[11]\tvalid_0's balanced_log_loss: 0.472289\n",
      "[12]\tvalid_0's balanced_log_loss: 0.460786\n",
      "[13]\tvalid_0's balanced_log_loss: 0.448772\n",
      "[14]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[15]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[16]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[17]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[18]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[19]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[20]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[21]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[22]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[23]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[24]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[25]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[26]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[27]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[28]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[29]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[30]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[31]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[32]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[33]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[34]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[35]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[36]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[37]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[38]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[39]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[40]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[41]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[42]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[43]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[44]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[45]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[46]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[47]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[48]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[49]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[50]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[51]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[52]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[53]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[54]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[55]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[56]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[57]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[58]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[59]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[60]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[61]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[62]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[63]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[64]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[65]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[66]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[67]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[68]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[69]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[70]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[71]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[72]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[73]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[74]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[75]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[76]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[77]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[78]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[79]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[80]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[81]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[82]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[83]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[84]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[85]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[86]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[87]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[88]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[89]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[90]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[91]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[92]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[93]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[94]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[95]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[96]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[97]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[98]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[99]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[100]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[101]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[102]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[103]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[104]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[105]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[106]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[107]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[108]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[109]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[110]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[111]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[112]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[113]\tvalid_0's balanced_log_loss: 0.436536\n",
      "[114]\tvalid_0's balanced_log_loss: 0.436536\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| balanced_log_loss: \u001b[1m\u001b[34m0.43654\u001b[0m | Best iteration: \u001b[1m\u001b[34m  14\u001b[0m\n",
      "\u001b[1m\u001b[31m CV score: \u001b[0m balanced_log_loss: \u001b[1m\u001b[31m0.43963\u001b[0m\n",
      "**************************************************\n",
      "\n",
      "\u001b[1m\u001b[31m Avg score 5-fold: \u001b[0m balanced_log_loss: \u001b[1m\u001b[31m0.46139\u001b[0m\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from shaphypetune import BoostBoruta\n",
    "\n",
    "params = {\n",
    "        'boosting_type':'goss',\n",
    "        'learning_rate': 0.06733232950390658, \n",
    "        'n_estimators': 5000, \n",
    "        'early_stopping_round' : 100, \n",
    "        'subsample' : 0.7, # bagging_fraction\n",
    "        'colsample_bytree': 0.6, # feature_fraction\n",
    "        'num_leaves': 33,\n",
    "        'class_weight': 'balanced',\n",
    "        'metric': 'none', \n",
    "        'is_unbalance': True, \n",
    "        'random_state': 8062023,\n",
    "        'feature_fraction_seed': 8062023,\n",
    "        'bagging_seed': 8062023,\n",
    "        'max_depth': 6,\n",
    "        'reg_alpha': 2.025436e-04,  \n",
    "        'reg_lambda': 2.290193e-07,\n",
    "#         'bagging_freq': 6,\n",
    "        'max_bin': 198,\n",
    "        'min_child_samples': 32,\n",
    "        'importance_type': 'gain'\n",
    "        }\n",
    "\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability  is replaced with max(min(,11015),1015)\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1 - y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2\n",
    "\n",
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def calc_log_loss_weight(y_true): \n",
    "    '''w0, w1 assign different weights to individual data points during training.'''\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    return w0, w1\n",
    "\n",
    "def lgbm_tuning(features, permut=False, boruta=False):\n",
    "    metric = balanced_log_loss\n",
    "    eval_results_ = {}\n",
    "\n",
    "    cv_scores = [] # store all cv scores of outer loop inference\n",
    "\n",
    "    perm_df_ = pd.DataFrame()\n",
    "    feature_importances_ = pd.DataFrame()\n",
    "    boruta_df_ = pd.DataFrame()\n",
    "    \n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "        \n",
    "        # Make random under-sampling to balance classes\n",
    "        positive_count_train = train_df.Class.value_counts()[1]\n",
    "        sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                        1: positive_count_train}, \n",
    "                                     random_state=15062023+i, \n",
    "                                     replacement=True)\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=8062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "        \n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start = 1): \n",
    "            X, y = X_re[features], y_re\n",
    "\n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "\n",
    "            X_train = X_train.reset_index(drop=True)\n",
    "            y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "            # Store models here\n",
    "            models_ = [] \n",
    "\n",
    "            eval_results_[fold]= {}\n",
    "\n",
    "            clf = lgb.LGBMClassifier(**params)\n",
    "            clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                    eval_metric=bll_metric, # eval_sample_weight=w_val, \n",
    "                    early_stopping_rounds=100, verbose=1)\n",
    "\n",
    "            models_.append(clf)\n",
    "\n",
    "            val_preds = clf.predict_proba(X_val)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "\n",
    "            val_score = metric(y_val, val_preds)\n",
    "            best_iter = clf.best_iteration_\n",
    "\n",
    "            print(f'Fold: {blu}{fold:>3}{res}| {metric.__name__}: {blu}{val_score:.5f}{res}'\n",
    "                  f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "\n",
    "            # permutation importance\n",
    "            if permut:\n",
    "                perm = PermutationImportance(clf, scoring=None, n_iter=1, \n",
    "                                             random_state=42, cv=None, refit=False).fit(X_val, y_val)\n",
    "\n",
    "                perm_importance_df = pd.DataFrame({'importance': perm.feature_importances_}, \n",
    "                                                   index=X_val.columns).sort_index()\n",
    "\n",
    "                if perm_df_.shape[0] == 0:\n",
    "                    perm_df_ = perm_importance_df.copy()\n",
    "                else:\n",
    "                    perm_df_ += perm_importance_df\n",
    "\n",
    "            # tree feature importance\n",
    "            f_i = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns), \n",
    "                                              reverse=True, key=lambda x: x[1]), \n",
    "                               columns=['Value','Feature'])\n",
    "\n",
    "            if feature_importances_.shape[0] == 0:\n",
    "                feature_importances_ = f_i.copy()\n",
    "            else:\n",
    "\n",
    "                feature_importances_['Value'] += f_i['Value']\n",
    "\n",
    "            # Boruta SHAP importance\n",
    "            if boruta:\n",
    "                model = BoostBoruta(clf, importance_type='shap_importances', train_importance=False)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                          eval_metric=bll_metric, early_stopping_rounds=300, verbose=-1)\n",
    "\n",
    "                boruta_importance_df = pd.DataFrame({'importance': model.ranking_}, \n",
    "                                                     index=X_train.columns).sort_index()\n",
    "                if boruta_df_.shape[0] == 0:\n",
    "                    boruta_df_ = boruta_importance_df.copy()\n",
    "                else:\n",
    "                    boruta_df_ += boruta_importance_df\n",
    "\n",
    "        fold_cv_score = metric(y_re, oof)\n",
    "        print(f'{red} CV score: {res} {metric.__name__}: {red}{fold_cv_score:.5f}{res}')\n",
    "        print(f'{\"*\" * 50}\\n')\n",
    "        cv_scores.append(fold_cv_score)\n",
    "\n",
    "\n",
    "    print(f'{red} Avg score {CFG.n_feature_sel_folds}-fold: {res} {metric.__name__}: {red}{np.mean(cv_scores):.5f}{res}')\n",
    "    print(f'{\"*\" * 50}\\n')\n",
    "    \n",
    "    if permut:\n",
    "        perm_df_ = perm_df_.sort_values('importance', ascending=False)\n",
    "        \n",
    "    if boruta:\n",
    "        boruta_df_ = boruta_df_.sort_values('importance')\n",
    "                                    \n",
    "    feature_importances_ = feature_importances_.sort_values('Value', ascending=False)\n",
    "    \n",
    "    return perm_df_, feature_importances_, boruta_df_, np.mean(cv_scores)\n",
    "\n",
    "if CFG.feature_sel:\n",
    "    perm_df_, feature_importances_, boruta_df_, cv_scores = lgbm_tuning(features, permut=False, boruta=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check features correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    col = 'BZ'\n",
    "    x = train_df[train_df[col] <= train_df[col].quantile(0.99)]\n",
    "    cm = x[[c for c in train_df.columns if c not in ['Id', 'Class']]].corr()\n",
    "    display(np.abs(cm[col]).sort_values(ascending=False)[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.619184Z",
     "iopub.status.busy": "2023-06-08T15:32:11.618864Z",
     "iopub.status.idle": "2023-06-08T15:32:11.652915Z",
     "shell.execute_reply": "2023-06-08T15:32:11.652069Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.619157Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    perm_df_.to_csv('perm_df.csv')\n",
    "    perm_df_\n",
    "    perm_cols = set(perm_df_.index[-35:])\n",
    "    display(perm_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze tree gain feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.654626Z",
     "iopub.status.busy": "2023-06-08T15:32:11.654102Z",
     "iopub.status.idle": "2023-06-08T15:32:11.669674Z",
     "shell.execute_reply": "2023-06-08T15:32:11.668840Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.654583Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    feature_importances_.to_csv('feature_importances.csv')\n",
    "    feature_importances_\n",
    "    fi_cols = set(feature_importances_['Feature'].values[-23:])\n",
    "    display(fi_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze BORUTA importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    boruta_df_.to_csv('boruta_df_.csv')\n",
    "    boruta_df_\n",
    "    boruta_cols = set(boruta_df_.index[-35:])\n",
    "    display(boruta_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:20:15,455] A new study created in memory with name: no-name-b4491000-b388-4f73-8d8a-7f27ff9f3a2a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:20:17,853] Trial 0 finished with value: 0.18892005719012475 and parameters: {'boosting_type': 'goss', 'learning_rate': 0.10697234520758851, 'lambda_l1': 0.000396964712338032, 'lambda_l2': 0.5452195131263328, 'max_depth': 10, 'num_leaves': 123, 'feature_fraction': 0.31233003634052664, 'min_data_in_leaf': 18, 'max_bin': 113, 'bagging_freq': 5}. Best is trial 0 with value: 0.18892005719012475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:20:59,925] Trial 1 finished with value: 0.32141918764421884 and parameters: {'boosting_type': 'dart', 'learning_rate': 0.01291886257117534, 'lambda_l1': 7.971757418525103e-07, 'lambda_l2': 0.033246695034243774, 'max_depth': 10, 'num_leaves': 26, 'feature_fraction': 0.5919810217300694, 'min_data_in_leaf': 23, 'max_bin': 171, 'bagging_freq': 4, 'bagging_fraction': 0.326440880874238}. Best is trial 0 with value: 0.18892005719012475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:21:09,727] Trial 2 finished with value: 0.6973915667428459 and parameters: {'boosting_type': 'dart', 'learning_rate': 0.0038497989967737267, 'lambda_l1': 1.4831537299578065e-08, 'lambda_l2': 0.00013517895378162203, 'max_depth': 6, 'num_leaves': 118, 'feature_fraction': 0.6999791503283905, 'min_data_in_leaf': 62, 'max_bin': 160, 'bagging_freq': 5, 'bagging_fraction': 0.3651051110204697}. Best is trial 0 with value: 0.18892005719012475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:21:10,358] Trial 3 finished with value: 0.6973915667428459 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0003423338408344596, 'lambda_l1': 2.6572133497111632e-05, 'lambda_l2': 0.00037613744626938263, 'max_depth': 8, 'num_leaves': 34, 'feature_fraction': 0.671469755767987, 'min_data_in_leaf': 98, 'max_bin': 135, 'bagging_freq': 5, 'bagging_fraction': 0.5710559192067766}. Best is trial 0 with value: 0.18892005719012475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:21:11,031] Trial 4 finished with value: 0.6860128459689832 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03170141758707658, 'lambda_l1': 0.81728906623537, 'lambda_l2': 8.493898941768053e-08, 'max_depth': 6, 'num_leaves': 75, 'feature_fraction': 0.6795553548506662, 'min_data_in_leaf': 67, 'max_bin': 153, 'bagging_freq': 4, 'bagging_fraction': 0.6828530143036393}. Best is trial 0 with value: 0.18892005719012475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#5\n",
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:21:11,709] Trial 5 finished with value: 0.6973915667428459 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.00673320783371971, 'lambda_l1': 1.1008453984575852, 'lambda_l2': 9.619429492818879e-05, 'max_depth': 5, 'num_leaves': 42, 'feature_fraction': 0.42632923566071784, 'min_data_in_leaf': 73, 'max_bin': 166, 'bagging_freq': 6, 'bagging_fraction': 0.4485009740200605}. Best is trial 0 with value: 0.18892005719012475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:21:12,321] Trial 6 finished with value: 0.6973915667428459 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0003150133813620926, 'lambda_l1': 1.3553280015177709, 'lambda_l2': 0.0001623003685249506, 'max_depth': 10, 'num_leaves': 66, 'feature_fraction': 0.49546877945332324, 'min_data_in_leaf': 67, 'max_bin': 111, 'bagging_freq': 6, 'bagging_fraction': 0.3737408995272305}. Best is trial 0 with value: 0.18892005719012475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#5\n",
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:21:12,888] Trial 7 finished with value: 0.6973915667428459 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06292288328578349, 'lambda_l1': 0.26821685232687464, 'lambda_l2': 9.730379881711538e-06, 'max_depth': 5, 'num_leaves': 112, 'feature_fraction': 0.5173379162150782, 'min_data_in_leaf': 78, 'max_bin': 123, 'bagging_freq': 6, 'bagging_fraction': 0.5824817764566992}. Best is trial 0 with value: 0.18892005719012475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-06-15 15:21:14,316] Trial 8 failed with parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0006303332783493984, 'lambda_l1': 2.6605054586252357, 'lambda_l2': 1.1945871999575372e-07, 'max_depth': 4, 'num_leaves': 48, 'feature_fraction': 0.32667953679014455, 'min_data_in_leaf': 18, 'max_bin': 238, 'bagging_freq': 6, 'bagging_fraction': 0.35721817408643103} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_5861/4055452463.py\", line 117, in objective\n",
      "    gbm = lgb.train(\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/lightgbm/engine.py\", line 292, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/lightgbm/basic.py\", line 3021, in update\n",
      "    _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2023-06-15 15:21:14,316] Trial 8 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5861/4055452463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;31m#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of finished trials: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \"\"\"\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5861/4055452463.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m#             pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'balanced_log_loss')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             gbm = lgb.train(\n\u001b[0m\u001b[1;32m    118\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# callbacks=[pruning_callback],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbll_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability  is replaced with max(min(,11015),1015)\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1 - y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2\n",
    "\n",
    "def bll_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def calc_log_loss_weight(y_true): \n",
    "    '''w0, w1 assign different weights to individual data points during training.'''\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    return w0, w1\n",
    "\n",
    "X, y = train_df[features], train_df.Class \n",
    "    \n",
    "def objective(trial):\n",
    "    param = {\n",
    "        # Main parameters\n",
    "#                     'device': 'gpu',\n",
    "#                     'gpu_platform_id': 0,\n",
    "#                     'gpu_device_id': 0,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'none',\n",
    "        'is_unbalance': True,\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['goss', 'gbdt', 'dart']),   \n",
    "        # Hyperparamters (in order of importance decreasing)\n",
    "        'n_estimators': 3000, # trial.suggest_int('n_estimators', 500, 1500),  # max number of trees in model\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 3e-1),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True), # L1,  alias: reg_alpha\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True), # L2, alias: reg_lambda\n",
    "         # decrease to deal with overfit\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),   # tree max depth \n",
    "         # decrease to deal with overfit\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 128),  # Max number of leaves in one tree\n",
    "                                                               # should be ~ 2**(max_depth-1)\n",
    "        'bagging_fraction': None, # Randomly select part of data without \n",
    "                                  # resampling if bagging_fraction < 1.0\n",
    "                                  # alias: subsample\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.3, 0.7), # Randomly select a subset of features \n",
    "                                                                   # if feature_fraction < 1.0\n",
    "                                                                   # alias: colsample_bytree\n",
    "        # decrease to deal with overfit\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                           # aliases: min_child_samples, \n",
    "#             # decrease to deat with overfit\n",
    "#             'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-4, 1e-1), # Stop trying to split \n",
    "#                                                                                                    # leave if sum of it's\n",
    "#                                                                                                    # hessian less than k\n",
    "#                                                                                                    # alias: min_child_weight\n",
    "\n",
    "        # increase for accuracy, decrease to deal with overfit\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255), # Max number of bins that feature values will be bucketed in\n",
    "        # increase to deal with overfit\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7), # Perform bagging at every k iteration\n",
    "        'early_stopping_round': 100, \n",
    "\n",
    "#           'subsample_for_bin': 200000, # Number of data that sampled to construct feature discrete bins; setting this \n",
    "                                     # to larger value will give better training result but may increase train time \n",
    "#           'cat_smooth': trial.suggest_float('cat_smooth', 10.0, 100.0),  # this can reduce the effect of noises in \n",
    "                                                                       # categorical features, especially for \n",
    "                                                                       # categories with few data\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    if param['boosting_type'] != 'goss':\n",
    "        param['bagging_fraction'] = trial.suggest_float('bagging_fraction', 0.3, 0.7)\n",
    "\n",
    "    bll_list = list()\n",
    "    \n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under-sampling to balance classes\n",
    "        positive_count_train = train_df.Class.value_counts()[1]\n",
    "        sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                        1: positive_count_train}, \n",
    "                                     random_state=15062023+i, \n",
    "                                     replacement=True)\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "            dvalid = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "            # Add a callback for pruning\n",
    "#             pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'balanced_log_loss')\n",
    "\n",
    "            gbm = lgb.train(\n",
    "                param, dtrain, valid_sets=[dvalid], # callbacks=[pruning_callback], \n",
    "                feval=bll_metric, verbose_eval=0\n",
    "            )\n",
    "\n",
    "            val_preds = gbm.predict(X_val)\n",
    "            oof[val_idx] = val_preds\n",
    "        bll_list.append(balanced_log_loss(y_re, oof))\n",
    "\n",
    "    return np.mean(bll_list)\n",
    "            \n",
    "\n",
    "if CFG.lgbm_optimize:\n",
    "#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df.to_csv(f'optuna_lgbm_{boosting_type}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LGBM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "param_list = glob.glob(\"optuna_lgbm*.csv\")\n",
    "models = list()\n",
    "best_lgbm_params = list()\n",
    "\n",
    "lgbm_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    gb_type = [f.split('_')][0][2][:-4]\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    tmp['params_boosting_type'] = gb_type\n",
    "    if lgbm_params.shape[0] == 0:\n",
    "        lgbm_params = tmp\n",
    "    else:\n",
    "        lgbm_params = pd.concat([lgbm_params, tmp])\n",
    "        \n",
    "lgbm_params = lgbm_params.sort_values('value').head(20)\n",
    "param_cols = [c for c in lgbm_params.columns if c.startswith('params_')]\n",
    "lgbm_params = lgbm_params[param_cols]\n",
    "\n",
    "for idx, row in lgbm_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['objective'] = 'binary'\n",
    "    row_dict['metric'] = 'none'\n",
    "#     row_dict['subsample_for_bin'] = 300000\n",
    "    row_dict['force_col_wise'] = False\n",
    "    row_dict['early_stopping_rounds'] = 50\n",
    "    row_dict['verbose'] = -1\n",
    "    row_dict['max_bin'] = 255\n",
    "    row_dict['bagging_freq'] = int(row_dict['bagging_freq'])\n",
    "#     if row_dict['bagging_fraction'] != row_dict['bagging_fraction']:\n",
    "#         row_dict['bagging_fraction'] = None\n",
    "    row_dict['min_data_in_leaf'] = int(row_dict['min_data_in_leaf'])\n",
    "    row_dict['n_estimators'] = 3000 # int(row_dict['n_estimators'])\n",
    "    \n",
    "    row_dict['learning_rate'] = 0.06433232950390658 # float(row_dict['learning_rate'])\n",
    "    row_dict['num_leaves'] = int(row_dict['num_leaves'])\n",
    "    row_dict['max_depth'] = int(row_dict['max_depth'])\n",
    "    row_dict['is_unbalance'] = True\n",
    "    row_dict['class_weight'] = 'balanced'\n",
    "    row_dict['verbose'] = -1\n",
    "    \n",
    "    best_lgbm_params.append(row_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.672883Z",
     "iopub.status.busy": "2023-06-08T15:32:11.672350Z",
     "iopub.status.idle": "2023-06-08T15:32:38.349383Z",
     "shell.execute_reply": "2023-06-08T15:32:38.347823Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.672854Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with \u001b[1m\u001b[34m39\u001b[0m features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785d7bc8bd084c468cedbcfdc8c59b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "488\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.01764\u001b[0m | Best iteration: \u001b[1m\u001b[34m 488\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "609\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.01908\u001b[0m | Best iteration: \u001b[1m\u001b[34m 609\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "327\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.04364\u001b[0m | Best iteration: \u001b[1m\u001b[34m 327\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "457\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.03293\u001b[0m | Best iteration: \u001b[1m\u001b[34m 457\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "652\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.01907\u001b[0m | Best iteration: \u001b[1m\u001b[34m 652\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "814\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.02054\u001b[0m | Best iteration: \u001b[1m\u001b[34m 814\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "664\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.01805\u001b[0m | Best iteration: \u001b[1m\u001b[34m 664\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "322\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.03712\u001b[0m | Best iteration: \u001b[1m\u001b[34m 322\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "360\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.04023\u001b[0m | Best iteration: \u001b[1m\u001b[34m 360\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "449\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.02506\u001b[0m | Best iteration: \u001b[1m\u001b[34m 449\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.01536\u001b[0m | Best iteration: \u001b[1m\u001b[34m 599\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "600\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.01629\u001b[0m | Best iteration: \u001b[1m\u001b[34m 600\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "285\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.04023\u001b[0m | Best iteration: \u001b[1m\u001b[34m 285\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "496\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.02648\u001b[0m | Best iteration: \u001b[1m\u001b[34m 496\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "525\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.02836\u001b[0m | Best iteration: \u001b[1m\u001b[34m 525\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "430\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.02872\u001b[0m | Best iteration: \u001b[1m\u001b[34m 430\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "501\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.03545\u001b[0m | Best iteration: \u001b[1m\u001b[34m 501\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "551\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.02040\u001b[0m | Best iteration: \u001b[1m\u001b[34m 551\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "566\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.02146\u001b[0m | Best iteration: \u001b[1m\u001b[34m 566\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "527\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.01772\u001b[0m | Best iteration: \u001b[1m\u001b[34m 527\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12295\u001b[0m | Best iteration: \u001b[1m\u001b[34m 392\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "219\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12824\u001b[0m | Best iteration: \u001b[1m\u001b[34m 219\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "313\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15311\u001b[0m | Best iteration: \u001b[1m\u001b[34m 313\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "222\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15214\u001b[0m | Best iteration: \u001b[1m\u001b[34m 222\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "281\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11623\u001b[0m | Best iteration: \u001b[1m\u001b[34m 281\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "297\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14079\u001b[0m | Best iteration: \u001b[1m\u001b[34m 297\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "357\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13217\u001b[0m | Best iteration: \u001b[1m\u001b[34m 357\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "242\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13266\u001b[0m | Best iteration: \u001b[1m\u001b[34m 242\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "258\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14634\u001b[0m | Best iteration: \u001b[1m\u001b[34m 258\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "280\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15303\u001b[0m | Best iteration: \u001b[1m\u001b[34m 280\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13858\u001b[0m | Best iteration: \u001b[1m\u001b[34m 298\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "295\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13821\u001b[0m | Best iteration: \u001b[1m\u001b[34m 295\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "348\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13657\u001b[0m | Best iteration: \u001b[1m\u001b[34m 348\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "344\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10914\u001b[0m | Best iteration: \u001b[1m\u001b[34m 344\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "550\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15125\u001b[0m | Best iteration: \u001b[1m\u001b[34m 550\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "266\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14536\u001b[0m | Best iteration: \u001b[1m\u001b[34m 266\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "310\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12580\u001b[0m | Best iteration: \u001b[1m\u001b[34m 310\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "342\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13585\u001b[0m | Best iteration: \u001b[1m\u001b[34m 342\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "235\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15159\u001b[0m | Best iteration: \u001b[1m\u001b[34m 235\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "258\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11874\u001b[0m | Best iteration: \u001b[1m\u001b[34m 258\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "194\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17200\u001b[0m | Best iteration: \u001b[1m\u001b[34m 194\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18118\u001b[0m | Best iteration: \u001b[1m\u001b[34m 149\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "94\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20593\u001b[0m | Best iteration: \u001b[1m\u001b[34m  94\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "109\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24782\u001b[0m | Best iteration: \u001b[1m\u001b[34m 109\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "78\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25317\u001b[0m | Best iteration: \u001b[1m\u001b[34m  78\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "128\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17053\u001b[0m | Best iteration: \u001b[1m\u001b[34m 128\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "149\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25523\u001b[0m | Best iteration: \u001b[1m\u001b[34m 149\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "126\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18260\u001b[0m | Best iteration: \u001b[1m\u001b[34m 126\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "150\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19808\u001b[0m | Best iteration: \u001b[1m\u001b[34m 150\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "131\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18611\u001b[0m | Best iteration: \u001b[1m\u001b[34m 131\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "139\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21219\u001b[0m | Best iteration: \u001b[1m\u001b[34m 139\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "143\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25591\u001b[0m | Best iteration: \u001b[1m\u001b[34m 143\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "166\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17540\u001b[0m | Best iteration: \u001b[1m\u001b[34m 166\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22907\u001b[0m | Best iteration: \u001b[1m\u001b[34m 164\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "134\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20971\u001b[0m | Best iteration: \u001b[1m\u001b[34m 134\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "130\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22986\u001b[0m | Best iteration: \u001b[1m\u001b[34m 130\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "97\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25375\u001b[0m | Best iteration: \u001b[1m\u001b[34m  97\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "138\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22087\u001b[0m | Best iteration: \u001b[1m\u001b[34m 138\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "141\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22055\u001b[0m | Best iteration: \u001b[1m\u001b[34m 141\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "167\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17915\u001b[0m | Best iteration: \u001b[1m\u001b[34m 167\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "81\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19398\u001b[0m | Best iteration: \u001b[1m\u001b[34m  81\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "90\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17947\u001b[0m | Best iteration: \u001b[1m\u001b[34m  90\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "78\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21063\u001b[0m | Best iteration: \u001b[1m\u001b[34m  78\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "103\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20973\u001b[0m | Best iteration: \u001b[1m\u001b[34m 103\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "104\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15990\u001b[0m | Best iteration: \u001b[1m\u001b[34m 104\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21770\u001b[0m | Best iteration: \u001b[1m\u001b[34m  70\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "92\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16921\u001b[0m | Best iteration: \u001b[1m\u001b[34m  92\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "92\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19149\u001b[0m | Best iteration: \u001b[1m\u001b[34m  92\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "85\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20883\u001b[0m | Best iteration: \u001b[1m\u001b[34m  85\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "69\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22951\u001b[0m | Best iteration: \u001b[1m\u001b[34m  69\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "92\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19189\u001b[0m | Best iteration: \u001b[1m\u001b[34m  92\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "94\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17683\u001b[0m | Best iteration: \u001b[1m\u001b[34m  94\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "92\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23209\u001b[0m | Best iteration: \u001b[1m\u001b[34m  92\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "83\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21783\u001b[0m | Best iteration: \u001b[1m\u001b[34m  83\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "83\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18783\u001b[0m | Best iteration: \u001b[1m\u001b[34m  83\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "92\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18789\u001b[0m | Best iteration: \u001b[1m\u001b[34m  92\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20224\u001b[0m | Best iteration: \u001b[1m\u001b[34m  86\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "77\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21231\u001b[0m | Best iteration: \u001b[1m\u001b[34m  77\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "107\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17723\u001b[0m | Best iteration: \u001b[1m\u001b[34m 107\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "88\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18344\u001b[0m | Best iteration: \u001b[1m\u001b[34m  88\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "145\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13738\u001b[0m | Best iteration: \u001b[1m\u001b[34m 145\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "141\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15327\u001b[0m | Best iteration: \u001b[1m\u001b[34m 141\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "271\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11889\u001b[0m | Best iteration: \u001b[1m\u001b[34m 271\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "274\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09733\u001b[0m | Best iteration: \u001b[1m\u001b[34m 274\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "326\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08525\u001b[0m | Best iteration: \u001b[1m\u001b[34m 326\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "277\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09809\u001b[0m | Best iteration: \u001b[1m\u001b[34m 277\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "231\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09261\u001b[0m | Best iteration: \u001b[1m\u001b[34m 231\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12210\u001b[0m | Best iteration: \u001b[1m\u001b[34m 208\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "262\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10688\u001b[0m | Best iteration: \u001b[1m\u001b[34m 262\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "124\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14146\u001b[0m | Best iteration: \u001b[1m\u001b[34m 124\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "245\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09537\u001b[0m | Best iteration: \u001b[1m\u001b[34m 245\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "220\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11131\u001b[0m | Best iteration: \u001b[1m\u001b[34m 220\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "145\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13350\u001b[0m | Best iteration: \u001b[1m\u001b[34m 145\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "291\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09642\u001b[0m | Best iteration: \u001b[1m\u001b[34m 291\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "220\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11984\u001b[0m | Best iteration: \u001b[1m\u001b[34m 220\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "194\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14164\u001b[0m | Best iteration: \u001b[1m\u001b[34m 194\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "142\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12001\u001b[0m | Best iteration: \u001b[1m\u001b[34m 142\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "273\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14498\u001b[0m | Best iteration: \u001b[1m\u001b[34m 273\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15547\u001b[0m | Best iteration: \u001b[1m\u001b[34m 170\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "167\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19790\u001b[0m | Best iteration: \u001b[1m\u001b[34m 167\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "127\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12618\u001b[0m | Best iteration: \u001b[1m\u001b[34m 127\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "102\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14161\u001b[0m | Best iteration: \u001b[1m\u001b[34m 102\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "109\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13945\u001b[0m | Best iteration: \u001b[1m\u001b[34m 109\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "151\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14656\u001b[0m | Best iteration: \u001b[1m\u001b[34m 151\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "134\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13093\u001b[0m | Best iteration: \u001b[1m\u001b[34m 134\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "108\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13862\u001b[0m | Best iteration: \u001b[1m\u001b[34m 108\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "152\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13709\u001b[0m | Best iteration: \u001b[1m\u001b[34m 152\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "124\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12736\u001b[0m | Best iteration: \u001b[1m\u001b[34m 124\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "182\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12056\u001b[0m | Best iteration: \u001b[1m\u001b[34m 182\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16797\u001b[0m | Best iteration: \u001b[1m\u001b[34m 108\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "121\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13312\u001b[0m | Best iteration: \u001b[1m\u001b[34m 121\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "119\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14253\u001b[0m | Best iteration: \u001b[1m\u001b[34m 119\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "137\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15117\u001b[0m | Best iteration: \u001b[1m\u001b[34m 137\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "126\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15289\u001b[0m | Best iteration: \u001b[1m\u001b[34m 126\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "132\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12517\u001b[0m | Best iteration: \u001b[1m\u001b[34m 132\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "139\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11909\u001b[0m | Best iteration: \u001b[1m\u001b[34m 139\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "111\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15431\u001b[0m | Best iteration: \u001b[1m\u001b[34m 111\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "130\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13887\u001b[0m | Best iteration: \u001b[1m\u001b[34m 130\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "124\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12514\u001b[0m | Best iteration: \u001b[1m\u001b[34m 124\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12617\u001b[0m | Best iteration: \u001b[1m\u001b[34m 141\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "37\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.46087\u001b[0m | Best iteration: \u001b[1m\u001b[34m  37\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "181\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28692\u001b[0m | Best iteration: \u001b[1m\u001b[34m 181\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "144\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.35949\u001b[0m | Best iteration: \u001b[1m\u001b[34m 144\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "158\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34454\u001b[0m | Best iteration: \u001b[1m\u001b[34m 158\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "116\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.36877\u001b[0m | Best iteration: \u001b[1m\u001b[34m 116\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "176\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34144\u001b[0m | Best iteration: \u001b[1m\u001b[34m 176\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "216\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.31105\u001b[0m | Best iteration: \u001b[1m\u001b[34m 216\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "200\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29670\u001b[0m | Best iteration: \u001b[1m\u001b[34m 200\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "160\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33171\u001b[0m | Best iteration: \u001b[1m\u001b[34m 160\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33988\u001b[0m | Best iteration: \u001b[1m\u001b[34m 161\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "168\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.32436\u001b[0m | Best iteration: \u001b[1m\u001b[34m 168\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "160\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.31898\u001b[0m | Best iteration: \u001b[1m\u001b[34m 160\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "154\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33223\u001b[0m | Best iteration: \u001b[1m\u001b[34m 154\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "197\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29595\u001b[0m | Best iteration: \u001b[1m\u001b[34m 197\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "264\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34188\u001b[0m | Best iteration: \u001b[1m\u001b[34m 264\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "162\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.35123\u001b[0m | Best iteration: \u001b[1m\u001b[34m 162\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "127\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33423\u001b[0m | Best iteration: \u001b[1m\u001b[34m 127\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "163\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.36987\u001b[0m | Best iteration: \u001b[1m\u001b[34m 163\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "173\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34625\u001b[0m | Best iteration: \u001b[1m\u001b[34m 173\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.41473\u001b[0m | Best iteration: \u001b[1m\u001b[34m 144\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "529\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.03332\u001b[0m | Best iteration: \u001b[1m\u001b[34m 529\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "631\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.03165\u001b[0m | Best iteration: \u001b[1m\u001b[34m 631\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "564\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.04658\u001b[0m | Best iteration: \u001b[1m\u001b[34m 564\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "737\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.03772\u001b[0m | Best iteration: \u001b[1m\u001b[34m 737\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "458\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.04548\u001b[0m | Best iteration: \u001b[1m\u001b[34m 458\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "588\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.03021\u001b[0m | Best iteration: \u001b[1m\u001b[34m 588\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "595\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.02716\u001b[0m | Best iteration: \u001b[1m\u001b[34m 595\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "355\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07898\u001b[0m | Best iteration: \u001b[1m\u001b[34m 355\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "531\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.04010\u001b[0m | Best iteration: \u001b[1m\u001b[34m 531\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "531\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.03749\u001b[0m | Best iteration: \u001b[1m\u001b[34m 531\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.04460\u001b[0m | Best iteration: \u001b[1m\u001b[34m 379\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "733\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.01666\u001b[0m | Best iteration: \u001b[1m\u001b[34m 733\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "409\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.05763\u001b[0m | Best iteration: \u001b[1m\u001b[34m 409\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "758\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.01702\u001b[0m | Best iteration: \u001b[1m\u001b[34m 758\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "494\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.05638\u001b[0m | Best iteration: \u001b[1m\u001b[34m 494\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "691\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.01703\u001b[0m | Best iteration: \u001b[1m\u001b[34m 691\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "383\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.05774\u001b[0m | Best iteration: \u001b[1m\u001b[34m 383\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "755\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.02361\u001b[0m | Best iteration: \u001b[1m\u001b[34m 755\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "457\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.03850\u001b[0m | Best iteration: \u001b[1m\u001b[34m 457\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "436\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06514\u001b[0m | Best iteration: \u001b[1m\u001b[34m 436\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "223\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09242\u001b[0m | Best iteration: \u001b[1m\u001b[34m 223\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13942\u001b[0m | Best iteration: \u001b[1m\u001b[34m 186\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "187\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07333\u001b[0m | Best iteration: \u001b[1m\u001b[34m 187\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "203\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13494\u001b[0m | Best iteration: \u001b[1m\u001b[34m 203\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "223\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14812\u001b[0m | Best iteration: \u001b[1m\u001b[34m 223\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "146\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15503\u001b[0m | Best iteration: \u001b[1m\u001b[34m 146\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "125\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16248\u001b[0m | Best iteration: \u001b[1m\u001b[34m 125\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "209\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14215\u001b[0m | Best iteration: \u001b[1m\u001b[34m 209\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "153\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12045\u001b[0m | Best iteration: \u001b[1m\u001b[34m 153\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "129\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12823\u001b[0m | Best iteration: \u001b[1m\u001b[34m 129\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "164\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11593\u001b[0m | Best iteration: \u001b[1m\u001b[34m 164\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15718\u001b[0m | Best iteration: \u001b[1m\u001b[34m 208\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "145\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16605\u001b[0m | Best iteration: \u001b[1m\u001b[34m 145\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "180\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14485\u001b[0m | Best iteration: \u001b[1m\u001b[34m 180\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "199\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10702\u001b[0m | Best iteration: \u001b[1m\u001b[34m 199\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "194\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11683\u001b[0m | Best iteration: \u001b[1m\u001b[34m 194\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "166\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14777\u001b[0m | Best iteration: \u001b[1m\u001b[34m 166\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "187\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11566\u001b[0m | Best iteration: \u001b[1m\u001b[34m 187\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "170\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12231\u001b[0m | Best iteration: \u001b[1m\u001b[34m 170\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "182\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11744\u001b[0m | Best iteration: \u001b[1m\u001b[34m 182\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "101\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42460\u001b[0m | Best iteration: \u001b[1m\u001b[34m 101\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "70\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39781\u001b[0m | Best iteration: \u001b[1m\u001b[34m  70\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "34\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.49411\u001b[0m | Best iteration: \u001b[1m\u001b[34m  34\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "78\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39497\u001b[0m | Best iteration: \u001b[1m\u001b[34m  78\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "41\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38199\u001b[0m | Best iteration: \u001b[1m\u001b[34m  41\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38013\u001b[0m | Best iteration: \u001b[1m\u001b[34m 115\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "105\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.36513\u001b[0m | Best iteration: \u001b[1m\u001b[34m 105\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "47\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42220\u001b[0m | Best iteration: \u001b[1m\u001b[34m  47\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "69\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.37949\u001b[0m | Best iteration: \u001b[1m\u001b[34m  69\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "93\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39910\u001b[0m | Best iteration: \u001b[1m\u001b[34m  93\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "63\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34726\u001b[0m | Best iteration: \u001b[1m\u001b[34m  63\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "52\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.36401\u001b[0m | Best iteration: \u001b[1m\u001b[34m  52\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "47\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42219\u001b[0m | Best iteration: \u001b[1m\u001b[34m  47\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "47\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42866\u001b[0m | Best iteration: \u001b[1m\u001b[34m  47\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "35\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39690\u001b[0m | Best iteration: \u001b[1m\u001b[34m  35\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39734\u001b[0m | Best iteration: \u001b[1m\u001b[34m  95\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "53\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.37825\u001b[0m | Best iteration: \u001b[1m\u001b[34m  53\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "53\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.44600\u001b[0m | Best iteration: \u001b[1m\u001b[34m  53\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "95\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39733\u001b[0m | Best iteration: \u001b[1m\u001b[34m  95\u001b[0m\n",
      "[LightGBM] [Warning] early_stopping_round is set=50, early_stopping_rounds=50 will be ignored. Current value: early_stopping_round=50\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "46\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.41446\u001b[0m | Best iteration: \u001b[1m\u001b[34m  46\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def lgbm_training():\n",
    "    models_ = list()\n",
    "    bll_list = list()\n",
    "    weights_ = list()\n",
    "    \n",
    "    X, y = train_df[features], train_df.Class\n",
    "#     X, y = generated_features_train, train_df.Class\n",
    "     \n",
    "    kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=8062023+20)\n",
    "    metric = balanced_log_loss\n",
    "    eval_results_ = {}     # used to store evaluation results for each fold\n",
    "\n",
    "    oof_level2 = np.zeros([y.shape[0], len(best_lgbm_params) + 1])\n",
    "    oof_level2[:, len(best_lgbm_params)] = y\n",
    "\n",
    "    print(f\"Training with {blu}{X.shape[1]}{res} features\")\n",
    "\n",
    "    for fold, (fit_idx, val_idx) in tqdm(enumerate(kf.split(X=train_df, y=greeks.iloc[:,1:3]), start = 1),\n",
    "                                         total=CFG.n_stacking_folds):\n",
    "        \n",
    "        # Split the dataset according to the fold indexes.\n",
    "        X_train = X.iloc[fit_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_train = y.iloc[fit_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        for i, params in enumerate(best_lgbm_params):\n",
    "            \n",
    "            clf = lgb.LGBMClassifier(**params)\n",
    "            clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                    eval_metric=bll_metric, verbose=-1)\n",
    "            models_.append(clf)\n",
    "\n",
    "            val_preds = clf.predict_proba(X_val)[:,1]\n",
    "            oof_level2[val_idx, i] = val_preds\n",
    "\n",
    "            val_score = balanced_log_loss(y_val, val_preds)\n",
    "            best_iter = clf.best_iteration_\n",
    "\n",
    "            print(clf.best_iteration_)\n",
    "            \n",
    "            print(f'Fold: {blu}{fold:>3}{res}| bll_metric: {blu}{val_score:.5f}{res}'\n",
    "                  f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "        \n",
    "    return oof_level2, models_\n",
    "\n",
    "if CFG.stacking:\n",
    "    oof_level2_lgbm, models_lgbm = lgbm_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:27:44,387] A new study created in memory with name: no-name-5b706e8c-7411-4867-babf-b8c6cb53825e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.68057\n",
      "[409]\tvalidation_0-logloss:0.28587\n",
      "[0]\tvalidation_0-logloss:0.68524\n",
      "[335]\tvalidation_0-logloss:0.22760\n",
      "[0]\tvalidation_0-logloss:0.66400\n",
      "[548]\tvalidation_0-logloss:0.40614\n",
      "[0]\tvalidation_0-logloss:0.66888\n",
      "[232]\tvalidation_0-logloss:0.43345\n",
      "[0]\tvalidation_0-logloss:0.68240\n",
      "[230]\tvalidation_0-logloss:0.42186\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.64133\n",
      "[434]\tvalidation_0-logloss:0.10903\n",
      "[0]\tvalidation_0-logloss:0.65529\n",
      "[231]\tvalidation_0-logloss:0.30404\n",
      "[0]\tvalidation_0-logloss:0.65559\n",
      "[639]\tvalidation_0-logloss:0.27892\n",
      "[0]\tvalidation_0-logloss:0.65559\n",
      "[128]\tvalidation_0-logloss:0.43786\n",
      "[0]\tvalidation_0-logloss:0.65433\n",
      "[562]\tvalidation_0-logloss:0.24229\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.67084\n",
      "[311]\tvalidation_0-logloss:0.29251\n",
      "[0]\tvalidation_0-logloss:0.68051\n",
      "[374]\tvalidation_0-logloss:0.24343\n",
      "[0]\tvalidation_0-logloss:0.66691\n",
      "[539]\tvalidation_0-logloss:0.14530\n",
      "[0]\tvalidation_0-logloss:0.68407\n",
      "[704]\tvalidation_0-logloss:0.29233\n",
      "[0]\tvalidation_0-logloss:0.67885\n",
      "[399]\tvalidation_0-logloss:0.22683\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.67988\n",
      "[562]\tvalidation_0-logloss:0.15134\n",
      "[0]\tvalidation_0-logloss:0.67529\n",
      "[231]\tvalidation_0-logloss:0.49418\n",
      "[0]\tvalidation_0-logloss:0.65760\n",
      "[336]\tvalidation_0-logloss:0.33135\n",
      "[0]\tvalidation_0-logloss:0.66107\n",
      "[579]\tvalidation_0-logloss:0.40059\n",
      "[0]\tvalidation_0-logloss:0.67240\n",
      "[287]\tvalidation_0-logloss:0.21583\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.65935\n",
      "[454]\tvalidation_0-logloss:0.32103\n",
      "[0]\tvalidation_0-logloss:0.64533\n",
      "[384]\tvalidation_0-logloss:0.21478\n",
      "[0]\tvalidation_0-logloss:0.65239\n",
      "[536]\tvalidation_0-logloss:0.14667\n",
      "[0]\tvalidation_0-logloss:0.68135\n",
      "[234]\tvalidation_0-logloss:0.35098\n",
      "[0]\tvalidation_0-logloss:0.65588\n",
      "[207]\tvalidation_0-logloss:0.34842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:27:49,624] Trial 0 finished with value: 0.286093718239291 and parameters: {'booster': 'gbtree', 'alpha': 0.25623728735464407, 'lambda': 0.00019336903261921336, 'subsample': 0.7112340405466451, 'colsample_bytree': 0.6375939340861976, 'learning_rate': 0.0807215616583345, 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.204081655787243, 'grow_policy': 'depthwise'}. Best is trial 0 with value: 0.286093718239291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.74057\n",
      "[107]\tvalidation_0-logloss:0.69313\n",
      "[0]\tvalidation_0-logloss:0.72642\n",
      "[112]\tvalidation_0-logloss:0.42529\n",
      "[0]\tvalidation_0-logloss:1.31727\n",
      "[100]\tvalidation_0-logloss:0.84068\n",
      "[0]\tvalidation_0-logloss:0.74713\n",
      "[114]\tvalidation_0-logloss:0.54952\n",
      "[0]\tvalidation_0-logloss:0.78410\n",
      "[1000]\tvalidation_0-logloss:0.46838\n",
      "[1068]\tvalidation_0-logloss:0.46838\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.74303\n",
      "[1000]\tvalidation_0-logloss:0.26996\n",
      "[2000]\tvalidation_0-logloss:0.26966\n",
      "[2999]\tvalidation_0-logloss:0.26965\n",
      "[0]\tvalidation_0-logloss:2.21567\n",
      "[100]\tvalidation_0-logloss:15.42197\n",
      "[0]\tvalidation_0-logloss:1.13108\n",
      "[111]\tvalidation_0-logloss:0.61508\n",
      "[0]\tvalidation_0-logloss:0.79442\n",
      "[103]\tvalidation_0-logloss:1.66532\n",
      "[0]\tvalidation_0-logloss:0.73432\n",
      "[199]\tvalidation_0-logloss:0.37096\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.70926\n",
      "[111]\tvalidation_0-logloss:0.75246\n",
      "[0]\tvalidation_0-logloss:1.99752\n",
      "[100]\tvalidation_0-logloss:20.56262\n",
      "[0]\tvalidation_0-logloss:0.61913\n",
      "[182]\tvalidation_0-logloss:0.30494\n",
      "[0]\tvalidation_0-logloss:0.96749\n",
      "[141]\tvalidation_0-logloss:0.46504\n",
      "[0]\tvalidation_0-logloss:1.27674\n",
      "[103]\tvalidation_0-logloss:20.09529\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.91388\n",
      "[186]\tvalidation_0-logloss:0.40257\n",
      "[0]\tvalidation_0-logloss:1.23382\n",
      "[107]\tvalidation_0-logloss:0.69073\n",
      "[0]\tvalidation_0-logloss:1.39692\n",
      "[1000]\tvalidation_0-logloss:0.26122\n",
      "[2000]\tvalidation_0-logloss:0.25873\n",
      "[2999]\tvalidation_0-logloss:0.25862\n",
      "[0]\tvalidation_0-logloss:1.21664\n",
      "[320]\tvalidation_0-logloss:0.41404\n",
      "[0]\tvalidation_0-logloss:0.61326\n",
      "[104]\tvalidation_0-logloss:0.48943\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:1.63251\n",
      "[101]\tvalidation_0-logloss:18.84907\n",
      "[0]\tvalidation_0-logloss:1.21664\n",
      "[103]\tvalidation_0-logloss:18.84907\n",
      "[0]\tvalidation_0-logloss:1.31855\n",
      "[101]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:0.80701\n",
      "[106]\tvalidation_0-logloss:1.27384\n",
      "[0]\tvalidation_0-logloss:0.71484\n",
      "[103]\tvalidation_0-logloss:0.45332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:27:53,088] Trial 1 finished with value: 4.608972343530562 and parameters: {'booster': 'gblinear', 'alpha': 0.047803898808096594, 'lambda': 0.000669631281406815, 'subsample': 0.6855484871090611, 'colsample_bytree': 0.490262726529753}. Best is trial 0 with value: 0.286093718239291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.69230\n",
      "[1000]\tvalidation_0-logloss:0.35016\n",
      "[2000]\tvalidation_0-logloss:0.29255\n",
      "[2577]\tvalidation_0-logloss:0.28466\n",
      "[0]\tvalidation_0-logloss:0.69216\n",
      "[1000]\tvalidation_0-logloss:0.26329\n",
      "[2000]\tvalidation_0-logloss:0.22335\n",
      "[2999]\tvalidation_0-logloss:0.20838\n",
      "[0]\tvalidation_0-logloss:0.69027\n",
      "[480]\tvalidation_0-logloss:0.49304\n",
      "[0]\tvalidation_0-logloss:0.69102\n",
      "[1000]\tvalidation_0-logloss:0.38234\n",
      "[1027]\tvalidation_0-logloss:0.38142\n",
      "[0]\tvalidation_0-logloss:0.69060\n",
      "[715]\tvalidation_0-logloss:0.43608\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.68850\n",
      "[1000]\tvalidation_0-logloss:0.14692\n",
      "[2000]\tvalidation_0-logloss:0.11828\n",
      "[2801]\tvalidation_0-logloss:0.11251\n",
      "[0]\tvalidation_0-logloss:0.69055\n",
      "[1000]\tvalidation_0-logloss:0.26884\n",
      "[1410]\tvalidation_0-logloss:0.26425\n",
      "[0]\tvalidation_0-logloss:0.68947\n",
      "[1000]\tvalidation_0-logloss:0.29634\n",
      "[1942]\tvalidation_0-logloss:0.27116\n",
      "[0]\tvalidation_0-logloss:0.68962\n",
      "[543]\tvalidation_0-logloss:0.43305\n",
      "[0]\tvalidation_0-logloss:0.68948\n",
      "[1000]\tvalidation_0-logloss:0.26319\n",
      "[2000]\tvalidation_0-logloss:0.23127\n",
      "[2652]\tvalidation_0-logloss:0.22486\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.69096\n",
      "[1000]\tvalidation_0-logloss:0.32829\n",
      "[2000]\tvalidation_0-logloss:0.30947\n",
      "[2623]\tvalidation_0-logloss:0.30655\n",
      "[0]\tvalidation_0-logloss:0.69199\n",
      "[1000]\tvalidation_0-logloss:0.32562\n",
      "[2000]\tvalidation_0-logloss:0.24638\n",
      "[2999]\tvalidation_0-logloss:0.23353\n",
      "[0]\tvalidation_0-logloss:0.69085\n",
      "[1000]\tvalidation_0-logloss:0.21008\n",
      "[2000]\tvalidation_0-logloss:0.16335\n",
      "[2999]\tvalidation_0-logloss:0.15440\n",
      "[0]\tvalidation_0-logloss:0.69075\n",
      "[1000]\tvalidation_0-logloss:0.32619\n",
      "[2000]\tvalidation_0-logloss:0.27518\n",
      "[2501]\tvalidation_0-logloss:0.27018\n",
      "[0]\tvalidation_0-logloss:0.69211\n",
      "[1000]\tvalidation_0-logloss:0.30658\n",
      "[2000]\tvalidation_0-logloss:0.24394\n",
      "[2999]\tvalidation_0-logloss:0.23545\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.69010\n",
      "[1000]\tvalidation_0-logloss:0.18071\n",
      "[2000]\tvalidation_0-logloss:0.14318\n",
      "[2538]\tvalidation_0-logloss:0.13673\n",
      "[0]\tvalidation_0-logloss:0.69216\n",
      "[1000]\tvalidation_0-logloss:0.43983\n",
      "[1051]\tvalidation_0-logloss:0.43920\n",
      "[0]\tvalidation_0-logloss:0.68973\n",
      "[1000]\tvalidation_0-logloss:0.36958\n",
      "[2000]\tvalidation_0-logloss:0.31864\n",
      "[2471]\tvalidation_0-logloss:0.31238\n",
      "[0]\tvalidation_0-logloss:0.69010\n",
      "[489]\tvalidation_0-logloss:0.47751\n",
      "[0]\tvalidation_0-logloss:0.69042\n",
      "[1000]\tvalidation_0-logloss:0.22652\n",
      "[2000]\tvalidation_0-logloss:0.19865\n",
      "[2999]\tvalidation_0-logloss:0.19086\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.69106\n",
      "[633]\tvalidation_0-logloss:0.35097\n",
      "[0]\tvalidation_0-logloss:0.68879\n",
      "[1000]\tvalidation_0-logloss:0.23724\n",
      "[1663]\tvalidation_0-logloss:0.22515\n",
      "[0]\tvalidation_0-logloss:0.68977\n",
      "[1000]\tvalidation_0-logloss:0.18338\n",
      "[2000]\tvalidation_0-logloss:0.14329\n",
      "[2676]\tvalidation_0-logloss:0.13585\n",
      "[0]\tvalidation_0-logloss:0.69041\n",
      "[773]\tvalidation_0-logloss:0.35943\n",
      "[0]\tvalidation_0-logloss:0.68963\n",
      "[943]\tvalidation_0-logloss:0.33145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:28:13,438] Trial 2 finished with value: 0.28995669627009757 and parameters: {'booster': 'gbtree', 'alpha': 0.00014317194084270988, 'lambda': 0.001337070033804407, 'subsample': 0.7870181850144897, 'colsample_bytree': 0.5275266305332861, 'learning_rate': 0.006894378212073432, 'max_depth': 9, 'min_child_weight': 9, 'gamma': 0.06282789438775545, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.286093718239291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.69139\n",
      "[1000]\tvalidation_0-logloss:0.27859\n",
      "[1521]\tvalidation_0-logloss:0.26315\n",
      "[0]\tvalidation_0-logloss:0.68960\n",
      "[1000]\tvalidation_0-logloss:0.21464\n",
      "[1573]\tvalidation_0-logloss:0.20546\n",
      "[0]\tvalidation_0-logloss:0.68764\n",
      "[1000]\tvalidation_0-logloss:0.40070\n",
      "[1176]\tvalidation_0-logloss:0.39484\n",
      "[0]\tvalidation_0-logloss:0.68815\n",
      "[804]\tvalidation_0-logloss:0.36956\n",
      "[0]\tvalidation_0-logloss:0.68926\n",
      "[496]\tvalidation_0-logloss:0.40708\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.68353\n",
      "[1000]\tvalidation_0-logloss:0.10973\n",
      "[2000]\tvalidation_0-logloss:0.09911\n",
      "[2016]\tvalidation_0-logloss:0.09920\n",
      "[0]\tvalidation_0-logloss:0.68644\n",
      "[642]\tvalidation_0-logloss:0.24882\n",
      "[0]\tvalidation_0-logloss:0.68548\n",
      "[836]\tvalidation_0-logloss:0.25632\n",
      "[0]\tvalidation_0-logloss:0.68666\n",
      "[317]\tvalidation_0-logloss:0.41780\n",
      "[0]\tvalidation_0-logloss:0.68657\n",
      "[1000]\tvalidation_0-logloss:0.23232\n",
      "[1653]\tvalidation_0-logloss:0.22193\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.68964\n",
      "[1000]\tvalidation_0-logloss:0.29756\n",
      "[1269]\tvalidation_0-logloss:0.29618\n",
      "[0]\tvalidation_0-logloss:0.69121\n",
      "[1000]\tvalidation_0-logloss:0.23176\n",
      "[1598]\tvalidation_0-logloss:0.21481\n",
      "[0]\tvalidation_0-logloss:0.68884\n",
      "[1000]\tvalidation_0-logloss:0.14659\n",
      "[2000]\tvalidation_0-logloss:0.13234\n",
      "[2484]\tvalidation_0-logloss:0.13053\n",
      "[0]\tvalidation_0-logloss:0.68983\n",
      "[1000]\tvalidation_0-logloss:0.26553\n",
      "[1651]\tvalidation_0-logloss:0.25495\n",
      "[0]\tvalidation_0-logloss:0.68973\n",
      "[1000]\tvalidation_0-logloss:0.21092\n",
      "[1279]\tvalidation_0-logloss:0.20635\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.69042\n",
      "[1000]\tvalidation_0-logloss:0.13181\n",
      "[1602]\tvalidation_0-logloss:0.12231\n",
      "[0]\tvalidation_0-logloss:0.68873\n",
      "[745]\tvalidation_0-logloss:0.40840\n",
      "[0]\tvalidation_0-logloss:0.68656\n",
      "[1000]\tvalidation_0-logloss:0.29622\n",
      "[1392]\tvalidation_0-logloss:0.28477\n",
      "[0]\tvalidation_0-logloss:0.68754\n",
      "[1000]\tvalidation_0-logloss:0.37276\n",
      "[1174]\tvalidation_0-logloss:0.36962\n",
      "[0]\tvalidation_0-logloss:0.68772\n",
      "[1000]\tvalidation_0-logloss:0.20193\n",
      "[1254]\tvalidation_0-logloss:0.19523\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.68707\n",
      "[468]\tvalidation_0-logloss:0.33442\n",
      "[0]\tvalidation_0-logloss:0.68497\n",
      "[912]\tvalidation_0-logloss:0.21599\n",
      "[0]\tvalidation_0-logloss:0.68679\n",
      "[1000]\tvalidation_0-logloss:0.12922\n",
      "[1883]\tvalidation_0-logloss:0.11552\n",
      "[0]\tvalidation_0-logloss:0.68934\n",
      "[506]\tvalidation_0-logloss:0.34233\n",
      "[0]\tvalidation_0-logloss:0.68615\n",
      "[600]\tvalidation_0-logloss:0.31213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:28:26,579] Trial 3 finished with value: 0.26574023507112743 and parameters: {'booster': 'gbtree', 'alpha': 1.673446089952982e-06, 'lambda': 5.701035590782378e-08, 'subsample': 0.6791338161995366, 'colsample_bytree': 0.5152795884113237, 'learning_rate': 0.013258564465428795, 'max_depth': 7, 'min_child_weight': 7, 'gamma': 0.1533721918116734, 'grow_policy': 'lossguide'}. Best is trial 3 with value: 0.26574023507112743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.79388\n",
      "[167]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:0.87575\n",
      "[101]\tvalidation_0-logloss:20.56262\n",
      "[0]\tvalidation_0-logloss:1.35010\n",
      "[105]\tvalidation_0-logloss:20.09529\n",
      "[0]\tvalidation_0-logloss:1.15553\n",
      "[122]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:1.36460\n",
      "[102]\tvalidation_0-logloss:17.13552\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:1.18007\n",
      "[111]\tvalidation_0-logloss:17.58338\n",
      "[0]\tvalidation_0-logloss:0.98454\n",
      "[139]\tvalidation_0-logloss:21.41940\n",
      "[0]\tvalidation_0-logloss:2.31550\n",
      "[101]\tvalidation_0-logloss:19.70584\n",
      "[0]\tvalidation_0-logloss:0.85237\n",
      "[101]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:1.73321\n",
      "[103]\tvalidation_0-logloss:16.27874\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:1.01825\n",
      "[100]\tvalidation_0-logloss:17.99229\n",
      "[0]\tvalidation_0-logloss:0.74956\n",
      "[100]\tvalidation_0-logloss:20.56262\n",
      "[0]\tvalidation_0-logloss:1.35989\n",
      "[101]\tvalidation_0-logloss:14.56519\n",
      "[0]\tvalidation_0-logloss:2.56655\n",
      "[99]\tvalidation_0-logloss:18.84907\n",
      "[0]\tvalidation_0-logloss:0.70928\n",
      "[152]\tvalidation_0-logloss:20.09529\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.92930\n",
      "[128]\tvalidation_0-logloss:19.70584\n",
      "[0]\tvalidation_0-logloss:1.02906\n",
      "[106]\tvalidation_0-logloss:24.84650\n",
      "[0]\tvalidation_0-logloss:2.64061\n",
      "[100]\tvalidation_0-logloss:16.27874\n",
      "[0]\tvalidation_0-logloss:1.49210\n",
      "[101]\tvalidation_0-logloss:19.25798\n",
      "[0]\tvalidation_0-logloss:1.13366\n",
      "[142]\tvalidation_0-logloss:12.85164\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:3.39616\n",
      "[100]\tvalidation_0-logloss:18.84907\n",
      "[0]\tvalidation_0-logloss:0.71334\n",
      "[138]\tvalidation_0-logloss:0.38580\n",
      "[0]\tvalidation_0-logloss:0.78055\n",
      "[116]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:2.02092\n",
      "[102]\tvalidation_0-logloss:19.70584\n",
      "[0]\tvalidation_0-logloss:2.24021\n",
      "[100]\tvalidation_0-logloss:18.42068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:28:27,923] Trial 4 finished with value: 16.709446123167126 and parameters: {'booster': 'gblinear', 'alpha': 1.1963094133785981e-06, 'lambda': 6.853392598216787e-08, 'subsample': 0.41754568076154747, 'colsample_bytree': 0.4168219763283739}. Best is trial 3 with value: 0.26574023507112743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:1.63890\n",
      "[100]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:1.39336\n",
      "[121]\tvalidation_0-logloss:20.56262\n",
      "[0]\tvalidation_0-logloss:1.14376\n",
      "[106]\tvalidation_0-logloss:20.09529\n",
      "[0]\tvalidation_0-logloss:1.16535\n",
      "[100]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:0.88401\n",
      "[106]\tvalidation_0-logloss:17.13552\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.73125\n",
      "[114]\tvalidation_0-logloss:17.58338\n",
      "[0]\tvalidation_0-logloss:1.15840\n",
      "[100]\tvalidation_0-logloss:15.42197\n",
      "[0]\tvalidation_0-logloss:2.24978\n",
      "[99]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:0.86189\n",
      "[103]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:1.11490\n",
      "[100]\tvalidation_0-logloss:16.27874\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:3.95136\n",
      "[100]\tvalidation_0-logloss:17.99229\n",
      "[0]\tvalidation_0-logloss:3.12749\n",
      "[100]\tvalidation_0-logloss:20.56262\n",
      "[0]\tvalidation_0-logloss:0.74316\n",
      "[101]\tvalidation_0-logloss:15.42197\n",
      "[0]\tvalidation_0-logloss:0.84191\n",
      "[104]\tvalidation_0-logloss:0.99517\n",
      "[0]\tvalidation_0-logloss:0.95515\n",
      "[108]\tvalidation_0-logloss:20.09529\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:1.33828\n",
      "[105]\tvalidation_0-logloss:19.70584\n",
      "[0]\tvalidation_0-logloss:2.90034\n",
      "[99]\tvalidation_0-logloss:24.84650\n",
      "[0]\tvalidation_0-logloss:0.70672\n",
      "[101]\tvalidation_0-logloss:16.27874\n",
      "[0]\tvalidation_0-logloss:3.49871\n",
      "[100]\tvalidation_0-logloss:18.42068\n",
      "[0]\tvalidation_0-logloss:0.79915\n",
      "[125]\tvalidation_0-logloss:0.32039\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.82044\n",
      "[100]\tvalidation_0-logloss:18.84907\n",
      "[0]\tvalidation_0-logloss:0.76273\n",
      "[129]\tvalidation_0-logloss:17.99229\n",
      "[0]\tvalidation_0-logloss:2.72311\n",
      "[100]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:0.89336\n",
      "[101]\tvalidation_0-logloss:19.70584\n",
      "[0]\tvalidation_0-logloss:3.59622\n",
      "[99]\tvalidation_0-logloss:18.42068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:28:29,239] Trial 5 finished with value: 16.16842183069694 and parameters: {'booster': 'gblinear', 'alpha': 6.693911815733384e-07, 'lambda': 4.104082288043595e-05, 'subsample': 0.842077620145698, 'colsample_bytree': 0.9323566099311857}. Best is trial 3 with value: 0.26574023507112743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:2.87299\n",
      "[99]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:1.27876\n",
      "[113]\tvalidation_0-logloss:16.27874\n",
      "[0]\tvalidation_0-logloss:0.77604\n",
      "[103]\tvalidation_0-logloss:20.09529\n",
      "[0]\tvalidation_0-logloss:1.07695\n",
      "[100]\tvalidation_0-logloss:16.27874\n",
      "[0]\tvalidation_0-logloss:1.69203\n",
      "[100]\tvalidation_0-logloss:17.13552\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.77464\n",
      "[102]\tvalidation_0-logloss:17.58338\n",
      "[0]\tvalidation_0-logloss:1.53980\n",
      "[103]\tvalidation_0-logloss:21.41940\n",
      "[0]\tvalidation_0-logloss:1.20451\n",
      "[101]\tvalidation_0-logloss:19.70584\n",
      "[0]\tvalidation_0-logloss:0.82821\n",
      "[102]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:0.73039\n",
      "[99]\tvalidation_0-logloss:16.27874\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.79529\n",
      "[101]\tvalidation_0-logloss:0.97604\n",
      "[0]\tvalidation_0-logloss:0.83819\n",
      "[102]\tvalidation_0-logloss:20.56262\n",
      "[0]\tvalidation_0-logloss:1.06618\n",
      "[102]\tvalidation_0-logloss:21.41940\n",
      "[0]\tvalidation_0-logloss:0.70904\n",
      "[122]\tvalidation_0-logloss:17.99229\n",
      "[0]\tvalidation_0-logloss:0.80173\n",
      "[127]\tvalidation_0-logloss:20.09529\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:2.58458\n",
      "[99]\tvalidation_0-logloss:19.70584\n",
      "[0]\tvalidation_0-logloss:1.06518\n",
      "[108]\tvalidation_0-logloss:0.56769\n",
      "[0]\tvalidation_0-logloss:0.70927\n",
      "[105]\tvalidation_0-logloss:16.27874\n",
      "[0]\tvalidation_0-logloss:2.04114\n",
      "[101]\tvalidation_0-logloss:18.42068\n",
      "[0]\tvalidation_0-logloss:2.79235\n",
      "[99]\tvalidation_0-logloss:12.85164\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:1.65983\n",
      "[101]\tvalidation_0-logloss:11.99486\n",
      "[0]\tvalidation_0-logloss:0.80953\n",
      "[131]\tvalidation_0-logloss:17.99229\n",
      "[0]\tvalidation_0-logloss:3.75343\n",
      "[100]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:1.32236\n",
      "[100]\tvalidation_0-logloss:19.70584\n",
      "[0]\tvalidation_0-logloss:2.31049\n",
      "[101]\tvalidation_0-logloss:18.42068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:28:30,515] Trial 6 finished with value: 15.578352514354089 and parameters: {'booster': 'gblinear', 'alpha': 7.518918729168488e-05, 'lambda': 5.071698666779992e-08, 'subsample': 0.9940302588186833, 'colsample_bytree': 0.6394134083573966}. Best is trial 3 with value: 0.26574023507112743.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.69166\n",
      "[1000]\tvalidation_0-logloss:0.24598\n",
      "[2000]\tvalidation_0-logloss:0.19846\n",
      "[2999]\tvalidation_0-logloss:0.18277\n",
      "[0]\tvalidation_0-logloss:0.69079\n",
      "[1000]\tvalidation_0-logloss:0.23935\n",
      "[2000]\tvalidation_0-logloss:0.20376\n",
      "[2999]\tvalidation_0-logloss:0.19170\n",
      "[0]\tvalidation_0-logloss:0.69166\n",
      "[1000]\tvalidation_0-logloss:0.35239\n",
      "[2000]\tvalidation_0-logloss:0.33291\n",
      "[2369]\tvalidation_0-logloss:0.33017\n",
      "[0]\tvalidation_0-logloss:0.69080\n",
      "[1000]\tvalidation_0-logloss:0.30705\n",
      "[1151]\tvalidation_0-logloss:0.30633\n",
      "[0]\tvalidation_0-logloss:0.69188\n",
      "[1000]\tvalidation_0-logloss:0.30683\n",
      "[1317]\tvalidation_0-logloss:0.30300\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.68971\n",
      "[1000]\tvalidation_0-logloss:0.11210\n",
      "[2000]\tvalidation_0-logloss:0.08173\n",
      "[2905]\tvalidation_0-logloss:0.07491\n",
      "[0]\tvalidation_0-logloss:0.69030\n",
      "[1000]\tvalidation_0-logloss:0.16449\n",
      "[1834]\tvalidation_0-logloss:0.14433\n",
      "[0]\tvalidation_0-logloss:0.69020\n",
      "[1000]\tvalidation_0-logloss:0.23912\n",
      "[2000]\tvalidation_0-logloss:0.21681\n",
      "[2999]\tvalidation_0-logloss:0.20438\n",
      "[0]\tvalidation_0-logloss:0.69101\n",
      "[879]\tvalidation_0-logloss:0.33542\n",
      "[0]\tvalidation_0-logloss:0.69060\n",
      "[1000]\tvalidation_0-logloss:0.22412\n",
      "[2000]\tvalidation_0-logloss:0.20382\n",
      "[2687]\tvalidation_0-logloss:0.19781\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.69074\n",
      "[1000]\tvalidation_0-logloss:0.26465\n",
      "[1161]\tvalidation_0-logloss:0.26300\n",
      "[0]\tvalidation_0-logloss:0.69205\n",
      "[1000]\tvalidation_0-logloss:0.26427\n",
      "[2000]\tvalidation_0-logloss:0.19565\n",
      "[2999]\tvalidation_0-logloss:0.16624\n",
      "[0]\tvalidation_0-logloss:0.68993\n",
      "[1000]\tvalidation_0-logloss:0.18819\n",
      "[2000]\tvalidation_0-logloss:0.13765\n",
      "[2999]\tvalidation_0-logloss:0.11693\n",
      "[0]\tvalidation_0-logloss:0.69225\n",
      "[1000]\tvalidation_0-logloss:0.27146\n",
      "[2000]\tvalidation_0-logloss:0.23175\n",
      "[2999]\tvalidation_0-logloss:0.20990\n",
      "[0]\tvalidation_0-logloss:0.69158\n",
      "[1000]\tvalidation_0-logloss:0.24017\n",
      "[2000]\tvalidation_0-logloss:0.19058\n",
      "[2999]\tvalidation_0-logloss:0.15968\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.69024\n",
      "[1000]\tvalidation_0-logloss:0.13206\n",
      "[2000]\tvalidation_0-logloss:0.08199\n",
      "[2999]\tvalidation_0-logloss:0.06974\n",
      "[0]\tvalidation_0-logloss:0.69158\n",
      "[1000]\tvalidation_0-logloss:0.31697\n",
      "[2000]\tvalidation_0-logloss:0.29275\n",
      "[2006]\tvalidation_0-logloss:0.29311\n",
      "[0]\tvalidation_0-logloss:0.69097\n",
      "[1000]\tvalidation_0-logloss:0.28008\n",
      "[2000]\tvalidation_0-logloss:0.22824\n",
      "[2999]\tvalidation_0-logloss:0.21656\n",
      "[0]\tvalidation_0-logloss:0.69099\n",
      "[1000]\tvalidation_0-logloss:0.37020\n",
      "[1127]\tvalidation_0-logloss:0.37199\n",
      "[0]\tvalidation_0-logloss:0.69244\n",
      "[1000]\tvalidation_0-logloss:0.21677\n",
      "[1479]\tvalidation_0-logloss:0.20608\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.69244\n",
      "[1000]\tvalidation_0-logloss:0.29082\n",
      "[1257]\tvalidation_0-logloss:0.28758\n",
      "[0]\tvalidation_0-logloss:0.69115\n",
      "[1000]\tvalidation_0-logloss:0.19043\n",
      "[1501]\tvalidation_0-logloss:0.17529\n",
      "[0]\tvalidation_0-logloss:0.69088\n",
      "[1000]\tvalidation_0-logloss:0.15220\n",
      "[2000]\tvalidation_0-logloss:0.10449\n",
      "[2999]\tvalidation_0-logloss:0.09171\n",
      "[0]\tvalidation_0-logloss:0.69062\n",
      "[1000]\tvalidation_0-logloss:0.30139\n",
      "[1325]\tvalidation_0-logloss:0.29661\n",
      "[0]\tvalidation_0-logloss:0.69066\n",
      "[1000]\tvalidation_0-logloss:0.23402\n",
      "[1607]\tvalidation_0-logloss:0.22221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:28:57,992] Trial 7 finished with value: 0.2161163239742509 and parameters: {'booster': 'gbtree', 'alpha': 0.34168240158341634, 'lambda': 2.633136279415161e-07, 'subsample': 0.6467556845791176, 'colsample_bytree': 0.6305522882983134, 'learning_rate': 0.00460225068312338, 'max_depth': 10, 'min_child_weight': 3, 'gamma': 3.5004421525015634e-06, 'grow_policy': 'depthwise'}. Best is trial 7 with value: 0.2161163239742509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.67909\n",
      "[564]\tvalidation_0-logloss:0.18813\n",
      "[0]\tvalidation_0-logloss:0.68621\n",
      "[738]\tvalidation_0-logloss:0.18885\n",
      "[0]\tvalidation_0-logloss:0.67963\n",
      "[547]\tvalidation_0-logloss:0.31977\n",
      "[0]\tvalidation_0-logloss:0.67578\n",
      "[322]\tvalidation_0-logloss:0.29945\n",
      "[0]\tvalidation_0-logloss:0.68176\n",
      "[312]\tvalidation_0-logloss:0.33179\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.67211\n",
      "[854]\tvalidation_0-logloss:0.05832\n",
      "[0]\tvalidation_0-logloss:0.68707\n",
      "[364]\tvalidation_0-logloss:0.11062\n",
      "[0]\tvalidation_0-logloss:0.67445\n",
      "[316]\tvalidation_0-logloss:0.19413\n",
      "[0]\tvalidation_0-logloss:0.68732\n",
      "[235]\tvalidation_0-logloss:0.34346\n",
      "[0]\tvalidation_0-logloss:0.67869\n",
      "[406]\tvalidation_0-logloss:0.18938\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.68349\n",
      "[285]\tvalidation_0-logloss:0.25390\n",
      "[0]\tvalidation_0-logloss:0.67788\n",
      "[974]\tvalidation_0-logloss:0.12447\n",
      "[0]\tvalidation_0-logloss:0.67825\n",
      "[1000]\tvalidation_0-logloss:0.11532\n",
      "[1270]\tvalidation_0-logloss:0.11283\n",
      "[0]\tvalidation_0-logloss:0.68541\n",
      "[948]\tvalidation_0-logloss:0.15532\n",
      "[0]\tvalidation_0-logloss:0.68241\n",
      "[1000]\tvalidation_0-logloss:0.12091\n",
      "[1124]\tvalidation_0-logloss:0.12128\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.67567\n",
      "[903]\tvalidation_0-logloss:0.04120\n",
      "[0]\tvalidation_0-logloss:0.68242\n",
      "[378]\tvalidation_0-logloss:0.24872\n",
      "[0]\tvalidation_0-logloss:0.68150\n",
      "[406]\tvalidation_0-logloss:0.20507\n",
      "[0]\tvalidation_0-logloss:0.67828\n",
      "[952]\tvalidation_0-logloss:0.29747\n",
      "[0]\tvalidation_0-logloss:0.68669\n",
      "[271]\tvalidation_0-logloss:0.21525\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.67831\n",
      "[292]\tvalidation_0-logloss:0.26670\n",
      "[0]\tvalidation_0-logloss:0.67020\n",
      "[357]\tvalidation_0-logloss:0.15834\n",
      "[0]\tvalidation_0-logloss:0.67727\n",
      "[1000]\tvalidation_0-logloss:0.05742\n",
      "[1002]\tvalidation_0-logloss:0.05716\n",
      "[0]\tvalidation_0-logloss:0.68998\n",
      "[245]\tvalidation_0-logloss:0.29359\n",
      "[0]\tvalidation_0-logloss:0.67227\n",
      "[303]\tvalidation_0-logloss:0.21808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:29:04,867] Trial 8 finished with value: 0.19453448622302355 and parameters: {'booster': 'gbtree', 'alpha': 4.383408941082582e-08, 'lambda': 7.224002743743152e-06, 'subsample': 0.7214192492925153, 'colsample_bytree': 0.6487475085154554, 'learning_rate': 0.03325288085414608, 'max_depth': 3, 'min_child_weight': 2, 'gamma': 1.87597859410113e-06, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.19453448622302355.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.69195\n",
      "[1000]\tvalidation_0-logloss:0.31229\n",
      "[2000]\tvalidation_0-logloss:0.26761\n",
      "[2656]\tvalidation_0-logloss:0.26208\n",
      "[0]\tvalidation_0-logloss:0.69162\n",
      "[1000]\tvalidation_0-logloss:0.25470\n",
      "[1915]\tvalidation_0-logloss:0.21886\n",
      "[0]\tvalidation_0-logloss:0.68969\n",
      "[472]\tvalidation_0-logloss:0.48283\n",
      "[0]\tvalidation_0-logloss:0.69084\n",
      "[1000]\tvalidation_0-logloss:0.37498\n",
      "[1052]\tvalidation_0-logloss:0.37337\n",
      "[0]\tvalidation_0-logloss:0.69009\n",
      "[1000]\tvalidation_0-logloss:0.40883\n",
      "[1626]\tvalidation_0-logloss:0.40144\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.68722\n",
      "[1000]\tvalidation_0-logloss:0.12938\n",
      "[2000]\tvalidation_0-logloss:0.10660\n",
      "[2868]\tvalidation_0-logloss:0.10200\n",
      "[0]\tvalidation_0-logloss:0.68920\n",
      "[943]\tvalidation_0-logloss:0.25796\n",
      "[0]\tvalidation_0-logloss:0.68886\n",
      "[1000]\tvalidation_0-logloss:0.27779\n",
      "[2000]\tvalidation_0-logloss:0.25984\n",
      "[2731]\tvalidation_0-logloss:0.25337\n",
      "[0]\tvalidation_0-logloss:0.68905\n",
      "[537]\tvalidation_0-logloss:0.42491\n",
      "[0]\tvalidation_0-logloss:0.68892\n",
      "[1000]\tvalidation_0-logloss:0.25171\n",
      "[2000]\tvalidation_0-logloss:0.22854\n",
      "[2442]\tvalidation_0-logloss:0.22418\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.69082\n",
      "[1000]\tvalidation_0-logloss:0.32055\n",
      "[1520]\tvalidation_0-logloss:0.30930\n",
      "[0]\tvalidation_0-logloss:0.69209\n",
      "[1000]\tvalidation_0-logloss:0.28882\n",
      "[2000]\tvalidation_0-logloss:0.23223\n",
      "[2999]\tvalidation_0-logloss:0.22224\n",
      "[0]\tvalidation_0-logloss:0.69041\n",
      "[1000]\tvalidation_0-logloss:0.18504\n",
      "[2000]\tvalidation_0-logloss:0.14947\n",
      "[2696]\tvalidation_0-logloss:0.14490\n",
      "[0]\tvalidation_0-logloss:0.69115\n",
      "[1000]\tvalidation_0-logloss:0.30070\n",
      "[2000]\tvalidation_0-logloss:0.26725\n",
      "[2026]\tvalidation_0-logloss:0.26717\n",
      "[0]\tvalidation_0-logloss:0.69078\n",
      "[1000]\tvalidation_0-logloss:0.27866\n",
      "[2000]\tvalidation_0-logloss:0.23706\n",
      "[2387]\tvalidation_0-logloss:0.23486\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.69180\n",
      "[1000]\tvalidation_0-logloss:0.15700\n",
      "[2000]\tvalidation_0-logloss:0.13004\n",
      "[2498]\tvalidation_0-logloss:0.12713\n",
      "[0]\tvalidation_0-logloss:0.69055\n",
      "[817]\tvalidation_0-logloss:0.42750\n",
      "[0]\tvalidation_0-logloss:0.69090\n",
      "[1000]\tvalidation_0-logloss:0.34579\n",
      "[1878]\tvalidation_0-logloss:0.30543\n",
      "[0]\tvalidation_0-logloss:0.68956\n",
      "[331]\tvalidation_0-logloss:0.47097\n",
      "[0]\tvalidation_0-logloss:0.69079\n",
      "[1000]\tvalidation_0-logloss:0.22364\n",
      "[2000]\tvalidation_0-logloss:0.19499\n",
      "[2399]\tvalidation_0-logloss:0.19109\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.69062\n",
      "[602]\tvalidation_0-logloss:0.34839\n",
      "[0]\tvalidation_0-logloss:0.68798\n",
      "[1000]\tvalidation_0-logloss:0.22228\n",
      "[1442]\tvalidation_0-logloss:0.21818\n",
      "[0]\tvalidation_0-logloss:0.68902\n",
      "[1000]\tvalidation_0-logloss:0.16552\n",
      "[2000]\tvalidation_0-logloss:0.13277\n",
      "[2676]\tvalidation_0-logloss:0.12863\n",
      "[0]\tvalidation_0-logloss:0.69013\n",
      "[638]\tvalidation_0-logloss:0.34473\n",
      "[0]\tvalidation_0-logloss:0.68900\n",
      "[1000]\tvalidation_0-logloss:0.31350\n",
      "[1126]\tvalidation_0-logloss:0.31598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:29:23,751] Trial 9 finished with value: 0.2807813295226981 and parameters: {'booster': 'gbtree', 'alpha': 2.21761125917675e-06, 'lambda': 4.839015380711274e-07, 'subsample': 0.7331140614158747, 'colsample_bytree': 0.6296714747215986, 'learning_rate': 0.008262126104638789, 'max_depth': 8, 'min_child_weight': 8, 'gamma': 0.00039833279485992603, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.19453448622302355.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.69280\n",
      "[1000]\tvalidation_0-logloss:0.48232\n",
      "[2000]\tvalidation_0-logloss:0.37538\n",
      "[2999]\tvalidation_0-logloss:0.30243\n",
      "[0]\tvalidation_0-logloss:0.69268\n",
      "[1000]\tvalidation_0-logloss:0.43700\n",
      "[2000]\tvalidation_0-logloss:0.32790\n",
      "[2999]\tvalidation_0-logloss:0.27324\n",
      "[0]\tvalidation_0-logloss:0.69263\n",
      "[1000]\tvalidation_0-logloss:0.45601\n",
      "[2000]\tvalidation_0-logloss:0.37881\n",
      "[2999]\tvalidation_0-logloss:0.34839\n",
      "[0]\tvalidation_0-logloss:0.69274\n",
      "[1000]\tvalidation_0-logloss:0.46698\n",
      "[2000]\tvalidation_0-logloss:0.38270\n",
      "[2999]\tvalidation_0-logloss:0.34442\n",
      "[0]\tvalidation_0-logloss:0.69277\n",
      "[1000]\tvalidation_0-logloss:0.44565\n",
      "[2000]\tvalidation_0-logloss:0.35538\n",
      "[2999]\tvalidation_0-logloss:0.31672\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.69275\n",
      "[1000]\tvalidation_0-logloss:0.34750\n",
      "[2000]\tvalidation_0-logloss:0.21172\n",
      "[2999]\tvalidation_0-logloss:0.14818\n",
      "[0]\tvalidation_0-logloss:0.69271\n",
      "[1000]\tvalidation_0-logloss:0.42524\n",
      "[2000]\tvalidation_0-logloss:0.27887\n",
      "[2999]\tvalidation_0-logloss:0.20109\n",
      "[0]\tvalidation_0-logloss:0.69274\n",
      "[1000]\tvalidation_0-logloss:0.41861\n",
      "[2000]\tvalidation_0-logloss:0.31166\n",
      "[2999]\tvalidation_0-logloss:0.25897\n",
      "[0]\tvalidation_0-logloss:0.69271\n",
      "[1000]\tvalidation_0-logloss:0.46305\n",
      "[2000]\tvalidation_0-logloss:0.38020\n",
      "[2999]\tvalidation_0-logloss:0.34605\n",
      "[0]\tvalidation_0-logloss:0.69281\n",
      "[1000]\tvalidation_0-logloss:0.41451\n",
      "[2000]\tvalidation_0-logloss:0.29942\n",
      "[2999]\tvalidation_0-logloss:0.24737\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.69282\n",
      "[1000]\tvalidation_0-logloss:0.42742\n",
      "[2000]\tvalidation_0-logloss:0.31967\n",
      "[2999]\tvalidation_0-logloss:0.27644\n",
      "[0]\tvalidation_0-logloss:0.69263\n",
      "[1000]\tvalidation_0-logloss:0.46308\n",
      "[2000]\tvalidation_0-logloss:0.35923\n",
      "[2999]\tvalidation_0-logloss:0.29536\n",
      "[0]\tvalidation_0-logloss:0.69272\n",
      "[1000]\tvalidation_0-logloss:0.44950\n",
      "[2000]\tvalidation_0-logloss:0.32856\n",
      "[2999]\tvalidation_0-logloss:0.24949\n",
      "[0]\tvalidation_0-logloss:0.69277\n",
      "[1000]\tvalidation_0-logloss:0.47362\n",
      "[2000]\tvalidation_0-logloss:0.36433\n",
      "[2999]\tvalidation_0-logloss:0.30234\n",
      "[0]\tvalidation_0-logloss:0.69279\n",
      "[1000]\tvalidation_0-logloss:0.49086\n",
      "[2000]\tvalidation_0-logloss:0.36473\n",
      "[2999]\tvalidation_0-logloss:0.28656\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.69252\n",
      "[1000]\tvalidation_0-logloss:0.39594\n",
      "[2000]\tvalidation_0-logloss:0.25951\n",
      "[2999]\tvalidation_0-logloss:0.18288\n",
      "[0]\tvalidation_0-logloss:0.69271\n",
      "[1000]\tvalidation_0-logloss:0.51552\n",
      "[2000]\tvalidation_0-logloss:0.41050\n",
      "[2999]\tvalidation_0-logloss:0.34585\n",
      "[0]\tvalidation_0-logloss:0.69262\n",
      "[1000]\tvalidation_0-logloss:0.46717\n",
      "[2000]\tvalidation_0-logloss:0.37273\n",
      "[2999]\tvalidation_0-logloss:0.31634\n",
      "[0]\tvalidation_0-logloss:0.69274\n",
      "[1000]\tvalidation_0-logloss:0.47012\n",
      "[2000]\tvalidation_0-logloss:0.39481\n",
      "[2999]\tvalidation_0-logloss:0.36376\n",
      "[0]\tvalidation_0-logloss:0.69296\n",
      "[1000]\tvalidation_0-logloss:0.39452\n",
      "[2000]\tvalidation_0-logloss:0.28268\n",
      "[2999]\tvalidation_0-logloss:0.23487\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.69283\n",
      "[1000]\tvalidation_0-logloss:0.45341\n",
      "[2000]\tvalidation_0-logloss:0.35016\n",
      "[2999]\tvalidation_0-logloss:0.30360\n",
      "[0]\tvalidation_0-logloss:0.69268\n",
      "[1000]\tvalidation_0-logloss:0.42013\n",
      "[2000]\tvalidation_0-logloss:0.29477\n",
      "[2999]\tvalidation_0-logloss:0.23220\n",
      "[0]\tvalidation_0-logloss:0.69279\n",
      "[1000]\tvalidation_0-logloss:0.42016\n",
      "[2000]\tvalidation_0-logloss:0.28680\n",
      "[2999]\tvalidation_0-logloss:0.20538\n",
      "[0]\tvalidation_0-logloss:0.69294\n",
      "[1000]\tvalidation_0-logloss:0.47308\n",
      "[2000]\tvalidation_0-logloss:0.38436\n",
      "[2999]\tvalidation_0-logloss:0.33615\n",
      "[0]\tvalidation_0-logloss:0.69288\n",
      "[1000]\tvalidation_0-logloss:0.42508\n",
      "[2000]\tvalidation_0-logloss:0.31245\n",
      "[2999]\tvalidation_0-logloss:0.25636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:30:01,892] Trial 10 finished with value: 0.2789750803750953 and parameters: {'booster': 'gbtree', 'alpha': 5.2074748137124503e-08, 'lambda': 0.24977844976744568, 'subsample': 0.5459264243204285, 'colsample_bytree': 0.7900878585863832, 'learning_rate': 0.0011164871539282425, 'max_depth': 3, 'min_child_weight': 2, 'gamma': 1.686644629592159e-08, 'grow_policy': 'lossguide'}. Best is trial 8 with value: 0.19453448622302355.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.67438\n",
      "[337]\tvalidation_0-logloss:0.20444\n",
      "[0]\tvalidation_0-logloss:0.67090\n",
      "[689]\tvalidation_0-logloss:0.17668\n",
      "[0]\tvalidation_0-logloss:0.67964\n",
      "[237]\tvalidation_0-logloss:0.32245\n",
      "[0]\tvalidation_0-logloss:0.67554\n",
      "[213]\tvalidation_0-logloss:0.32650\n",
      "[0]\tvalidation_0-logloss:0.67247\n",
      "[266]\tvalidation_0-logloss:0.30518\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.67818\n",
      "[553]\tvalidation_0-logloss:0.06217\n",
      "[0]\tvalidation_0-logloss:0.67198\n",
      "[272]\tvalidation_0-logloss:0.13285\n",
      "[0]\tvalidation_0-logloss:0.66794\n",
      "[1000]\tvalidation_0-logloss:0.18055\n",
      "[1012]\tvalidation_0-logloss:0.17961\n",
      "[0]\tvalidation_0-logloss:0.68103\n",
      "[204]\tvalidation_0-logloss:0.34653\n",
      "[0]\tvalidation_0-logloss:0.66897\n",
      "[455]\tvalidation_0-logloss:0.18587\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.66838\n",
      "[280]\tvalidation_0-logloss:0.25700\n",
      "[0]\tvalidation_0-logloss:0.67835\n",
      "[707]\tvalidation_0-logloss:0.13249\n",
      "[0]\tvalidation_0-logloss:0.67327\n",
      "[742]\tvalidation_0-logloss:0.08574\n",
      "[0]\tvalidation_0-logloss:0.67577\n",
      "[888]\tvalidation_0-logloss:0.15175\n",
      "[0]\tvalidation_0-logloss:0.68149\n",
      "[976]\tvalidation_0-logloss:0.09412\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.66984\n",
      "[635]\tvalidation_0-logloss:0.05282\n",
      "[0]\tvalidation_0-logloss:0.67755\n",
      "[288]\tvalidation_0-logloss:0.28268\n",
      "[0]\tvalidation_0-logloss:0.67309\n",
      "[403]\tvalidation_0-logloss:0.21914\n",
      "[0]\tvalidation_0-logloss:0.67685\n",
      "[1000]\tvalidation_0-logloss:0.25466\n",
      "[1122]\tvalidation_0-logloss:0.25594\n",
      "[0]\tvalidation_0-logloss:0.68657\n",
      "[224]\tvalidation_0-logloss:0.21824\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.67341\n",
      "[242]\tvalidation_0-logloss:0.28913\n",
      "[0]\tvalidation_0-logloss:0.67203\n",
      "[255]\tvalidation_0-logloss:0.16520\n",
      "[0]\tvalidation_0-logloss:0.67017\n",
      "[632]\tvalidation_0-logloss:0.07179\n",
      "[0]\tvalidation_0-logloss:0.67169\n",
      "[353]\tvalidation_0-logloss:0.30673\n",
      "[0]\tvalidation_0-logloss:0.66744\n",
      "[264]\tvalidation_0-logloss:0.20408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:30:07,971] Trial 11 finished with value: 0.1930995163714154 and parameters: {'booster': 'gbtree', 'alpha': 0.008337045735939824, 'lambda': 1.2773032475076913e-06, 'subsample': 0.5881656713002873, 'colsample_bytree': 0.7463972542037534, 'learning_rate': 0.041082829795820654, 'max_depth': 4, 'min_child_weight': 2, 'gamma': 7.861350185475737e-07, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.1930995163714154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.67527\n",
      "[371]\tvalidation_0-logloss:0.26118\n",
      "[0]\tvalidation_0-logloss:0.67525\n",
      "[464]\tvalidation_0-logloss:0.20159\n",
      "[0]\tvalidation_0-logloss:0.66892\n",
      "[547]\tvalidation_0-logloss:0.34287\n",
      "[0]\tvalidation_0-logloss:0.67557\n",
      "[224]\tvalidation_0-logloss:0.37245\n",
      "[0]\tvalidation_0-logloss:0.67872\n",
      "[402]\tvalidation_0-logloss:0.34761\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.66731\n",
      "[550]\tvalidation_0-logloss:0.08070\n",
      "[0]\tvalidation_0-logloss:0.67761\n",
      "[373]\tvalidation_0-logloss:0.20090\n",
      "[0]\tvalidation_0-logloss:0.67852\n",
      "[426]\tvalidation_0-logloss:0.20967\n",
      "[0]\tvalidation_0-logloss:0.67467\n",
      "[168]\tvalidation_0-logloss:0.38562\n",
      "[0]\tvalidation_0-logloss:0.67579\n",
      "[411]\tvalidation_0-logloss:0.20702\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.66461\n",
      "[424]\tvalidation_0-logloss:0.29920\n",
      "[0]\tvalidation_0-logloss:0.68094\n",
      "[706]\tvalidation_0-logloss:0.14279\n",
      "[0]\tvalidation_0-logloss:0.67339\n",
      "[634]\tvalidation_0-logloss:0.10729\n",
      "[0]\tvalidation_0-logloss:0.67901\n",
      "[430]\tvalidation_0-logloss:0.20733\n",
      "[0]\tvalidation_0-logloss:0.67461\n",
      "[507]\tvalidation_0-logloss:0.15775\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.67128\n",
      "[564]\tvalidation_0-logloss:0.08495\n",
      "[0]\tvalidation_0-logloss:0.67498\n",
      "[230]\tvalidation_0-logloss:0.36713\n",
      "[0]\tvalidation_0-logloss:0.66851\n",
      "[409]\tvalidation_0-logloss:0.24469\n",
      "[0]\tvalidation_0-logloss:0.67239\n",
      "[1000]\tvalidation_0-logloss:0.31713\n",
      "[1064]\tvalidation_0-logloss:0.31678\n",
      "[0]\tvalidation_0-logloss:0.67591\n",
      "[696]\tvalidation_0-logloss:0.15553\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.67013\n",
      "[335]\tvalidation_0-logloss:0.30718\n",
      "[0]\tvalidation_0-logloss:0.67462\n",
      "[248]\tvalidation_0-logloss:0.19008\n",
      "[0]\tvalidation_0-logloss:0.67624\n",
      "[539]\tvalidation_0-logloss:0.09191\n",
      "[0]\tvalidation_0-logloss:0.66665\n",
      "[188]\tvalidation_0-logloss:0.33982\n",
      "[0]\tvalidation_0-logloss:0.68161\n",
      "[228]\tvalidation_0-logloss:0.31197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:30:13,254] Trial 12 finished with value: 0.22774611920433596 and parameters: {'booster': 'gbtree', 'alpha': 0.0038773497909091736, 'lambda': 1.0596491399462018e-05, 'subsample': 0.5713432404091563, 'colsample_bytree': 0.7733492716535749, 'learning_rate': 0.050398767666114355, 'max_depth': 3, 'min_child_weight': 4, 'gamma': 1.1088363890597523e-06, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.1930995163714154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.68265\n",
      "[574]\tvalidation_0-logloss:0.26779\n",
      "[0]\tvalidation_0-logloss:0.68239\n",
      "[910]\tvalidation_0-logloss:0.19025\n",
      "[0]\tvalidation_0-logloss:0.67835\n",
      "[549]\tvalidation_0-logloss:0.34818\n",
      "[0]\tvalidation_0-logloss:0.68377\n",
      "[409]\tvalidation_0-logloss:0.35613\n",
      "[0]\tvalidation_0-logloss:0.68295\n",
      "[420]\tvalidation_0-logloss:0.33334\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.67285\n",
      "[854]\tvalidation_0-logloss:0.08571\n",
      "[0]\tvalidation_0-logloss:0.68229\n",
      "[365]\tvalidation_0-logloss:0.22362\n",
      "[0]\tvalidation_0-logloss:0.67518\n",
      "[1000]\tvalidation_0-logloss:0.22330\n",
      "[1120]\tvalidation_0-logloss:0.22106\n",
      "[0]\tvalidation_0-logloss:0.67809\n",
      "[227]\tvalidation_0-logloss:0.41606\n",
      "[0]\tvalidation_0-logloss:0.67594\n",
      "[872]\tvalidation_0-logloss:0.20362\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.67704\n",
      "[635]\tvalidation_0-logloss:0.27499\n",
      "[0]\tvalidation_0-logloss:0.68247\n",
      "[935]\tvalidation_0-logloss:0.18215\n",
      "[0]\tvalidation_0-logloss:0.67608\n",
      "[746]\tvalidation_0-logloss:0.11535\n",
      "[0]\tvalidation_0-logloss:0.68902\n",
      "[1000]\tvalidation_0-logloss:0.21879\n",
      "[1196]\tvalidation_0-logloss:0.21852\n",
      "[0]\tvalidation_0-logloss:0.67989\n",
      "[568]\tvalidation_0-logloss:0.18789\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.68875\n",
      "[895]\tvalidation_0-logloss:0.09803\n",
      "[0]\tvalidation_0-logloss:0.68194\n",
      "[344]\tvalidation_0-logloss:0.39126\n",
      "[0]\tvalidation_0-logloss:0.67770\n",
      "[1000]\tvalidation_0-logloss:0.24291\n",
      "[1042]\tvalidation_0-logloss:0.24247\n",
      "[0]\tvalidation_0-logloss:0.68074\n",
      "[944]\tvalidation_0-logloss:0.34291\n",
      "[0]\tvalidation_0-logloss:0.67927\n",
      "[628]\tvalidation_0-logloss:0.18074\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.68674\n",
      "[232]\tvalidation_0-logloss:0.34195\n",
      "[0]\tvalidation_0-logloss:0.67710\n",
      "[366]\tvalidation_0-logloss:0.20908\n",
      "[0]\tvalidation_0-logloss:0.68429\n",
      "[783]\tvalidation_0-logloss:0.11942\n",
      "[0]\tvalidation_0-logloss:0.67787\n",
      "[369]\tvalidation_0-logloss:0.32349\n",
      "[0]\tvalidation_0-logloss:0.67634\n",
      "[281]\tvalidation_0-logloss:0.27768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:30:20,567] Trial 13 finished with value: 0.24072421654345516 and parameters: {'booster': 'gbtree', 'alpha': 1.305902982967035e-08, 'lambda': 2.5172351460072036e-06, 'subsample': 0.5753938269675715, 'colsample_bytree': 0.7623992790871502, 'learning_rate': 0.031632044063630856, 'max_depth': 5, 'min_child_weight': 5, 'gamma': 2.163742885523729e-06, 'grow_policy': 'depthwise'}. Best is trial 11 with value: 0.1930995163714154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.68310\n",
      "[456]\tvalidation_0-logloss:0.18281\n",
      "[0]\tvalidation_0-logloss:0.67702\n",
      "[948]\tvalidation_0-logloss:0.17564\n",
      "[0]\tvalidation_0-logloss:0.67811\n",
      "[206]\tvalidation_0-logloss:0.32507\n",
      "[0]\tvalidation_0-logloss:0.67605\n",
      "[296]\tvalidation_0-logloss:0.28860\n",
      "[0]\tvalidation_0-logloss:0.67681\n",
      "[226]\tvalidation_0-logloss:0.30176\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.66796\n",
      "[779]\tvalidation_0-logloss:0.05935\n",
      "[0]\tvalidation_0-logloss:0.67258\n",
      "[426]\tvalidation_0-logloss:0.08057\n",
      "[0]\tvalidation_0-logloss:0.67284\n",
      "[291]\tvalidation_0-logloss:0.20741\n",
      "[0]\tvalidation_0-logloss:0.68081\n",
      "[215]\tvalidation_0-logloss:0.33796\n",
      "[0]\tvalidation_0-logloss:0.67919\n",
      "[667]\tvalidation_0-logloss:0.19042\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.67715\n",
      "[227]\tvalidation_0-logloss:0.23578\n",
      "[0]\tvalidation_0-logloss:0.67367\n",
      "[958]\tvalidation_0-logloss:0.12054\n",
      "[0]\tvalidation_0-logloss:0.68044\n",
      "[1000]\tvalidation_0-logloss:0.09029\n",
      "[1274]\tvalidation_0-logloss:0.08938\n",
      "[0]\tvalidation_0-logloss:0.67985\n",
      "[1000]\tvalidation_0-logloss:0.14513\n",
      "[1321]\tvalidation_0-logloss:0.14404\n",
      "[0]\tvalidation_0-logloss:0.67640\n",
      "[756]\tvalidation_0-logloss:0.14776\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.67830\n",
      "[1000]\tvalidation_0-logloss:0.03575\n",
      "[1065]\tvalidation_0-logloss:0.03578\n",
      "[0]\tvalidation_0-logloss:0.68379\n",
      "[405]\tvalidation_0-logloss:0.24187\n",
      "[0]\tvalidation_0-logloss:0.67542\n",
      "[395]\tvalidation_0-logloss:0.22039\n",
      "[0]\tvalidation_0-logloss:0.67691\n",
      "[209]\tvalidation_0-logloss:0.35251\n",
      "[0]\tvalidation_0-logloss:0.67647\n",
      "[247]\tvalidation_0-logloss:0.22172\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.67616\n",
      "[213]\tvalidation_0-logloss:0.28856\n",
      "[0]\tvalidation_0-logloss:0.67611\n",
      "[357]\tvalidation_0-logloss:0.16932\n",
      "[0]\tvalidation_0-logloss:0.67530\n",
      "[1000]\tvalidation_0-logloss:0.05621\n",
      "[1121]\tvalidation_0-logloss:0.05557\n",
      "[0]\tvalidation_0-logloss:0.69031\n",
      "[239]\tvalidation_0-logloss:0.29052\n",
      "[0]\tvalidation_0-logloss:0.67344\n",
      "[244]\tvalidation_0-logloss:0.19254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:30:27,623] Trial 14 finished with value: 0.19042787401206218 and parameters: {'booster': 'gbtree', 'alpha': 0.0027937466766300503, 'lambda': 2.7138521177750515e-06, 'subsample': 0.8141487090356295, 'colsample_bytree': 0.8810635829162934, 'learning_rate': 0.02919081520857816, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 1.9982059654628238e-08, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.19042787401206218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.64428\n",
      "[287]\tvalidation_0-logloss:0.19797\n",
      "[0]\tvalidation_0-logloss:0.64830\n",
      "[321]\tvalidation_0-logloss:0.20343\n",
      "[0]\tvalidation_0-logloss:0.65742\n",
      "[506]\tvalidation_0-logloss:0.30169\n",
      "[0]\tvalidation_0-logloss:0.65392\n",
      "[168]\tvalidation_0-logloss:0.32080\n",
      "[0]\tvalidation_0-logloss:0.65758\n",
      "[227]\tvalidation_0-logloss:0.33696\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.63341\n",
      "[412]\tvalidation_0-logloss:0.08022\n",
      "[0]\tvalidation_0-logloss:0.66129\n",
      "[164]\tvalidation_0-logloss:0.19181\n",
      "[0]\tvalidation_0-logloss:0.66236\n",
      "[271]\tvalidation_0-logloss:0.18934\n",
      "[0]\tvalidation_0-logloss:0.66407\n",
      "[133]\tvalidation_0-logloss:0.39863\n",
      "[0]\tvalidation_0-logloss:0.65168\n",
      "[421]\tvalidation_0-logloss:0.20402\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.66310\n",
      "[200]\tvalidation_0-logloss:0.28374\n",
      "[0]\tvalidation_0-logloss:0.66695\n",
      "[613]\tvalidation_0-logloss:0.15821\n",
      "[0]\tvalidation_0-logloss:0.66852\n",
      "[395]\tvalidation_0-logloss:0.10681\n",
      "[0]\tvalidation_0-logloss:0.66030\n",
      "[391]\tvalidation_0-logloss:0.22572\n",
      "[0]\tvalidation_0-logloss:0.66582\n",
      "[399]\tvalidation_0-logloss:0.17767\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.65134\n",
      "[372]\tvalidation_0-logloss:0.06947\n",
      "[0]\tvalidation_0-logloss:0.66704\n",
      "[179]\tvalidation_0-logloss:0.31865\n",
      "[0]\tvalidation_0-logloss:0.65115\n",
      "[640]\tvalidation_0-logloss:0.23315\n",
      "[0]\tvalidation_0-logloss:0.65385\n",
      "[691]\tvalidation_0-logloss:0.34112\n",
      "[0]\tvalidation_0-logloss:0.64541\n",
      "[542]\tvalidation_0-logloss:0.17598\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.65809\n",
      "[394]\tvalidation_0-logloss:0.29931\n",
      "[0]\tvalidation_0-logloss:0.65171\n",
      "[221]\tvalidation_0-logloss:0.18751\n",
      "[0]\tvalidation_0-logloss:0.64638\n",
      "[1000]\tvalidation_0-logloss:0.07861\n",
      "[1128]\tvalidation_0-logloss:0.07737\n",
      "[0]\tvalidation_0-logloss:0.67335\n",
      "[162]\tvalidation_0-logloss:0.30588\n",
      "[0]\tvalidation_0-logloss:0.65431\n",
      "[230]\tvalidation_0-logloss:0.24247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:30:32,372] Trial 15 finished with value: 0.21633831475070214 and parameters: {'booster': 'gbtree', 'alpha': 0.007856446303269218, 'lambda': 1.0251258377880626e-08, 'subsample': 0.8449816432887808, 'colsample_bytree': 0.8948878104762891, 'learning_rate': 0.08357681560179434, 'max_depth': 5, 'min_child_weight': 5, 'gamma': 1.0891531063019111e-08, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.19042787401206218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.68788\n",
      "[854]\tvalidation_0-logloss:0.22366\n",
      "[0]\tvalidation_0-logloss:0.68357\n",
      "[871]\tvalidation_0-logloss:0.18031\n",
      "[0]\tvalidation_0-logloss:0.68564\n",
      "[795]\tvalidation_0-logloss:0.33571\n",
      "[0]\tvalidation_0-logloss:0.68465\n",
      "[283]\tvalidation_0-logloss:0.33059\n",
      "[0]\tvalidation_0-logloss:0.68727\n",
      "[403]\tvalidation_0-logloss:0.32905\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.68311\n",
      "[858]\tvalidation_0-logloss:0.08189\n",
      "[0]\tvalidation_0-logloss:0.68446\n",
      "[412]\tvalidation_0-logloss:0.17314\n",
      "[0]\tvalidation_0-logloss:0.68716\n",
      "[827]\tvalidation_0-logloss:0.21017\n",
      "[0]\tvalidation_0-logloss:0.68321\n",
      "[258]\tvalidation_0-logloss:0.36261\n",
      "[0]\tvalidation_0-logloss:0.68643\n",
      "[717]\tvalidation_0-logloss:0.18939\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.68827\n",
      "[339]\tvalidation_0-logloss:0.28302\n",
      "[0]\tvalidation_0-logloss:0.68692\n",
      "[756]\tvalidation_0-logloss:0.17217\n",
      "[0]\tvalidation_0-logloss:0.68397\n",
      "[742]\tvalidation_0-logloss:0.12015\n",
      "[0]\tvalidation_0-logloss:0.68884\n",
      "[731]\tvalidation_0-logloss:0.22381\n",
      "[0]\tvalidation_0-logloss:0.68260\n",
      "[1000]\tvalidation_0-logloss:0.13904\n",
      "[1254]\tvalidation_0-logloss:0.13716\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.68404\n",
      "[898]\tvalidation_0-logloss:0.07547\n",
      "[0]\tvalidation_0-logloss:0.68571\n",
      "[400]\tvalidation_0-logloss:0.30409\n",
      "[0]\tvalidation_0-logloss:0.68251\n",
      "[1000]\tvalidation_0-logloss:0.24350\n",
      "[1263]\tvalidation_0-logloss:0.24263\n",
      "[0]\tvalidation_0-logloss:0.68302\n",
      "[265]\tvalidation_0-logloss:0.37373\n",
      "[0]\tvalidation_0-logloss:0.68669\n",
      "[606]\tvalidation_0-logloss:0.19798\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.68338\n",
      "[921]\tvalidation_0-logloss:0.27958\n",
      "[0]\tvalidation_0-logloss:0.68414\n",
      "[349]\tvalidation_0-logloss:0.19997\n",
      "[0]\tvalidation_0-logloss:0.68061\n",
      "[1000]\tvalidation_0-logloss:0.08648\n",
      "[1154]\tvalidation_0-logloss:0.08471\n",
      "[0]\tvalidation_0-logloss:0.68334\n",
      "[403]\tvalidation_0-logloss:0.32705\n",
      "[0]\tvalidation_0-logloss:0.68773\n",
      "[392]\tvalidation_0-logloss:0.25900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:30:40,860] Trial 16 finished with value: 0.2231321558737589 and parameters: {'booster': 'gbtree', 'alpha': 0.00134217561088062, 'lambda': 7.594781053671044e-07, 'subsample': 0.46682263229961274, 'colsample_bytree': 0.9998060445070174, 'learning_rate': 0.02101985988722709, 'max_depth': 5, 'min_child_weight': 3, 'gamma': 6.382277604477745e-08, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.19042787401206218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.68401\n",
      "[908]\tvalidation_0-logloss:0.16983\n",
      "[0]\tvalidation_0-logloss:0.68314\n",
      "[1000]\tvalidation_0-logloss:0.17580\n",
      "[1144]\tvalidation_0-logloss:0.17813\n",
      "[0]\tvalidation_0-logloss:0.68552\n",
      "[322]\tvalidation_0-logloss:0.31791\n",
      "[0]\tvalidation_0-logloss:0.68593\n",
      "[423]\tvalidation_0-logloss:0.30274\n",
      "[0]\tvalidation_0-logloss:0.68416\n",
      "[393]\tvalidation_0-logloss:0.29132\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.68101\n",
      "[1000]\tvalidation_0-logloss:0.06612\n",
      "[1015]\tvalidation_0-logloss:0.06600\n",
      "[0]\tvalidation_0-logloss:0.68680\n",
      "[567]\tvalidation_0-logloss:0.12690\n",
      "[0]\tvalidation_0-logloss:0.68531\n",
      "[588]\tvalidation_0-logloss:0.20309\n",
      "[0]\tvalidation_0-logloss:0.68593\n",
      "[308]\tvalidation_0-logloss:0.31558\n",
      "[0]\tvalidation_0-logloss:0.68298\n",
      "[868]\tvalidation_0-logloss:0.18350\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.68165\n",
      "[497]\tvalidation_0-logloss:0.24873\n",
      "[0]\tvalidation_0-logloss:0.68414\n",
      "[1000]\tvalidation_0-logloss:0.12198\n",
      "[1196]\tvalidation_0-logloss:0.11968\n",
      "[0]\tvalidation_0-logloss:0.68762\n",
      "[1000]\tvalidation_0-logloss:0.09251\n",
      "[1195]\tvalidation_0-logloss:0.09063\n",
      "[0]\tvalidation_0-logloss:0.68558\n",
      "[1000]\tvalidation_0-logloss:0.16844\n",
      "[1204]\tvalidation_0-logloss:0.16551\n",
      "[0]\tvalidation_0-logloss:0.68476\n",
      "[1000]\tvalidation_0-logloss:0.14081\n",
      "[1293]\tvalidation_0-logloss:0.14058\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.68765\n",
      "[1000]\tvalidation_0-logloss:0.04283\n",
      "[1042]\tvalidation_0-logloss:0.04299\n",
      "[0]\tvalidation_0-logloss:0.68404\n",
      "[403]\tvalidation_0-logloss:0.26417\n",
      "[0]\tvalidation_0-logloss:0.68166\n",
      "[830]\tvalidation_0-logloss:0.20981\n",
      "[0]\tvalidation_0-logloss:0.68487\n",
      "[392]\tvalidation_0-logloss:0.32826\n",
      "[0]\tvalidation_0-logloss:0.68910\n",
      "[649]\tvalidation_0-logloss:0.19151\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.68459\n",
      "[391]\tvalidation_0-logloss:0.27588\n",
      "[0]\tvalidation_0-logloss:0.68306\n",
      "[469]\tvalidation_0-logloss:0.17721\n",
      "[0]\tvalidation_0-logloss:0.68207\n",
      "[1000]\tvalidation_0-logloss:0.07564\n",
      "[1201]\tvalidation_0-logloss:0.07412\n",
      "[0]\tvalidation_0-logloss:0.68235\n",
      "[369]\tvalidation_0-logloss:0.29779\n",
      "[0]\tvalidation_0-logloss:0.68499\n",
      "[616]\tvalidation_0-logloss:0.18968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:30:50,453] Trial 17 finished with value: 0.19398809258048424 and parameters: {'booster': 'gbtree', 'alpha': 0.03106931723138533, 'lambda': 1.8805299510504855e-05, 'subsample': 0.6185650458858846, 'colsample_bytree': 0.8278290389972701, 'learning_rate': 0.018595626965791767, 'max_depth': 6, 'min_child_weight': 2, 'gamma': 1.6129693080046337e-07, 'grow_policy': 'depthwise'}. Best is trial 14 with value: 0.19042787401206218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:1.36002\n",
      "[101]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:0.76786\n",
      "[120]\tvalidation_0-logloss:20.56262\n",
      "[0]\tvalidation_0-logloss:1.04871\n",
      "[109]\tvalidation_0-logloss:0.84322\n",
      "[0]\tvalidation_0-logloss:0.72684\n",
      "[250]\tvalidation_0-logloss:0.43913\n",
      "[0]\tvalidation_0-logloss:1.17248\n",
      "[104]\tvalidation_0-logloss:17.13552\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:1.15798\n",
      "[141]\tvalidation_0-logloss:17.58338\n",
      "[0]\tvalidation_0-logloss:2.85480\n",
      "[100]\tvalidation_0-logloss:21.41940\n",
      "[0]\tvalidation_0-logloss:2.16160\n",
      "[101]\tvalidation_0-logloss:19.70584\n",
      "[0]\tvalidation_0-logloss:0.77967\n",
      "[100]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:0.85593\n",
      "[101]\tvalidation_0-logloss:16.27874\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.91164\n",
      "[104]\tvalidation_0-logloss:17.99229\n",
      "[0]\tvalidation_0-logloss:0.63189\n",
      "[115]\tvalidation_0-logloss:20.56262\n",
      "[0]\tvalidation_0-logloss:0.90536\n",
      "[101]\tvalidation_0-logloss:15.42197\n",
      "[0]\tvalidation_0-logloss:1.02583\n",
      "[109]\tvalidation_0-logloss:17.99229\n",
      "[0]\tvalidation_0-logloss:0.81894\n",
      "[168]\tvalidation_0-logloss:0.24250\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.88436\n",
      "[121]\tvalidation_0-logloss:19.70584\n",
      "[0]\tvalidation_0-logloss:4.26895\n",
      "[100]\tvalidation_0-logloss:24.84650\n",
      "[0]\tvalidation_0-logloss:0.59066\n",
      "[150]\tvalidation_0-logloss:0.38111\n",
      "[0]\tvalidation_0-logloss:1.27051\n",
      "[127]\tvalidation_0-logloss:0.51162\n",
      "[0]\tvalidation_0-logloss:0.83058\n",
      "[107]\tvalidation_0-logloss:12.85164\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.67662\n",
      "[103]\tvalidation_0-logloss:18.84907\n",
      "[0]\tvalidation_0-logloss:0.84444\n",
      "[133]\tvalidation_0-logloss:0.51281\n",
      "[0]\tvalidation_0-logloss:2.42161\n",
      "[100]\tvalidation_0-logloss:17.13552\n",
      "[0]\tvalidation_0-logloss:1.36733\n",
      "[101]\tvalidation_0-logloss:19.70584\n",
      "[0]\tvalidation_0-logloss:4.53522\n",
      "[99]\tvalidation_0-logloss:18.42068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:30:51,862] Trial 18 finished with value: 13.230997508388972 and parameters: {'booster': 'gblinear', 'alpha': 0.0004917576090950916, 'lambda': 2.0604867195720236e-06, 'subsample': 0.47268447930073065, 'colsample_bytree': 0.7193344273533461}. Best is trial 14 with value: 0.19042787401206218.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "[0]\tvalidation_0-logloss:0.66288\n",
      "[1000]\tvalidation_0-logloss:0.21399\n",
      "[1054]\tvalidation_0-logloss:0.21448\n",
      "[0]\tvalidation_0-logloss:0.67667\n",
      "[1000]\tvalidation_0-logloss:0.21456\n",
      "[1524]\tvalidation_0-logloss:0.21092\n",
      "[0]\tvalidation_0-logloss:0.67068\n",
      "[429]\tvalidation_0-logloss:0.37235\n",
      "[0]\tvalidation_0-logloss:0.66989\n",
      "[404]\tvalidation_0-logloss:0.31835\n",
      "[0]\tvalidation_0-logloss:0.67279\n",
      "[263]\tvalidation_0-logloss:0.35235\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "[0]\tvalidation_0-logloss:0.66221\n",
      "[1000]\tvalidation_0-logloss:0.08273\n",
      "[1355]\tvalidation_0-logloss:0.08143\n",
      "[0]\tvalidation_0-logloss:0.68102\n",
      "[353]\tvalidation_0-logloss:0.16782\n",
      "[0]\tvalidation_0-logloss:0.68043\n",
      "[1000]\tvalidation_0-logloss:0.19972\n",
      "[1065]\tvalidation_0-logloss:0.19994\n",
      "[0]\tvalidation_0-logloss:0.67902\n",
      "[166]\tvalidation_0-logloss:0.40022\n",
      "[0]\tvalidation_0-logloss:0.68016\n",
      "[1000]\tvalidation_0-logloss:0.18707\n",
      "[1107]\tvalidation_0-logloss:0.18721\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "[0]\tvalidation_0-logloss:0.67903\n",
      "[942]\tvalidation_0-logloss:0.28831\n",
      "[0]\tvalidation_0-logloss:0.68143\n",
      "[1000]\tvalidation_0-logloss:0.16467\n",
      "[1622]\tvalidation_0-logloss:0.16286\n",
      "[0]\tvalidation_0-logloss:0.68166\n",
      "[1000]\tvalidation_0-logloss:0.12987\n",
      "[1028]\tvalidation_0-logloss:0.12964\n",
      "[0]\tvalidation_0-logloss:0.68116\n",
      "[1000]\tvalidation_0-logloss:0.22026\n",
      "[1851]\tvalidation_0-logloss:0.21685\n",
      "[0]\tvalidation_0-logloss:0.67872\n",
      "[753]\tvalidation_0-logloss:0.18988\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "[0]\tvalidation_0-logloss:0.67546\n",
      "[1000]\tvalidation_0-logloss:0.08080\n",
      "[1549]\tvalidation_0-logloss:0.07865\n",
      "[0]\tvalidation_0-logloss:0.68445\n",
      "[336]\tvalidation_0-logloss:0.33946\n",
      "[0]\tvalidation_0-logloss:0.67195\n",
      "[1000]\tvalidation_0-logloss:0.27944\n",
      "[1075]\tvalidation_0-logloss:0.27939\n",
      "[0]\tvalidation_0-logloss:0.67976\n",
      "[1000]\tvalidation_0-logloss:0.34276\n",
      "[1331]\tvalidation_0-logloss:0.33977\n",
      "[0]\tvalidation_0-logloss:0.66741\n",
      "[795]\tvalidation_0-logloss:0.19158\n",
      "Repeat \u001b[1m\u001b[34m#5\n",
      "[0]\tvalidation_0-logloss:0.67793\n",
      "[204]\tvalidation_0-logloss:0.32317\n",
      "[0]\tvalidation_0-logloss:0.66950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-06-15 15:31:00,963] Trial 19 failed with parameters: {'booster': 'gbtree', 'alpha': 0.9565953476127818, 'lambda': 0.00012312636091171112, 'subsample': 0.9312375839707614, 'colsample_bytree': 0.8585146363436257, 'learning_rate': 0.0429556507861634, 'max_depth': 4, 'min_child_weight': 6, 'gamma': 1.5425985432141796e-07, 'grow_policy': 'depthwise'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_5861/4120141353.py\", line 75, in objective\n",
      "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=1000)\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n",
      "[W 2023-06-15 15:31:00,992] Trial 19 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5861/4120141353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgb_optimize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of finished trials: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \"\"\"\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5861/4120141353.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m# Learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mval_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m             )\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, y = train_df[features], train_df.Class\n",
    "\n",
    "def objective(trial):\n",
    "    bll_list = list()\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": 3000, # trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        \"random_state\": 14062023,\n",
    "        \"early_stopping_rounds\": 100,\n",
    "        \"verbosity\": 0,\n",
    "        \"scale_pos_weight\": 4.71,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        # use exact for small dataset.\n",
    "        \"tree_method\": \"exact\",\n",
    "        # defines booster, gblinear for linear functions.\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\"]),# \"dart\"]), \n",
    "        # L1 regularization weight.\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        # L2 regularization weight.\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        # sampling ratio for training data.\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "        # sampling according to each tree.\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "    }\n",
    "\n",
    "    if params[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        params[\"learning_rate\"] = trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True) # alias eta\n",
    "        # maximum depth of the tree, signifies complexity of the tree.\n",
    "        params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "        # minimum child weight, larger the term more conservative the tree.\n",
    "        params[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "        # defines how selective algorithm is.\n",
    "        params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "    if params[\"booster\"] == \"dart\":\n",
    "        params[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        params[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        params[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        params[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "\n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under-sampling to balance classes\n",
    "        positive_count_train = train_df.Class.value_counts()[1]\n",
    "        sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                        1: positive_count_train}, \n",
    "                                     random_state=15062023+i, \n",
    "                                     replacement=True)\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # Learning\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=1000)\n",
    "            # Predict\n",
    "            val_preds = model.predict_proba(X_val)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "        \n",
    "        bll_list.append(balanced_log_loss(y_re, oof))    \n",
    "    \n",
    "    return np.mean(bll_list)\n",
    "\n",
    "if CFG.xgb_optimize:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials, )\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe()\n",
    "    df.sort_values('value').iloc[:, [1] + list(range(5, 14))]\n",
    "    df.to_csv(f'optuna_xgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load XGBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "param_list = glob.glob(\"optuna_xgb.csv\")\n",
    "models = list()\n",
    "best_xb_params = list()\n",
    "\n",
    "xb_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if xb_params.shape[0] == 0:\n",
    "        xb_params = tmp\n",
    "    else:\n",
    "        xb_params = pd.concat([cb_params, tmp])\n",
    "        \n",
    "xb_params = xb_params.sort_values('value').head(10)\n",
    "param_cols = [c for c in xb_params.columns if c.startswith('params_')]\n",
    "xb_params = xb_params[param_cols]\n",
    "\n",
    "for idx, row in xb_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['n_estimators'] = 3000\n",
    "    row_dict['random_state'] = 14062023\n",
    "    row_dict['early_stopping_rounds'] = 100\n",
    "    row_dict['verbosity'] = 0\n",
    "    row_dict['scale_pos_weight'] = 4.71\n",
    "    row_dict['objective'] = \"binary:logistic\"\n",
    "    row_dict['eval_metric'] = \"logloss\"\n",
    "    row_dict['tree_method'] = \"exact\"\n",
    "    row_dict['booster'] = \"gbtree\"\n",
    "\n",
    "    if row_dict[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        row_dict[\"learning_rate\"] = float(row_dict['learning_rate'])\n",
    "        row_dict[\"max_depth\"] = int(row_dict['max_depth'])\n",
    "        row_dict[\"min_child_weight\"] = float(row_dict['min_child_weight'])\n",
    "        row_dict[\"gamma\"] = float(row_dict['gamma'])\n",
    "    else:\n",
    "        row_dict[\"learning_rate\"] = None\n",
    "        row_dict[\"max_depth\"] = None\n",
    "        row_dict[\"min_child_weight\"] = None\n",
    "        row_dict[\"gamma\"] = None\n",
    "        row_dict[\"grow_policy\"] = None     \n",
    "\n",
    "    if row_dict[\"booster\"] == \"dart\":\n",
    "        row_dict[\"rate_drop\"] = float(row_dict['rate_drop'])\n",
    "        row_dict[\"skip_drop\"] = float(row_dict['skip_drop'])\n",
    "    else:\n",
    "        row_dict[\"sample_type\"] = None\n",
    "        row_dict[\"normalize_type\"] = None\n",
    "        row_dict[\"rate_drop\"] = None\n",
    "        row_dict[\"skip_drop\"] = None\n",
    "\n",
    "    best_xb_params.append(row_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with \u001b[1m\u001b[34m39\u001b[0m features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6449140908724ea7a3b36e8e21332163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.65601\n",
      "[500]\tvalidation_0-logloss:0.05221\n",
      "[531]\tvalidation_0-logloss:0.05197\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07028\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66491\n",
      "[500]\tvalidation_0-logloss:0.07772\n",
      "[735]\tvalidation_0-logloss:0.07377\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09962\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.64909\n",
      "[500]\tvalidation_0-logloss:0.08023\n",
      "[510]\tvalidation_0-logloss:0.08030\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10457\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66341\n",
      "[500]\tvalidation_0-logloss:0.07050\n",
      "[649]\tvalidation_0-logloss:0.07042\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09266\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65339\n",
      "[500]\tvalidation_0-logloss:0.07362\n",
      "[508]\tvalidation_0-logloss:0.07433\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08669\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65879\n",
      "[500]\tvalidation_0-logloss:0.06382\n",
      "[722]\tvalidation_0-logloss:0.06128\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08373\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66152\n",
      "[500]\tvalidation_0-logloss:0.07820\n",
      "[504]\tvalidation_0-logloss:0.07868\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10067\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66066\n",
      "[500]\tvalidation_0-logloss:0.06995\n",
      "[505]\tvalidation_0-logloss:0.07011\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09483\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66473\n",
      "[500]\tvalidation_0-logloss:0.08035\n",
      "[588]\tvalidation_0-logloss:0.08172\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11258\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66134\n",
      "[500]\tvalidation_0-logloss:0.06721\n",
      "[508]\tvalidation_0-logloss:0.06733\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08713\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66377\n",
      "[222]\tvalidation_0-logloss:0.19302\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14609\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.67375\n",
      "[414]\tvalidation_0-logloss:0.20125\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14613\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66211\n",
      "[245]\tvalidation_0-logloss:0.22848\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16838\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.67191\n",
      "[237]\tvalidation_0-logloss:0.21559\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16837\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66847\n",
      "[238]\tvalidation_0-logloss:0.21522\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16210\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66571\n",
      "[271]\tvalidation_0-logloss:0.20918\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14307\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.67144\n",
      "[273]\tvalidation_0-logloss:0.21901\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17052\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66993\n",
      "[500]\tvalidation_0-logloss:0.20193\n",
      "[554]\tvalidation_0-logloss:0.20356\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13999\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.67281\n",
      "[433]\tvalidation_0-logloss:0.19266\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13841\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.67040\n",
      "[398]\tvalidation_0-logloss:0.20643\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13885\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65488\n",
      "[500]\tvalidation_0-logloss:0.18080\n",
      "[754]\tvalidation_0-logloss:0.17511\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.30111\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66625\n",
      "[500]\tvalidation_0-logloss:0.15213\n",
      "[887]\tvalidation_0-logloss:0.13868\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24498\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65468\n",
      "[500]\tvalidation_0-logloss:0.16822\n",
      "[691]\tvalidation_0-logloss:0.16721\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27758\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66454\n",
      "[500]\tvalidation_0-logloss:0.15498\n",
      "[937]\tvalidation_0-logloss:0.14717\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24334\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65693\n",
      "[500]\tvalidation_0-logloss:0.19530\n",
      "[604]\tvalidation_0-logloss:0.19674\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.35571\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66059\n",
      "[500]\tvalidation_0-logloss:0.16277\n",
      "[937]\tvalidation_0-logloss:0.15502\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23725\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66304\n",
      "[500]\tvalidation_0-logloss:0.16453\n",
      "[869]\tvalidation_0-logloss:0.15242\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26687\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66235\n",
      "[500]\tvalidation_0-logloss:0.14023\n",
      "[693]\tvalidation_0-logloss:0.13567\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22640\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66620\n",
      "[500]\tvalidation_0-logloss:0.15384\n",
      "[1000]\tvalidation_0-logloss:0.14345\n",
      "[1500]\tvalidation_0-logloss:0.13529\n",
      "[1509]\tvalidation_0-logloss:0.13468\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21820\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66300\n",
      "[500]\tvalidation_0-logloss:0.15222\n",
      "[693]\tvalidation_0-logloss:0.15093\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25341\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65539\n",
      "[193]\tvalidation_0-logloss:0.14423\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.30795\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66686\n",
      "[289]\tvalidation_0-logloss:0.17196\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42676\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65414\n",
      "[240]\tvalidation_0-logloss:0.13941\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34335\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66507\n",
      "[263]\tvalidation_0-logloss:0.15721\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.37550\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65819\n",
      "[222]\tvalidation_0-logloss:0.16125\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38262\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66175\n",
      "[212]\tvalidation_0-logloss:0.16690\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.35704\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66370\n",
      "[212]\tvalidation_0-logloss:0.17903\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.36876\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66270\n",
      "[378]\tvalidation_0-logloss:0.15443\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42885\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66651\n",
      "[492]\tvalidation_0-logloss:0.15273\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.41592\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66333\n",
      "[292]\tvalidation_0-logloss:0.16263\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.41260\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65685\n",
      "[347]\tvalidation_0-logloss:0.10779\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11936\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66859\n",
      "[500]\tvalidation_0-logloss:0.09285\n",
      "[720]\tvalidation_0-logloss:0.09215\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09976\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65866\n",
      "[500]\tvalidation_0-logloss:0.07715\n",
      "[640]\tvalidation_0-logloss:0.07780\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08773\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66703\n",
      "[500]\tvalidation_0-logloss:0.09059\n",
      "[935]\tvalidation_0-logloss:0.08708\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08563\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66220\n",
      "[346]\tvalidation_0-logloss:0.10147\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10511\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66239\n",
      "[500]\tvalidation_0-logloss:0.08514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[646]\tvalidation_0-logloss:0.08729\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10013\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66566\n",
      "[500]\tvalidation_0-logloss:0.10372\n",
      "[720]\tvalidation_0-logloss:0.10107\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10159\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66404\n",
      "[500]\tvalidation_0-logloss:0.08916\n",
      "[656]\tvalidation_0-logloss:0.08924\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09322\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66765\n",
      "[500]\tvalidation_0-logloss:0.08458\n",
      "[655]\tvalidation_0-logloss:0.08460\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09224\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66462\n",
      "[500]\tvalidation_0-logloss:0.09470\n",
      "[937]\tvalidation_0-logloss:0.08926\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10344\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65429\n",
      "[385]\tvalidation_0-logloss:0.13522\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23408\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66592\n",
      "[340]\tvalidation_0-logloss:0.13182\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20671\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65871\n",
      "[268]\tvalidation_0-logloss:0.14323\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17903\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66458\n",
      "[340]\tvalidation_0-logloss:0.14607\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22882\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66595\n",
      "[361]\tvalidation_0-logloss:0.15996\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27317\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66016\n",
      "[340]\tvalidation_0-logloss:0.14592\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21297\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66265\n",
      "[340]\tvalidation_0-logloss:0.13700\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21929\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66196\n",
      "[352]\tvalidation_0-logloss:0.12768\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19931\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66588\n",
      "[340]\tvalidation_0-logloss:0.13239\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19752\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66262\n",
      "[336]\tvalidation_0-logloss:0.13592\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19928\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66607\n",
      "[283]\tvalidation_0-logloss:0.29332\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.32289\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.67359\n",
      "[499]\tvalidation_0-logloss:0.28427\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.31791\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66574\n",
      "[347]\tvalidation_0-logloss:0.30405\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.35860\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.67052\n",
      "[424]\tvalidation_0-logloss:0.28130\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33655\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66829\n",
      "[309]\tvalidation_0-logloss:0.30288\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.35032\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66851\n",
      "[393]\tvalidation_0-logloss:0.29834\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34328\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.67126\n",
      "[470]\tvalidation_0-logloss:0.29530\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33863\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66820\n",
      "[316]\tvalidation_0-logloss:0.28495\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.31845\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.67127\n",
      "[424]\tvalidation_0-logloss:0.27501\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.30494\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66868\n",
      "[500]\tvalidation_0-logloss:0.28738\n",
      "[527]\tvalidation_0-logloss:0.28346\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.32674\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65721\n",
      "[312]\tvalidation_0-logloss:0.10231\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13431\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66798\n",
      "[500]\tvalidation_0-logloss:0.10143\n",
      "[560]\tvalidation_0-logloss:0.10618\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13932\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65436\n",
      "[500]\tvalidation_0-logloss:0.10411\n",
      "[511]\tvalidation_0-logloss:0.10423\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14463\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66631\n",
      "[500]\tvalidation_0-logloss:0.11956\n",
      "[560]\tvalidation_0-logloss:0.12121\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15780\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66016\n",
      "[500]\tvalidation_0-logloss:0.09141\n",
      "[511]\tvalidation_0-logloss:0.09106\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12729\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66257\n",
      "[357]\tvalidation_0-logloss:0.10938\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12674\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66496\n",
      "[303]\tvalidation_0-logloss:0.12504\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15479\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66423\n",
      "[460]\tvalidation_0-logloss:0.09880\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12638\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66786\n",
      "[500]\tvalidation_0-logloss:0.09267\n",
      "[510]\tvalidation_0-logloss:0.09300\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12304\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66484\n",
      "[310]\tvalidation_0-logloss:0.10651\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14350\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65589\n",
      "[361]\tvalidation_0-logloss:0.15065\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22246\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66836\n",
      "[362]\tvalidation_0-logloss:0.14717\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21934\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65407\n",
      "[365]\tvalidation_0-logloss:0.13954\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22272\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66673\n",
      "[422]\tvalidation_0-logloss:0.14547\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22186\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65887\n",
      "[420]\tvalidation_0-logloss:0.13963\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21290\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66302\n",
      "[438]\tvalidation_0-logloss:0.14774\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22275\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66540\n",
      "[500]\tvalidation_0-logloss:0.14711\n",
      "[630]\tvalidation_0-logloss:0.14493\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23077\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66465\n",
      "[432]\tvalidation_0-logloss:0.14667\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21153\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66821\n",
      "[437]\tvalidation_0-logloss:0.14564\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21726\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66524\n",
      "[376]\tvalidation_0-logloss:0.15033\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22369\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.64777\n",
      "[209]\tvalidation_0-logloss:0.19961\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.58006\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66459\n",
      "[361]\tvalidation_0-logloss:0.17732\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.58397\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.64734\n",
      "[260]\tvalidation_0-logloss:0.19951\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.66574\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66276\n",
      "[357]\tvalidation_0-logloss:0.19437\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.65484\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232]\tvalidation_0-logloss:0.19921\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.57993\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.65842\n",
      "[262]\tvalidation_0-logloss:0.18848\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.59030\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66117\n",
      "[368]\tvalidation_0-logloss:0.17645\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.58525\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66031\n",
      "[261]\tvalidation_0-logloss:0.19464\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.61616\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66443\n",
      "[375]\tvalidation_0-logloss:0.20335\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.67076\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "[0]\tvalidation_0-logloss:0.66100\n",
      "[260]\tvalidation_0-logloss:0.19775\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.61978\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def xgboost_training():\n",
    "    models_ = list()\n",
    "    bll_list = list()\n",
    "    weights_ = list()\n",
    "    \n",
    "    X, y = train_df[features], train_df.Class\n",
    "#     X, y = generated_features_train, train_df.Class\n",
    "     \n",
    "    kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=8062023+20)\n",
    "    metric = balanced_log_loss\n",
    "    eval_results_ = {}     # used to store evaluation results for each fold\n",
    "\n",
    "    oof_level2 = np.zeros([y.shape[0], len(best_xb_params) + 1])\n",
    "    oof_level2[:, len(best_xb_params)] = y\n",
    "\n",
    "    print(f\"Training with {blu}{X.shape[1]}{res} features\")\n",
    "\n",
    "    for fold, (fit_idx, val_idx) in tqdm(enumerate(kf.split(X=train_df, y=greeks.iloc[:,1:3]), start = 1),\n",
    "                                         total=CFG.n_stacking_folds):\n",
    "        \n",
    "        # Split the dataset according to the fold indexes.\n",
    "        X_train = X.iloc[fit_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_train = y.iloc[fit_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        for i, params in enumerate(best_xb_params):\n",
    "            \n",
    "            clf = xgb.XGBClassifier(**params)\n",
    "            \n",
    "            clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=500)\n",
    "            models_.append(clf)\n",
    "\n",
    "            val_preds = clf.predict_proba(X_val)[:,1]\n",
    "            oof_level2[val_idx, i] = val_preds\n",
    "\n",
    "            val_score = balanced_log_loss(y_val, val_preds)\n",
    "            best_iter = 0\n",
    "\n",
    "#             print(clf.best_iteration_)\n",
    "            \n",
    "            print(f'Fold: {blu}{fold:>3}{res}| bll_metric: {blu}{val_score:.5f}{res}'\n",
    "                  f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "        \n",
    "    return oof_level2, models_\n",
    "\n",
    "if CFG.stacking:\n",
    "    oof_level2_xgb, models_xgb = xgboost_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:47:25,150] A new study created in memory with name: no-name-f3c5fd83-32bb-46e0-92c1-970d9dcf1e13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n",
      "Repeat \u001b[1m\u001b[34m#4\n",
      "Repeat \u001b[1m\u001b[34m#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-15 15:48:08,476] Trial 0 finished with value: 0.17049209249813652 and parameters: {'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'learning_rate': 0.006043094362183259, 'l2_leaf_reg': 5.2665170889586595e-08, 'depth': 4, 'subsample': 0.4264901925342959, 'colsample_bylevel': 0.759570287866387, 'max_leaves': 87, 'random_strength': 34.15720934838517, 'bagging_temperature': 66.23907022233848, 'min_data_in_leaf': 34}. Best is trial 0 with value: 0.17049209249813652.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n",
      "Repeat \u001b[1m\u001b[34m#2\n",
      "Repeat \u001b[1m\u001b[34m#3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-06-15 15:48:26,409] Trial 1 failed with parameters: {'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'learning_rate': 0.008459153699234497, 'l2_leaf_reg': 3.275667642123539e-05, 'depth': 6, 'subsample': 0.8027356041258045, 'colsample_bylevel': 0.4943883271450967, 'max_leaves': 97, 'random_strength': 84.78125060785999, 'bagging_temperature': 13.006780327558431, 'min_data_in_leaf': 46} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_5861/708397832.py\", line 104, in objective\n",
      "    model.fit(train_pool, eval_set=val_pool, verbose=0)#, callbacks=[pruning_callback])\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/catboost/core.py\", line 5131, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/catboost/core.py\", line 2357, in _fit\n",
      "    self._train(\n",
      "  File \"/home/alex/.local/lib/python3.10/site-packages/catboost/core.py\", line 1761, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4624, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4673, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2023-06-15 15:48:26,412] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5861/708397832.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of finished trials: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \"\"\"\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5861/708397832.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# Add a callback for pruning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#             pruning_callback = optuna.integration.CatBoostPruningCallback(trial, \"Logloss\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, callbacks=[pruning_callback])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;31m# Evoke pruning manually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m#                 pruning_callback.check_pruned()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5129\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5131\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   5132\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5133\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_cout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_cerr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m             \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2357\u001b[0;31m             self._train(\n\u001b[0m\u001b[1;32m   2358\u001b[0m                 \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from optuna.integration import CatBoostPruningCallback\n",
    "\n",
    "X, y = train_df[features], train_df.Class\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    bll_list = list()\n",
    "\n",
    "    # Parameters\n",
    "    params = {\n",
    "        'task_type': 'CPU', # GPU\n",
    "        'auto_class_weights': 'Balanced',\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['Ordered', 'Plain']),\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
    "        'eval_metric': 'Logloss',\n",
    "        'loss_function': 'Logloss', \n",
    "        'random_seed': 10062023,\n",
    "        'od_type': 'Iter', # Type of overfitting detector - stop after k iteraions\n",
    "        'od_wait': 100, # Overfitting detector - stop training after k iterations without metric improvement\n",
    "#             'metric_period': 100, # Show metric each k iterations\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "         # Hyperparamters (in order of importance decreasing)\n",
    "        'iterations' : 5000, # trial.suggest_int('iterations', 300, 1200),        \n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-3, 3e-1),    \n",
    "        'l2_leaf_reg': trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
    "        'depth' : trial.suggest_int('depth', 4, 10),  # Max tree depth         \n",
    "         # decrease to deal with overfit\n",
    "        'subsample': trial.suggest_float('subsample', 0.3, 1), # randomly select part of data without return\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.3, 1), # the percentage of features to use at each \n",
    "                                                                               # split selection\n",
    "                                                                               # alias: rsm\n",
    "                                                                               # not supported in GPU mode\n",
    "         # decrease to deal with overfit\n",
    "         'max_leaves': trial.suggest_int('max_leaves', 4, 128), # Max number of leaves in one tree                                                 \n",
    "         # increase to deal with overfit\n",
    "        'random_strength': trial.suggest_float('random_strength', 0, 100), # The amount of randomness to use \n",
    "                                                                           # for scoring splits when the tree structure\n",
    "                                                                           # is selected. Helps to avoid overfitting\n",
    "        'bagging_temperature' : trial.suggest_float('bagging_temperature', 0, 100),     # Assigns random \n",
    "                                                                                        # weights to objects\n",
    "                                                                                        # works only with Bayesian bootstrap\n",
    "        # this feature value can be increased to 1024 for important features:\n",
    "        # per_float_feature_quantization='0:border_count=1024'\n",
    "        'border_count': 254, # trial.suggest_categorical('border_count', [128, 254]), # The number of splits for numerical features\n",
    "                                                                                      # bigger is better but slowly\n",
    "                                                                                      # alias: max_bin\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                           # aliases: min_child_samples, \n",
    "\n",
    "    }\n",
    "\n",
    "    if params['grow_policy'] != 'SymmetricTree': \n",
    "        params['boosting_type'] = 'Plain'\n",
    "\n",
    "    if params['grow_policy'] != 'Lossguide': \n",
    "        params['max_leaves'] = None\n",
    "        \n",
    "    if params['bootstrap_type'] != 'Bayesian':\n",
    "        params['bagging_temperature'] = None\n",
    "    else:\n",
    "        params['subsample'] = None\n",
    "\n",
    "#         if params['bootstrap_type'] == 'Bayesian':\n",
    "#             params['subsample'] = None\n",
    "#         else:\n",
    "#             params['subsample'] = trial.suggest_float('subsample', 0.3, 1)\n",
    "\n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under-sampling to balance classes\n",
    "        positive_count_train = train_df.Class.value_counts()[1]\n",
    "        sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                        1: positive_count_train}, \n",
    "                                     random_state=15062023+i, \n",
    "                                     replacement=True)\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "            val_pool = Pool(X_val, y_val, cat_features=['EJ'])\n",
    "\n",
    "            # Learning\n",
    "            model = cat.CatBoostClassifier(**params)     \n",
    "            # Add a callback for pruning\n",
    "#             pruning_callback = optuna.integration.CatBoostPruningCallback(trial, \"Logloss\")\n",
    "            model.fit(train_pool, eval_set=val_pool, verbose=0)#, callbacks=[pruning_callback])\n",
    "            # Evoke pruning manually\n",
    "#                 pruning_callback.check_pruned()\n",
    "            # Predict\n",
    "            val_preds = model.predict_proba(val_pool)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "        \n",
    "        bll_list.append(balanced_log_loss(y_re, oof))    \n",
    "    \n",
    "    return np.mean(bll_list)\n",
    "\n",
    "if CFG.cb_optimize:\n",
    "#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe()\n",
    "    df.sort_values('value').iloc[:, [1] + list(range(5, 14))]\n",
    "    df.to_csv(f'optuna_catboost_fold_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CatBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "param_list = glob.glob(\"optuna_catboost*.csv\")\n",
    "models = list()\n",
    "best_cb_params = list()\n",
    "\n",
    "cb_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if cb_params.shape[0] == 0:\n",
    "        cb_params = tmp\n",
    "    else:\n",
    "        cb_params = pd.concat([cb_params, tmp])\n",
    "        \n",
    "cb_params = cb_params.sort_values('value').head(10)\n",
    "param_cols = [c for c in cb_params.columns if c.startswith('params_')]\n",
    "cb_params = cb_params[param_cols]\n",
    "\n",
    "\n",
    "for idx, row in cb_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['task_type'] = 'CPU'\n",
    "    row_dict['auto_class_weights'] = 'Balanced'\n",
    "    row_dict['eval_metric'] = 'Logloss'\n",
    "    row_dict['loss_function'] = 'Logloss'\n",
    "    row_dict['random_seed'] = 13062023\n",
    "    row_dict['verbose'] = 0\n",
    "    row_dict['od_type'] = 'Iter'\n",
    "    row_dict['od_wait'] = 100\n",
    "    row_dict['border_count'] = 254\n",
    "    row_dict['iterations'] = 10000\n",
    "    row_dict['bagging_temperature'] = float(row_dict['bagging_temperature'])\n",
    "    row_dict['subsample'] = 0.7 # float(row_dict['subsample'])\n",
    "    row_dict['learning_rate'] = float(row_dict['learning_rate'])\n",
    "    row_dict['l2_leaf_reg'] = float(row_dict['l2_leaf_reg'])\n",
    "    row_dict['depth'] = int(row_dict['depth'])\n",
    "    row_dict['random_strength'] = float(row_dict['random_strength'])\n",
    "    row_dict['min_data_in_leaf'] = int(row_dict['min_data_in_leaf'])\n",
    "    \n",
    "    if row_dict['grow_policy'] == 'Lossguide':\n",
    "        row_dict['max_leaves'] = int(row_dict['max_leaves'])\n",
    "    else:\n",
    "        del row_dict['max_leaves']\n",
    "    \n",
    "    if row_dict['grow_policy'] == 'SymmetricTree':\n",
    "        row_dict['boosting_type'] = 'Plain'\n",
    "    else:\n",
    "        del row_dict['boosting_type']\n",
    "        \n",
    "    if row_dict['task_type'] == 'CPU':\n",
    "        row_dict['colsample_bylevel'] = 0.6 # float(row_dict['colsample_bylevel'])\n",
    "    else:\n",
    "        del row_dict['colsample_bylevel']\n",
    "    \n",
    "    best_cb_params.append(row_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with \u001b[1m\u001b[34m39\u001b[0m features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a288e72c9b9421f9c573564a5d85e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6551\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07625\u001b[0m | Best iteration: \u001b[1m\u001b[34m6551\u001b[0m\n",
      "9992\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07660\u001b[0m | Best iteration: \u001b[1m\u001b[34m9992\u001b[0m\n",
      "6238\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10452\u001b[0m | Best iteration: \u001b[1m\u001b[34m6238\u001b[0m\n",
      "3594\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09652\u001b[0m | Best iteration: \u001b[1m\u001b[34m3594\u001b[0m\n",
      "9994\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07382\u001b[0m | Best iteration: \u001b[1m\u001b[34m9994\u001b[0m\n",
      "6527\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09270\u001b[0m | Best iteration: \u001b[1m\u001b[34m6527\u001b[0m\n",
      "2277\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09004\u001b[0m | Best iteration: \u001b[1m\u001b[34m2277\u001b[0m\n",
      "1763\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09397\u001b[0m | Best iteration: \u001b[1m\u001b[34m1763\u001b[0m\n",
      "5158\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09341\u001b[0m | Best iteration: \u001b[1m\u001b[34m5158\u001b[0m\n",
      "5944\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08718\u001b[0m | Best iteration: \u001b[1m\u001b[34m5944\u001b[0m\n",
      "4727\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11037\u001b[0m | Best iteration: \u001b[1m\u001b[34m4727\u001b[0m\n",
      "5778\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11029\u001b[0m | Best iteration: \u001b[1m\u001b[34m5778\u001b[0m\n",
      "3875\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11027\u001b[0m | Best iteration: \u001b[1m\u001b[34m3875\u001b[0m\n",
      "4904\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10905\u001b[0m | Best iteration: \u001b[1m\u001b[34m4904\u001b[0m\n",
      "3991\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11408\u001b[0m | Best iteration: \u001b[1m\u001b[34m3991\u001b[0m\n",
      "5763\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10738\u001b[0m | Best iteration: \u001b[1m\u001b[34m5763\u001b[0m\n",
      "3194\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08938\u001b[0m | Best iteration: \u001b[1m\u001b[34m3194\u001b[0m\n",
      "2816\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10411\u001b[0m | Best iteration: \u001b[1m\u001b[34m2816\u001b[0m\n",
      "6720\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10055\u001b[0m | Best iteration: \u001b[1m\u001b[34m6720\u001b[0m\n",
      "2880\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10582\u001b[0m | Best iteration: \u001b[1m\u001b[34m2880\u001b[0m\n",
      "999\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27128\u001b[0m | Best iteration: \u001b[1m\u001b[34m 999\u001b[0m\n",
      "1178\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26114\u001b[0m | Best iteration: \u001b[1m\u001b[34m1178\u001b[0m\n",
      "1237\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26344\u001b[0m | Best iteration: \u001b[1m\u001b[34m1237\u001b[0m\n",
      "1242\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25135\u001b[0m | Best iteration: \u001b[1m\u001b[34m1242\u001b[0m\n",
      "1305\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26582\u001b[0m | Best iteration: \u001b[1m\u001b[34m1305\u001b[0m\n",
      "1646\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26048\u001b[0m | Best iteration: \u001b[1m\u001b[34m1646\u001b[0m\n",
      "903\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26794\u001b[0m | Best iteration: \u001b[1m\u001b[34m 903\u001b[0m\n",
      "883\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26298\u001b[0m | Best iteration: \u001b[1m\u001b[34m 883\u001b[0m\n",
      "1327\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27621\u001b[0m | Best iteration: \u001b[1m\u001b[34m1327\u001b[0m\n",
      "796\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24775\u001b[0m | Best iteration: \u001b[1m\u001b[34m 796\u001b[0m\n",
      "941\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25046\u001b[0m | Best iteration: \u001b[1m\u001b[34m 941\u001b[0m\n",
      "1004\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25568\u001b[0m | Best iteration: \u001b[1m\u001b[34m1004\u001b[0m\n",
      "1019\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25284\u001b[0m | Best iteration: \u001b[1m\u001b[34m1019\u001b[0m\n",
      "912\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25439\u001b[0m | Best iteration: \u001b[1m\u001b[34m 912\u001b[0m\n",
      "996\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25769\u001b[0m | Best iteration: \u001b[1m\u001b[34m 996\u001b[0m\n",
      "1422\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24158\u001b[0m | Best iteration: \u001b[1m\u001b[34m1422\u001b[0m\n",
      "605\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25266\u001b[0m | Best iteration: \u001b[1m\u001b[34m 605\u001b[0m\n",
      "664\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25393\u001b[0m | Best iteration: \u001b[1m\u001b[34m 664\u001b[0m\n",
      "1169\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25482\u001b[0m | Best iteration: \u001b[1m\u001b[34m1169\u001b[0m\n",
      "625\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25543\u001b[0m | Best iteration: \u001b[1m\u001b[34m 625\u001b[0m\n",
      "6310\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09852\u001b[0m | Best iteration: \u001b[1m\u001b[34m6310\u001b[0m\n",
      "7078\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09909\u001b[0m | Best iteration: \u001b[1m\u001b[34m7078\u001b[0m\n",
      "6535\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11737\u001b[0m | Best iteration: \u001b[1m\u001b[34m6535\u001b[0m\n",
      "4019\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11584\u001b[0m | Best iteration: \u001b[1m\u001b[34m4019\u001b[0m\n",
      "9999\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09479\u001b[0m | Best iteration: \u001b[1m\u001b[34m9999\u001b[0m\n",
      "3982\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12866\u001b[0m | Best iteration: \u001b[1m\u001b[34m3982\u001b[0m\n",
      "1353\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12135\u001b[0m | Best iteration: \u001b[1m\u001b[34m1353\u001b[0m\n",
      "1004\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13463\u001b[0m | Best iteration: \u001b[1m\u001b[34m1004\u001b[0m\n",
      "3284\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12824\u001b[0m | Best iteration: \u001b[1m\u001b[34m3284\u001b[0m\n",
      "2479\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12714\u001b[0m | Best iteration: \u001b[1m\u001b[34m2479\u001b[0m\n",
      "1079\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23484\u001b[0m | Best iteration: \u001b[1m\u001b[34m1079\u001b[0m\n",
      "1045\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22992\u001b[0m | Best iteration: \u001b[1m\u001b[34m1045\u001b[0m\n",
      "1066\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23287\u001b[0m | Best iteration: \u001b[1m\u001b[34m1066\u001b[0m\n",
      "915\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22616\u001b[0m | Best iteration: \u001b[1m\u001b[34m 915\u001b[0m\n",
      "1148\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22929\u001b[0m | Best iteration: \u001b[1m\u001b[34m1148\u001b[0m\n",
      "1475\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22601\u001b[0m | Best iteration: \u001b[1m\u001b[34m1475\u001b[0m\n",
      "598\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20278\u001b[0m | Best iteration: \u001b[1m\u001b[34m 598\u001b[0m\n",
      "646\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21217\u001b[0m | Best iteration: \u001b[1m\u001b[34m 646\u001b[0m\n",
      "1317\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22117\u001b[0m | Best iteration: \u001b[1m\u001b[34m1317\u001b[0m\n",
      "697\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22266\u001b[0m | Best iteration: \u001b[1m\u001b[34m 697\u001b[0m\n",
      "841\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34658\u001b[0m | Best iteration: \u001b[1m\u001b[34m 841\u001b[0m\n",
      "868\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34900\u001b[0m | Best iteration: \u001b[1m\u001b[34m 868\u001b[0m\n",
      "925\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34221\u001b[0m | Best iteration: \u001b[1m\u001b[34m 925\u001b[0m\n",
      "807\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33641\u001b[0m | Best iteration: \u001b[1m\u001b[34m 807\u001b[0m\n",
      "852\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34990\u001b[0m | Best iteration: \u001b[1m\u001b[34m 852\u001b[0m\n",
      "1491\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33646\u001b[0m | Best iteration: \u001b[1m\u001b[34m1491\u001b[0m\n",
      "590\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34291\u001b[0m | Best iteration: \u001b[1m\u001b[34m 590\u001b[0m\n",
      "703\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33137\u001b[0m | Best iteration: \u001b[1m\u001b[34m 703\u001b[0m\n",
      "1106\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33156\u001b[0m | Best iteration: \u001b[1m\u001b[34m1106\u001b[0m\n",
      "635\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.32839\u001b[0m | Best iteration: \u001b[1m\u001b[34m 635\u001b[0m\n",
      "9993\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07117\u001b[0m | Best iteration: \u001b[1m\u001b[34m9993\u001b[0m\n",
      "9999\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08431\u001b[0m | Best iteration: \u001b[1m\u001b[34m9999\u001b[0m\n",
      "6475\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10060\u001b[0m | Best iteration: \u001b[1m\u001b[34m6475\u001b[0m\n",
      "9992\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07016\u001b[0m | Best iteration: \u001b[1m\u001b[34m9992\u001b[0m\n",
      "9996\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08050\u001b[0m | Best iteration: \u001b[1m\u001b[34m9996\u001b[0m\n",
      "9997\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08569\u001b[0m | Best iteration: \u001b[1m\u001b[34m9997\u001b[0m\n",
      "9984\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08245\u001b[0m | Best iteration: \u001b[1m\u001b[34m9984\u001b[0m\n",
      "9997\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06508\u001b[0m | Best iteration: \u001b[1m\u001b[34m9997\u001b[0m\n",
      "9999\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07997\u001b[0m | Best iteration: \u001b[1m\u001b[34m9999\u001b[0m\n",
      "9999\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07569\u001b[0m | Best iteration: \u001b[1m\u001b[34m9999\u001b[0m\n",
      "1019\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24486\u001b[0m | Best iteration: \u001b[1m\u001b[34m1019\u001b[0m\n",
      "1253\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23680\u001b[0m | Best iteration: \u001b[1m\u001b[34m1253\u001b[0m\n",
      "1272\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23377\u001b[0m | Best iteration: \u001b[1m\u001b[34m1272\u001b[0m\n",
      "1135\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23459\u001b[0m | Best iteration: \u001b[1m\u001b[34m1135\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23804\u001b[0m | Best iteration: \u001b[1m\u001b[34m1151\u001b[0m\n",
      "1645\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24161\u001b[0m | Best iteration: \u001b[1m\u001b[34m1645\u001b[0m\n",
      "787\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22050\u001b[0m | Best iteration: \u001b[1m\u001b[34m 787\u001b[0m\n",
      "827\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19958\u001b[0m | Best iteration: \u001b[1m\u001b[34m 827\u001b[0m\n",
      "1544\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23594\u001b[0m | Best iteration: \u001b[1m\u001b[34m1544\u001b[0m\n",
      "745\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23193\u001b[0m | Best iteration: \u001b[1m\u001b[34m 745\u001b[0m\n",
      "762\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.47249\u001b[0m | Best iteration: \u001b[1m\u001b[34m 762\u001b[0m\n",
      "905\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.45249\u001b[0m | Best iteration: \u001b[1m\u001b[34m 905\u001b[0m\n",
      "919\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.46607\u001b[0m | Best iteration: \u001b[1m\u001b[34m 919\u001b[0m\n",
      "782\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.45930\u001b[0m | Best iteration: \u001b[1m\u001b[34m 782\u001b[0m\n",
      "870\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.45960\u001b[0m | Best iteration: \u001b[1m\u001b[34m 870\u001b[0m\n",
      "1338\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.44404\u001b[0m | Best iteration: \u001b[1m\u001b[34m1338\u001b[0m\n",
      "545\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.46076\u001b[0m | Best iteration: \u001b[1m\u001b[34m 545\u001b[0m\n",
      "576\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.45785\u001b[0m | Best iteration: \u001b[1m\u001b[34m 576\u001b[0m\n",
      "1120\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.45559\u001b[0m | Best iteration: \u001b[1m\u001b[34m1120\u001b[0m\n",
      "578\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.46277\u001b[0m | Best iteration: \u001b[1m\u001b[34m 578\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def cb_training():\n",
    "    models_ = list()\n",
    "    bll_list = list()\n",
    "    weights_ = list()\n",
    "    \n",
    "    X, y = train_df[features], train_df.Class\n",
    "#     X, y = generated_features_train, train_df.Class\n",
    "     \n",
    "    kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=8062023+20)\n",
    "    metric = balanced_log_loss\n",
    "    eval_results_ = {}     # used to store evaluation results for each fold\n",
    "\n",
    "    oof_level2 = np.zeros([y.shape[0], len(best_cb_params) + 1])\n",
    "    oof_level2[:, len(best_cb_params)] = y\n",
    "\n",
    "    print(f\"Training with {blu}{X.shape[1]}{res} features\")\n",
    "\n",
    "    for fold, (fit_idx, val_idx) in tqdm(enumerate(kf.split(X=train_df, y=greeks.iloc[:,1:3]), start = 1),\n",
    "                                         total=CFG.n_stacking_folds):\n",
    "        \n",
    "        # Split the dataset according to the fold indexes.\n",
    "        X_train = X.iloc[fit_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_train = y.iloc[fit_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "        val_pool = Pool(X_val, y_val, cat_features=['EJ'])\n",
    "        \n",
    "        for i, params in enumerate(best_cb_params):\n",
    "            \n",
    "            model = cat.CatBoostClassifier(**params)\n",
    "            model.fit(train_pool, eval_set=val_pool, verbose=0)\n",
    "            models_.append(model)\n",
    "\n",
    "            val_preds = model.predict_proba(val_pool)[:,1]\n",
    "            oof_level2[val_idx, i] = val_preds\n",
    "\n",
    "            val_score = balanced_log_loss(y_val, val_preds)\n",
    "            best_iter = model.best_iteration_\n",
    "\n",
    "            print(model.best_iteration_)\n",
    "            \n",
    "            print(f'Fold: {blu}{fold:>3}{res}| bll_metric: {blu}{val_score:.5f}{res}'\n",
    "                  f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "        \n",
    "    return oof_level2, models_\n",
    "\n",
    "if CFG.stacking:\n",
    "    oof_level2_cb, models_cb = cb_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18570262853231068\n",
      "0.15867122888336638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "oof_level2 = np.concatenate([oof_level2_lgbm[:,:-1] , oof_level2_cb[:,:-1], oof_level2_xgb[:,:-1]], axis=1)\n",
    "X = oof_level2\n",
    "y = oof_level2_lgbm[:,-1]\n",
    "\n",
    "# mean bll\n",
    "print(balanced_log_loss(y, np.mean(X, axis=1)))\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "lr.fit(X, y)\n",
    "\n",
    "pred = lr.predict_proba(X)[:,1]\n",
    "\n",
    "# lr bll\n",
    "print(balanced_log_loss(y, pred))\n",
    "\n",
    "weights = lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.16616213477809366\n",
    "# 0.162813150781854"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-08T15:32:38.350522Z",
     "iopub.status.idle": "2023-06-08T15:32:38.351460Z",
     "shell.execute_reply": "2023-06-08T15:32:38.351239Z",
     "shell.execute_reply.started": "2023-06-08T15:32:38.351217Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Model Evaluation\n",
    "# metric_score_folds = pd.DataFrame.from_dict(all_eval_results_)\n",
    "# fit_logloss = []\n",
    "# val_logloss = []\n",
    "\n",
    "# for seed in CFG.seeds:\n",
    "#     for fold in range(1,CFG.n_folds+1):\n",
    "#         fit_logloss.append(metric_score_folds[seed][fold]['training']['balanced_log_loss'])\n",
    "#         val_logloss.append(metric_score_folds[seed][fold]['valid_1']['balanced_log_loss'])\n",
    "\n",
    "# fig, axes = plt.subplots(math.ceil(CFG.n_folds*len(CFG.seeds)/CFG.n_folds), CFG.n_folds, figsize=(20, 20), dpi=150)\n",
    "# ax = axes.flatten()\n",
    "# for i, (f, v, m) in enumerate(zip(fit_logloss, val_logloss, models_), start = 1): \n",
    "#     sns.lineplot(f, color='#B90000', ax=ax[i-1], label='fit')\n",
    "#     sns.lineplot(v, color='#048BA8', ax=ax[i-1], label='val')\n",
    "#     ax[i-1].legend()\n",
    "#     ax[i-1].spines['top'].set_visible(False);\n",
    "#     ax[i-1].spines['right'].set_visible(False)\n",
    "#     ax[i-1].set_title(f'Seed {CFG.seeds[(i-1)//CFG.n_folds]} Fold {CFG.n_folds if i%CFG.n_folds==0 else i%CFG.n_folds}', fontdict={'fontweight': 'bold'})\n",
    "\n",
    "#     color =  ['#048BA8', palette[-3]]\n",
    "#     best_iter = m.best_iteration_\n",
    "#     span_range = [[0, best_iter], [best_iter + 10, best_iter + CFG.num_boost_round]]\n",
    "\n",
    "#     for idx, sub_title in enumerate([f'Best\\nIteration: {best_iter}', f'Early\\n Stopping: 2000']):\n",
    "#         ax[i-1].annotate(sub_title,\n",
    "#                     xy=(sum(span_range[idx])/2 , 0.5),\n",
    "#                     xytext=(0,0), textcoords='offset points',\n",
    "#                     va=\"center\", ha=\"center\",\n",
    "#                     color=\"w\", fontsize=16, fontweight='bold',\n",
    "#                     bbox=dict(boxstyle='round4', pad=0.4, color=color[idx], alpha=0.6))\n",
    "#         ax[i-1].axvspan(span_range[idx][0]-0.4,span_range[idx][1]+0.4,  color=color[idx], alpha=0.07)\n",
    "\n",
    "#     ax[i-1].set_xlim(0, best_iter + 20 + 2000)\n",
    "#     ax[i-1].legend(bbox_to_anchor=(0.95, 1), loc='upper right', title='logloss')\n",
    "\n",
    "# plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-08T15:32:38.352845Z",
     "iopub.status.idle": "2023-06-08T15:32:38.353222Z",
     "shell.execute_reply": "2023-06-08T15:32:38.353059Z",
     "shell.execute_reply.started": "2023-06-08T15:32:38.353042Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.696636</td>\n",
       "      <td>0.303364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.696636</td>\n",
       "      <td>0.303364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.696636</td>\n",
       "      <td>0.303364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.696636</td>\n",
       "      <td>0.303364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.696636</td>\n",
       "      <td>0.303364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.696636  0.303364\n",
       "1  010ebe33f668  0.696636  0.303364\n",
       "2  02fa521e1838  0.696636  0.303364\n",
       "3  040e15f562a2  0.696636  0.303364\n",
       "4  046e85c7cc7f  0.696636  0.303364"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = models_lgbm # + models_cb\n",
    "\n",
    "def predict(X):\n",
    "    y = np.zeros(len(X))\n",
    "    for i, model in enumerate(models):\n",
    "#         y += weights[i] * model.predict_proba(X)[:,1]\n",
    "        y += model.predict_proba(X)[:,1]\n",
    "#     return y / sum(weights)\n",
    "    return y / len(models)\n",
    "\n",
    "predictions = predict(test_df[features])\n",
    "# predictions = predict(generated_features_test)\n",
    "\n",
    "test_df['class_1'] = predictions\n",
    "test_df['class_0'] = 1 - predictions\n",
    "\n",
    "sample_submission[['class_0', 'class_1']] = test_df[['class_0', 'class_1']]\n",
    "sample_submission.to_csv(r\"submission.csv\", index=False)\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a lot of resulting features. I have already identified a few important once. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
