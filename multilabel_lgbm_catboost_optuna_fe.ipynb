{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabpfn --no-index --find-links=file:///kaggle/input/tab-pfn-dataset\n",
    "# !mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "# !cp /kaggle/input/tab-pfn-dataset/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:23.665663Z",
     "iopub.status.busy": "2023-06-08T15:31:23.665223Z",
     "iopub.status.idle": "2023-06-08T15:31:35.997437Z",
     "shell.execute_reply": "2023-06-08T15:31:35.996163Z",
     "shell.execute_reply.started": "2023-06-08T15:31:23.665630Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/iter-strat/iter_strat')\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "from catboost import Pool\n",
    "import xgboost as xgb\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "import itertools\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits, BaseShuffleSplit, _validate_shuffle_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import _num_samples, check_array\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import eli5\n",
    "from IPython.display import display\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "from colorama import Style, Fore\n",
    "\n",
    "palette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n",
    "           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n",
    "\n",
    "blk = Style.BRIGHT + Fore.BLACK\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "res = Style.RESET_ALL\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    # main\n",
    "    kaggle = False\n",
    "    test = False\n",
    "    \n",
    "    # features\n",
    "    fe_drop = True\n",
    "    \n",
    "    del_errs = False\n",
    "    del_outliers = False\n",
    "    del_outliers_adj = True\n",
    "    \n",
    "    feature_sel = False\n",
    "    n_feature_sel_repeats = 5\n",
    "    n_feature_sel_folds = 5\n",
    "    \n",
    "    undersample = False\n",
    "    oversample = False\n",
    "    \n",
    "    nan_impute = False\n",
    "    standard_scale = False\n",
    "    log = False\n",
    "    \n",
    "    # optimization\n",
    "    n_estimators = 3000\n",
    "    early_stopping_rounds = 100\n",
    "    \n",
    "    lgbm_optimize = False\n",
    "    xgb_optimize = False\n",
    "    cb_optimize = False\n",
    "    \n",
    "    n_trials = 500\n",
    "    n_optimize_folds = 10\n",
    "    n_optimize_repeats = 2\n",
    "    \n",
    "    # train\n",
    "    lgbm_train = True\n",
    "    xgb_train = False\n",
    "    cb_train = False\n",
    "    tabpfn_train = False\n",
    "\n",
    "    # inference\n",
    "    n_stacking_folds = 20\n",
    "    n_stacking_models_lgbm = 40\n",
    "    n_stacking_models_xgb = 10\n",
    "    n_stacking_models_cb = 20\n",
    "    n_stacking_models_tabpfn = 20\n",
    "\n",
    "    adjust_class_threshold = False\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.001085Z",
     "iopub.status.busy": "2023-06-08T15:31:35.999808Z",
     "iopub.status.idle": "2023-06-08T15:31:36.066222Z",
     "shell.execute_reply": "2023-06-08T15:31:36.064862Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.001050Z"
    }
   },
   "outputs": [],
   "source": [
    "if CFG.kaggle:\n",
    "    COMP_PATH = \"/kaggle/input/icr-identify-age-related-conditions\"\n",
    "else:\n",
    "    COMP_PATH = \"icr-identify-age-related-conditions\"\n",
    "\n",
    "train_df = pd.read_csv(f'{COMP_PATH}//train.csv')\n",
    "test_df = pd.read_csv(f'{COMP_PATH}/test.csv')\n",
    "greeks = pd.read_csv(f\"{COMP_PATH}/greeks.csv\")\n",
    "sample_submission = pd.read_csv(f\"{COMP_PATH}/sample_submission.csv\")\n",
    "\n",
    "train_df['EJ'] = train_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "test_df['EJ'] = test_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "\n",
    "train_df.columns = train_df.columns.str.replace(' ', '')\n",
    "test_df.columns = test_df.columns.str.replace(' ', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete erroneus objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.del_errs:\n",
    "    err_objs = [292, 102, 509, 367, 313, 462, 556]\n",
    "    train_df = train_df.loc[[i for i in train_df.index if i not in err_objs], :].reset_index(drop=True)\n",
    "    greeks = greeks.loc[[i for i in greeks.index if i not in err_objs], :].reset_index(drop=True)\n",
    "\n",
    "class_imbalance = 3 # train_df[train_df['Class'] == 0].shape[0] / train_df[train_df['Class'] == 1].shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "\n",
    "# features = train_df.drop(['Class', 'Id'], axis=1).columns\n",
    "\n",
    "# # average label of 20 Nearest Neighbours (colsine distance)\n",
    "# knn = NearestNeighbors(n_neighbors=10, metric='cosine', n_jobs=-1)\n",
    "# knn.fit(train_df[features].fillna(0))\n",
    "\n",
    "# # train\n",
    "# dists, nears = knn.kneighbors(train_df[features].fillna(0), return_distance=True)\n",
    "# dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# train_df['class_cos'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# train_df['class_cos'] = train_df['class_cos'].astype(float)\n",
    "\n",
    "# # test\n",
    "# dists, nears = knn.kneighbors(test_df[features].fillna(0), return_distance=True)\n",
    "# dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# test_df['class_cos'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# test_df['class_cos'] = test_df['class_cos'].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop not necessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 38, 55)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CFG.fe_drop:\n",
    "    features = [fe for fe in train_df.columns if fe not in ['CF', 'CB', 'DV', 'BR', 'DF', 'GB', 'AH',\n",
    "                                                            'CW', 'CL', 'BP', 'BD', 'FC', 'GE', 'GF',\n",
    "                                                            'AR', 'GI', 'Id', 'Class', 'AX', 'DA']]\n",
    "else:\n",
    "    features = [fe for fe in train_df.columns if fe not in ['Id', 'Class', 'EJ']]\n",
    "\n",
    "num_cols = train_df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "len(train_df.columns), len(features), len(num_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "train_df_tabpfn = train_df.copy()\n",
    "test_df_tabpfn = test_df.copy()\n",
    "\n",
    "train_df_tabpfn[num_cols] = imp.fit_transform(train_df_tabpfn[num_cols])\n",
    "test_df_tabpfn[num_cols] = imp.transform(test_df_tabpfn[num_cols])\n",
    "\n",
    "if CFG.nan_impute:\n",
    "    train_df[num_cols] = train_df_tabpfn[num_cols]\n",
    "    test_df[num_cols] = test_df_tabpfn[num_cols]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_outliers = [fe for fe in train_df.columns if fe not in ['BN', 'BQ', 'CW', 'EL', 'GH', \n",
    "                                                                      'GI', 'GL', 'Id', 'Class', 'EJ']]\n",
    "\n",
    "if CFG.del_outliers:\n",
    "    for f in features_with_outliers:\n",
    "        train_df[f] = train_df[f].clip(upper=train_df[f].quantile(0.99))\n",
    "        test_df[f] = test_df[f].clip(upper=test_df[f].quantile(0.99))\n",
    "\n",
    "if CFG.del_outliers_adj:\n",
    "    from adjdatatools.preprocessing import AdjustedScaler\n",
    "\n",
    "    adj_scaler = AdjustedScaler(with_centering=True)\n",
    "    adj_scaler.fit(train_df[features])\n",
    "    train_df[features] = adj_scaler.transform(train_df[features])\n",
    "    test_df[features] = adj_scaler.transform(test_df[features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "train_df_tabpfn[num_cols] = sc.fit_transform(train_df_tabpfn[num_cols])\n",
    "test_df_tabpfn[num_cols] = sc.transform(test_df_tabpfn[num_cols])\n",
    "train_df_tabpfn['EJ'] = train_df['EJ']\n",
    "test_df_tabpfn['EJ'] = test_df['EJ']\n",
    "\n",
    "if CFG.standard_scale:\n",
    "    train_df[num_cols] = train_df_tabpfn[num_cols]\n",
    "    test_df[num_cols] = test_df_tabpfn[num_cols]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log features (preserve sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.log:\n",
    "    train_df[num_cols] = np.log1p(train_df[num_cols])\n",
    "    test_df[num_cols] = np.log1p(test_df[num_cols])\n",
    "\n",
    "# for f in features:\n",
    "#     train_df[f] = np.sign(train_df[f]) * np.log1p(np.abs(train_df[f])) # no significant result for LGBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:41.223344Z",
     "iopub.status.busy": "2023-06-08T15:32:41.222954Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    N_inv_0 = 1/N_0 if N_0 > 0 else 0\n",
    "    N_inv_1 = 1/N_1 if N_1 > 0 else 0\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability ð‘ is replaced with max(min(ð‘,1âˆ’10âˆ’15),10âˆ’15)\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - N_inv_0 * np.sum((1 - y_true) * np.log(1 - y_pred)) - N_inv_1 * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2\n",
    "\n",
    "if not CFG.kaggle:\n",
    "\n",
    "    from shaphypetune import BoostBoruta\n",
    "\n",
    "    params = {\n",
    "                'n_estimators': CFG.n_estimators,\n",
    "                'early_stopping_round': CFG.early_stopping_rounds,\n",
    "                'objective': 'binary',\n",
    "                'metric': 'logloss', \n",
    "                'n_jobs': -1,\n",
    "                'is_unbalance':True, \n",
    "                'class_weight':'balanced', \n",
    "                'verbose': -1,\n",
    "                'seed': 19062023,\n",
    "            }\n",
    "\n",
    "    def bll_metric(y_true, y_pred):\n",
    "        return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "    def lgbm_tuning(features, permut=False, boruta=False):\n",
    "        metric = balanced_log_loss\n",
    "        eval_results_ = {}\n",
    "\n",
    "        cv_scores = [] # store all cv scores of outer loop inference\n",
    "\n",
    "        perm_df_ = pd.DataFrame()\n",
    "        feature_importances_ = pd.DataFrame()\n",
    "        boruta_df_ = pd.DataFrame()\n",
    "        \n",
    "        for i in range(CFG.n_feature_sel_repeats):\n",
    "            print(f'Repeat {blu}#{i+1}')\n",
    "            \n",
    "            # Make random under-sampling to balance classes\n",
    "            positive_count_train = train_df['Class'].value_counts()[1]\n",
    "            sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train * 3, \n",
    "                                                            1: positive_count_train}, \n",
    "                                        random_state=15062023+i, \n",
    "                                        replacement=True)\n",
    "\n",
    "            X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "            \n",
    "            if CFG.undersample:\n",
    "                X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "            \n",
    "            # Create Stratified Multilabel k-Fold scheme\n",
    "            kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=8062023+i)\n",
    "\n",
    "            # Create an oof array for inner loop\n",
    "            oof = np.zeros(X_re.shape[0])\n",
    "            \n",
    "            # Stratify based on Class and Alpha (3 types of conditions)\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start = 1): \n",
    "                X, y = X_re[features], y_re\n",
    "\n",
    "                # Split the dataset according to the fold indexes.\n",
    "                X_train = X.iloc[train_idx]\n",
    "                X_val = X.iloc[val_idx]\n",
    "                y_train = y.iloc[train_idx]\n",
    "                y_val = y.iloc[val_idx]\n",
    "\n",
    "\n",
    "                X_train = X_train.reset_index(drop=True)\n",
    "                y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "                # Store models here\n",
    "                models_ = [] \n",
    "\n",
    "                eval_results_[fold]= {}\n",
    "\n",
    "                clf = lgb.LGBMClassifier(**params)\n",
    "                clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=bll_metric, verbose=0)\n",
    "\n",
    "                models_.append(clf)\n",
    "\n",
    "                val_preds = clf.predict_proba(X_val)[:,1]\n",
    "                oof[val_idx] = val_preds\n",
    "\n",
    "                val_score = metric(y_val, val_preds)\n",
    "                best_iter = clf.best_iteration_\n",
    "\n",
    "                print(f'Fold: {blu}{fold:>3}{res}| {metric.__name__}: {blu}{val_score:.5f}{res}'\n",
    "                    f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "\n",
    "                # permutation importance\n",
    "                if permut:\n",
    "                    perm = PermutationImportance(clf, scoring=None, n_iter=1, \n",
    "                                                random_state=42, cv=None, refit=False).fit(X_val, y_val)\n",
    "\n",
    "                    perm_importance_df = pd.DataFrame({'importance': perm.feature_importances_}, \n",
    "                                                    index=X_val.columns).sort_index()\n",
    "\n",
    "                    if perm_df_.shape[0] == 0:\n",
    "                        perm_df_ = perm_importance_df.copy()\n",
    "                    else:\n",
    "                        perm_df_ += perm_importance_df\n",
    "\n",
    "                # tree feature importance\n",
    "                f_i = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns), \n",
    "                                                reverse=True, key=lambda x: x[1]), \n",
    "                                columns=['Value','Feature'])\n",
    "\n",
    "                if feature_importances_.shape[0] == 0:\n",
    "                    feature_importances_ = f_i.copy()\n",
    "                else:\n",
    "\n",
    "                    feature_importances_['Value'] += f_i['Value']\n",
    "\n",
    "                # Boruta SHAP importance\n",
    "                if boruta:\n",
    "                    model = BoostBoruta(clf, importance_type='shap_importances', train_importance=False)\n",
    "                    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=bll_metric, verbose=0)\n",
    "\n",
    "                    boruta_importance_df = pd.DataFrame({'importance': model.ranking_}, index=X_train.columns).sort_index()\n",
    "                    if boruta_df_.shape[0] == 0:\n",
    "                        boruta_df_ = boruta_importance_df.copy()\n",
    "                    else:\n",
    "                        boruta_df_ += boruta_importance_df\n",
    "\n",
    "            fold_cv_score = metric(y_re, oof)\n",
    "            print(f'{red} CV score: {res} {metric.__name__}: {red}{fold_cv_score:.5f}{res}')\n",
    "            print(f'{\"*\" * 50}\\n')\n",
    "            cv_scores.append(fold_cv_score)\n",
    "\n",
    "\n",
    "        print(f'{red} Avg score {CFG.n_feature_sel_folds}-fold: {res} {metric.__name__}: {red}{np.mean(cv_scores):.5f}{res}')\n",
    "        print(f'{\"*\" * 50}\\n')\n",
    "        \n",
    "        if permut:\n",
    "            perm_df_ = perm_df_.sort_values('importance', ascending=False)\n",
    "            \n",
    "        if boruta:\n",
    "            boruta_df_ = boruta_df_.sort_values('importance')\n",
    "                                        \n",
    "        feature_importances_ = feature_importances_.sort_values('Value', ascending=False)\n",
    "        \n",
    "        return perm_df_, feature_importances_, boruta_df_, np.mean(cv_scores)\n",
    "\n",
    "    if CFG.feature_sel:\n",
    "        perm_df_, feature_importances_, boruta_df_, cv_scores = lgbm_tuning(features, permut=True, boruta=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check features correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    col = 'DA'\n",
    "    x = train_df[train_df[col] <= train_df[col].quantile(0.99)]\n",
    "    cm = x[[c for c in train_df.columns if c not in ['Id', 'Class']]].corr()\n",
    "    display(np.abs(cm[col]).sort_values(ascending=False)[1:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.619184Z",
     "iopub.status.busy": "2023-06-08T15:32:11.618864Z",
     "iopub.status.idle": "2023-06-08T15:32:11.652915Z",
     "shell.execute_reply": "2023-06-08T15:32:11.652069Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.619157Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    perm_df_.to_csv('perm_df.csv')\n",
    "    perm_df_\n",
    "    perm_cols = set(perm_df_.index[-35:])\n",
    "    display(perm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pd.read_csv('perm_df.csv', index_col='Unnamed: 0')\n",
    "# x['feature'] = x.index.copy()\n",
    "# x = x.reset_index(drop=True)\n",
    "# x['rank'] = x['importance'].rank()\n",
    "# x = x[['feature', 'rank']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze tree gain feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.654626Z",
     "iopub.status.busy": "2023-06-08T15:32:11.654102Z",
     "iopub.status.idle": "2023-06-08T15:32:11.669674Z",
     "shell.execute_reply": "2023-06-08T15:32:11.668840Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.654583Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    feature_importances_.to_csv('feature_importances.csv')\n",
    "    feature_importances_\n",
    "    fi_cols = set(feature_importances_['Feature'].values[-23:])\n",
    "    display(fi_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = pd.read_csv('feature_importances.csv')\n",
    "# y['feature'] = y['Feature']\n",
    "# y = y.reset_index(drop=True)\n",
    "# y['rank'] = y['Value'].rank()\n",
    "# y = y[['feature', 'rank']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze BORUTA importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    boruta_df_.to_csv('boruta_df_.csv')\n",
    "    boruta_df_\n",
    "    boruta_cols = set(boruta_df_.index[-35:])\n",
    "    display(boruta_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = pd.read_csv('boruta_df_.csv', index_col='Unnamed: 0')\n",
    "# z['feature'] = z.index.copy()\n",
    "# z = z.reset_index(drop=True)\n",
    "# z['rank'] = z['importance'].rank(ascending=False)\n",
    "# z = z[['feature', 'rank']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort all features according to their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.concat([x, y, z])\n",
    "# a = a[['feature', 'rank']]\n",
    "# res = a.groupby('feature')['rank'].sum().sort_values(ascending=False)#.index.to_list()\n",
    "# res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "X, y = train_df[features], train_df['Class'] \n",
    "    \n",
    "def objective(trial):\n",
    "    param = {\n",
    "        # Main parameters\n",
    "#                     'device': 'gpu',\n",
    "#                     'gpu_platform_id': 0,\n",
    "#                     'gpu_device_id': 0,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'none',\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['goss', 'gbdt']),#, 'dart']),   \n",
    "        # Hyperparamters (in order of importance decreasing)\n",
    "        'n_estimators': CFG.n_estimators, # trial.suggest_int('n_estimators', 500, 1500),  # max number of trees in model\n",
    "        'early_stopping_round': CFG.early_stopping_rounds, \n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 3e-1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True), # L1,  alias: lambda_l1\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True), # L2, alias: lambda_l2\n",
    "         # decrease to deal with overfit\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),   # tree max depth \n",
    "         # decrease to deal with overfit\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 128),  # Max number of leaves in one tree\n",
    "                                                                # should be ~ 2**(max_depth-1)\n",
    "        'subsample': None, # Randomly select part of data without \n",
    "                                  # resampling if subsample < 1.0\n",
    "                                  # alias: bagging_fraction\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.7), # Randomly select a subset of features \n",
    "                                                                   # if colsample_bytree < 1.0\n",
    "                                                                   # alias:feature_fraction\n",
    "        # decrease to deal with overfit\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                             # aliases: min_data_in_leaf, \n",
    "        # increase for accuracy, decrease to deal with overfit\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255), # Max number of bins that feature values will be bucketed in\n",
    "        # increase to deal with overfit\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 1, 7), # Perform bagging at every k iteration, alias: bagging_freq\n",
    "\n",
    "#           'subsample_for_bin': 200000, # Number of data that sampled to construct feature discrete bins; setting this \n",
    "                                     # to larger value will give better training result but may increase train time \n",
    "#           'cat_smooth': trial.suggest_float('cat_smooth', 10.0, 100.0),  # this can reduce the effect of noises in \n",
    "                                                                       # categorical features, especially for \n",
    "                                                                       # categories with few data\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        param['is_unbalance'] = True\n",
    "        param['class_weight'] = 'balanced'\n",
    "    else:\n",
    "        param['scale_pos_weight'] = class_imbalance\n",
    "    \n",
    "    if param['boosting_type'] != 'goss':\n",
    "        param['subsample'] = trial.suggest_float('subsample', 0.3, 0.7)\n",
    "\n",
    "    bll_list = list()\n",
    "    \n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under- or oversampling to balance classes\n",
    "        if CFG.undersample:\n",
    "            positive_count_train = train_df['Class'].value_counts()[1]\n",
    "            sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train * class_imbalance, \n",
    "                                                            1: positive_count_train}, \n",
    "                                        random_state=15062023+i, \n",
    "                                        replacement=True)\n",
    "        elif CFG.oversample:\n",
    "            negative_count_train = train_df['Class'].value_counts()[0]\n",
    "            sampler = RandomOverSampler(sampling_strategy={0: negative_count_train, \n",
    "                                                           1: negative_count_train // class_imbalance}, \n",
    "                                        random_state=2306020231)\n",
    "\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_optimize_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # oversample\n",
    "            if CFG.oversample:\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "            clf = lgb.LGBMClassifier(**param)\n",
    "            clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                    eval_metric=bll_metric, verbose=0)\n",
    "\n",
    "            val_preds = clf.predict_proba(X_val)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "        bll_list.append(balanced_log_loss(y_re, oof))\n",
    "\n",
    "    return np.mean(bll_list)\n",
    "            \n",
    "\n",
    "if CFG.lgbm_optimize:\n",
    "#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials * 2)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df.to_csv(f'optuna_lgbm.csv')\n",
    "\n",
    "    display(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LGBM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if CFG.kaggle:\n",
    "    param_list = glob.glob(\"/kaggle/input/icr-optuna-no-da/optuna_lgbm.csv\")\n",
    "else:\n",
    "    param_list = glob.glob(\"optuna_lgbm.csv\")\n",
    "\n",
    "models = list()\n",
    "best_lgbm_params = list()\n",
    "\n",
    "lgbm_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if lgbm_params.shape[0] == 0:\n",
    "        lgbm_params = tmp\n",
    "    else:\n",
    "        lgbm_params = pd.concat([lgbm_params, tmp])\n",
    "        \n",
    "lgbm_params = lgbm_params.sort_values('value').head(CFG.n_stacking_models_lgbm)\n",
    "param_cols = [c for c in lgbm_params.columns if c.startswith('params_')]\n",
    "lgbm_params = lgbm_params[param_cols]\n",
    "\n",
    "for idx, row in lgbm_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['objective'] = 'binary'\n",
    "    row_dict['metric'] = 'none'\n",
    "#     row_dict['subsample_for_bin'] = 300000\n",
    "    row_dict['force_col_wise'] = False\n",
    "    row_dict['n_estimators'] = CFG.n_estimators\n",
    "    row_dict['early_stopping_round'] = CFG.early_stopping_rounds\n",
    "    row_dict['verbose'] = -1\n",
    "    row_dict['max_bin'] = 255\n",
    "    \n",
    "    row_dict['num_leaves'] = int(row_dict['num_leaves'])\n",
    "    row_dict['max_depth'] = int(row_dict['max_depth'])\n",
    "    row_dict['min_child_samples'] = int(row_dict['min_child_samples'])\n",
    "    row_dict['subsample_freq'] = int(row_dict['subsample_freq'])\n",
    "    row_dict['learning_rate'] = float(row_dict['learning_rate'])\n",
    "    \n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        row_dict['is_unbalance'] = True\n",
    "        row_dict['class_weight'] = 'balanced'\n",
    "    else:\n",
    "        row_dict['scale_pos_weight'] = class_imbalance\n",
    "    \n",
    "    if row_dict['boosting_type'] == 'goss':\n",
    "        row_dict['subsample'] = None\n",
    "        \n",
    "    best_lgbm_params.append(row_dict)\n",
    "\n",
    "if CFG.test:\n",
    "    best_lgbm_params = [{\n",
    "            'boosting_type': 'goss',\n",
    "            'n_estimators': 50000,\n",
    "            'early_stopping_round': 300,\n",
    "            'max_depth': 8,\n",
    "            'learning_rate': 0.06733232950390658,\n",
    "            'subsample': 0.6970532011679706,\n",
    "            'colsample_bytree': 0.6055755840633003,\n",
    "            'is_unbalance': True, \n",
    "            'class_weight': 'balanced',\n",
    "            'metric':'none',\n",
    "            'verbose': -1,\n",
    "            'random_state': 42,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "                         "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = train_df[features], train_df['Class']\n",
    "\n",
    "def objective(trial):\n",
    "    bll_list = list()\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": CFG.n_estimators, # trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        \"early_stopping_rounds\": CFG.early_stopping_rounds,\n",
    "        \"verbosity\": 0,\n",
    "        \"random_state\": 14062023,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        # use exact for small dataset.\n",
    "        \"tree_method\": \"exact\",\n",
    "        # defines booster, gblinear for linear functions.\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),# \"dart\", \"gblinear\"]), \n",
    "        # L1 regularization weight.\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        # L2 regularization weight.\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        # sampling ratio for training data.\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "        # sampling according to each tree.\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "    }\n",
    "\n",
    "    # if not CFG.oversample and not CFG.undersample:\n",
    "    params[\"scale_pos_weight\"] = class_imbalance\n",
    "    \n",
    "    if params[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        params[\"learning_rate\"] = trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True) # alias eta\n",
    "        # maximum depth of the tree, signifies complexity of the tree.\n",
    "        params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "        # minimum child weight, larger the term more conservative the tree.\n",
    "        params[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "        # defines how selective algorithm is.\n",
    "        params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "    if params[\"booster\"] == \"dart\":\n",
    "        params[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        params[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        params[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        params[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "\n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under- or oversampling to balance classes\n",
    "        if CFG.undersample:\n",
    "            positive_count_train = train_df['Class'].value_counts()[1]\n",
    "            sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train * class_imbalance, \n",
    "                                                            1: positive_count_train}, \n",
    "                                        random_state=15062023+i, \n",
    "                                        replacement=True)\n",
    "        elif CFG.oversample:\n",
    "            negative_count_train = train_df['Class'].value_counts()[0]\n",
    "            sampler = RandomOverSampler(sampling_strategy={0: negative_count_train, \n",
    "                                                           1: negative_count_train // class_imbalance}, \n",
    "                                        random_state=2306020231)\n",
    "\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_optimize_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # oversample\n",
    "            if CFG.oversample:\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "            # Learning\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "            # Predict\n",
    "            val_preds = model.predict_proba(X_val)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "        \n",
    "        bll_list.append(balanced_log_loss(y_re, oof))    \n",
    "    \n",
    "    return np.mean(bll_list)\n",
    "\n",
    "if CFG.xgb_optimize:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials * 2)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df.to_csv(f'optuna_xgb.csv')\n",
    "\n",
    "    display(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load XGBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if CFG.kaggle:\n",
    "    param_list = glob.glob(\"/kaggle/input/icr-optuna-no-da/optuna_xgb.csv\")\n",
    "else:\n",
    "    param_list = glob.glob(\"optuna_xgb.csv\")\n",
    "\n",
    "models = list()\n",
    "best_xgb_params = list()\n",
    "\n",
    "xgb_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if xgb_params.shape[0] == 0:\n",
    "        xgb_params = tmp\n",
    "    else:\n",
    "        xgb_params = pd.concat([xgb_params, tmp])\n",
    "        \n",
    "xgb_params = xgb_params.sort_values('value').head(CFG.n_stacking_models_xgb)\n",
    "param_cols = [c for c in xgb_params.columns if c.startswith('params_')]\n",
    "xgb_params = xgb_params[param_cols]\n",
    "\n",
    "for idx, row in xgb_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['n_estimators'] = CFG.n_estimators\n",
    "    row_dict['early_stopping_rounds'] = CFG.early_stopping_rounds\n",
    "    row_dict['random_state'] = 14062023\n",
    "    row_dict['verbosity'] = 0\n",
    "    row_dict['objective'] = \"binary:logistic\"\n",
    "    row_dict['eval_metric'] = \"logloss\"\n",
    "    row_dict['tree_method'] = \"exact\"\n",
    "    row_dict['booster'] = \"gbtree\"\n",
    "\n",
    "    # if not CFG.oversample and not CFG.undersample:\n",
    "    row_dict['scale_pos_weight'] = class_imbalance\n",
    "\n",
    "    if row_dict[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        row_dict[\"max_depth\"] = int(row_dict[\"max_depth\"])\n",
    "        row_dict[\"min_child_weight\"] = int(row_dict[\"min_child_weight\"])\n",
    "    else:\n",
    "        row_dict[\"learning_rate\"] = None\n",
    "        row_dict[\"max_depth\"] = None\n",
    "        row_dict[\"min_child_weight\"] = None\n",
    "        row_dict[\"gamma\"] = None\n",
    "        row_dict[\"grow_policy\"] = None     \n",
    "\n",
    "    if row_dict[\"booster\"] != \"dart\":\n",
    "        row_dict[\"sample_type\"] = None\n",
    "        row_dict[\"normalize_type\"] = None\n",
    "        row_dict[\"rate_drop\"] = None\n",
    "        row_dict[\"skip_drop\"] = None\n",
    "\n",
    "    best_xgb_params.append(row_dict)\n",
    "\n",
    "if CFG.test:\n",
    "    best_xgb_params = [{\n",
    "            'n_estimators': CFG.n_estimators,\n",
    "            'early_stopping_rounds': CFG.early_stopping_rounds,\n",
    "            'objective': \"binary:logistic\",\n",
    "            'scale_pos_weight': class_imbalance, \n",
    "            'verbosity': 0,\n",
    "            'random_state': 19062023,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = train_df[features], train_df['Class']\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    bll_list = list()\n",
    "\n",
    "    # Parameters\n",
    "    params = {\n",
    "        'task_type': 'CPU', # GPU\n",
    "        'eval_metric': 'Logloss',\n",
    "        'loss_function': 'Logloss', \n",
    "        'random_seed': 19062023,\n",
    "        'od_type': 'Iter', # Type of overfitting detector - stop after k iteraions\n",
    "        'iterations' : CFG.n_estimators, # trial.suggest_int('iterations', 300, 1200),        \n",
    "        'od_wait': CFG.early_stopping_rounds, # Overfitting detector - stop training after k iterations without metric improvement\n",
    "        # 'metric_period': 100, # Show metric each k iterations\n",
    "        # Hyperparamters (in order of importance decreasing)\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS', 'No']),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-3, 3e-1), \n",
    "        'l2_leaf_reg': trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
    "        'depth' : trial.suggest_int('depth', 4, 10),  # Max tree depth                                          \n",
    "         # increase to deal with overfit\n",
    "        'random_strength': trial.suggest_float('random_strength', 0, 100), # The amount of randomness to use\n",
    "                                                                           # for scoring splits when the tree structure\n",
    "                                                                           # is selected. Helps to avoid overfitting\n",
    "                                                                           # CPU only\n",
    "        # per_float_feature_quantization='0:border_count=1024'\n",
    "        'border_count': 254, # trial.suggest_categorical('border_count', [128, 254]), # The number of splits for numerical features\n",
    "                                                                                      # bigger is better but slowly\n",
    "                                                                                      # alias: max_bin\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                           # aliases: min_child_samples, \n",
    "\n",
    "    }\n",
    "\n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        params['scale_pos_weight'] = class_imbalance\n",
    "    else:\n",
    "        params['auto_class_weights'] = 'Balanced'\n",
    "        \n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 100) # Assigns random \n",
    "                                                                                           # weights to objects\n",
    "                                                                                           # works only with \n",
    "                                                                                           # Bayesian bootstrap\n",
    "    if params[\"bootstrap_type\"] in [\"Poisson\", \"Bernoulli\", \"MVS\"]:\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.3, 1) # Percentage of objects to use \n",
    "                                                                        # at each split\n",
    "\n",
    "    if params['task_type'] == 'CPU' and params['bootstrap_type'] != 'Bayesian':\n",
    "        params[\"colsample_bylevel\"] = trial.suggest_float(\"colsample_bylevel\", 0.3, 1)  # Percentage of features to use \n",
    "                                                                                        # at each split;\n",
    "                                                                                        # with Bayesian bootstrap and Lossguide grop policy\n",
    "                                                                                        # leads to error (CatBoost bug)\n",
    "    else:\n",
    "        params[\"colsample_bylevel\"] = None                                                     \n",
    "\n",
    "    if params['grow_policy'] == 'Lossguide': \n",
    "        params['max_leaves'] = trial.suggest_int('max_leaves', 4, 128) # Max number of leaves in one tree \n",
    "                                                                       # decrease to deal with the overfit\n",
    "\n",
    "    if params['grow_policy'] == 'SymmetricTree': \n",
    "        params['boosting_type'] = trial.suggest_categorical('boosting_type', ['Ordered', 'Plain'])\n",
    "    else:\n",
    "        params['boosting_type'] = 'Plain'\n",
    "    \n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under- or oversampling to balance classes\n",
    "        if CFG.undersample:\n",
    "            positive_count_train = train_df['Class'].value_counts()[1]\n",
    "            sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train * class_imbalance, \n",
    "                                                            1: positive_count_train}, \n",
    "                                        random_state=15062023+i, \n",
    "                                        replacement=True)\n",
    "        elif CFG.oversample:\n",
    "            negative_count_train = train_df['Class'].value_counts()[0]\n",
    "            sampler = RandomOverSampler(sampling_strategy={0: negative_count_train, \n",
    "                                                           1: negative_count_train // class_imbalance}, \n",
    "                                        random_state=2306020231)\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_optimize_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # oversample\n",
    "            if CFG.oversample:\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "            train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "            val_pool = Pool(X_val, y_val, cat_features=['EJ'])\n",
    "\n",
    "            # Learning\n",
    "            model = cat.CatBoostClassifier(**params)     \n",
    "            # Add a callback for pruning\n",
    "#             pruning_callback = optuna.integration.CatBoostPruningCallback(trial, \"Logloss\")\n",
    "            model.fit(train_pool, eval_set=val_pool, verbose=0)#, callbacks=[pruning_callback])\n",
    "            # Evoke pruning manually\n",
    "#                 pruning_callback.check_pruned()\n",
    "            # Predict\n",
    "            val_preds = model.predict_proba(val_pool)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "        \n",
    "        bll_list.append(balanced_log_loss(y_re, oof))    \n",
    "    \n",
    "    return np.mean(bll_list)\n",
    "\n",
    "if CFG.cb_optimize:\n",
    "#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df.to_csv(f'optuna_catboost.csv')\n",
    "\n",
    "    display(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CatBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if CFG.kaggle:\n",
    "    param_list = glob.glob(\"/kaggle/input/icr-optuna-no-da/optuna_catboost.csv\")\n",
    "else:\n",
    "    param_list = glob.glob(\"optuna_catboost.csv\")\n",
    "\n",
    "models = list()\n",
    "best_cb_params = list()\n",
    "\n",
    "cb_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if cb_params.shape[0] == 0:\n",
    "        cb_params = tmp\n",
    "    else:\n",
    "        cb_params = pd.concat([cb_params, tmp])\n",
    "        \n",
    "cb_params = cb_params.sort_values('value').head(CFG.n_stacking_models_cb)\n",
    "param_cols = [c for c in cb_params.columns if c.startswith('params_')]\n",
    "cb_params = cb_params[param_cols]\n",
    "\n",
    "\n",
    "for idx, row in cb_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['task_type'] = 'CPU'\n",
    "    row_dict['eval_metric'] = 'Logloss'\n",
    "    row_dict['loss_function'] = 'Logloss'\n",
    "    row_dict['random_seed'] = 13062023\n",
    "    row_dict['verbose'] = 0\n",
    "    row_dict['od_type'] = 'Iter'\n",
    "    row_dict['iterations'] = CFG.n_estimators * 4\n",
    "    row_dict['od_wait'] = CFG.early_stopping_rounds\n",
    "    row_dict['border_count'] = 254\n",
    "    \n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        row_dict['scale_pos_weight'] = class_imbalance\n",
    "    else:\n",
    "        row_dict['auto_class_weights'] = 'Balanced'\n",
    "        \n",
    "    if row_dict[\"task_type\"] != \"GPU\":\n",
    "        row_dict['colsample_bylevel'] = None\n",
    "    \n",
    "    if row_dict[\"bootstrap_type\"] != \"Bayesian\":\n",
    "        row_dict['bagging_temperature'] = None\n",
    "        \n",
    "    if row_dict[\"bootstrap_type\"] not in [\"Poisson\", \"Bernoulli\", \"MVS\"]:\n",
    "        row_dict['subsample'] = None\n",
    "    \n",
    "    if row_dict['grow_policy'] == 'Lossguide':\n",
    "        row_dict['max_leaves'] = int(row_dict['max_leaves'])\n",
    "    else:\n",
    "        row_dict['max_leaves'] = None\n",
    "    \n",
    "    if row_dict['grow_policy'] != 'SymmetricTree':\n",
    "        row_dict['boosting_type'] = 'Plain'\n",
    "    \n",
    "    best_cb_params.append(row_dict)\n",
    "\n",
    "if CFG.test:\n",
    "    best_cb_params = [{\n",
    "            'iterations': CFG.n_estimators,\n",
    "            'od_type': 'Iter',\n",
    "            'od_wait': CFG.early_stopping_rounds,\n",
    "            'eval_metric': \"Logloss\",\n",
    "            'loss_function': \"Logloss\",\n",
    "            'auto_class_weights': 'Balanced', \n",
    "            'verbose': 0,\n",
    "            'random_seed': 19062023,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def pp_prob(p):\n",
    "    c0 = p[:,0].sum()\n",
    "    c1 = p[:,1:].sum()\n",
    "    new_p = p * np.array([[1/(c0 if i==0 else c1) for i in range(p.shape[1])]])\n",
    "    new_p = new_p / np.sum(new_p,axis=1,keepdims=1)\n",
    "    return np.sum(new_p[:,1:],1,keepdims=False)\n",
    "\n",
    "def model_train(how, best_params):\n",
    "\n",
    "    oof_level2 = np.zeros([train_df['Class'].shape[0], len(best_params) + 1])\n",
    "    oof_level2[:, len(best_params)] = train_df['Class']\n",
    "    oof_level2_test = np.zeros([test_df.shape[0], len(best_params)])\n",
    "    \n",
    "    for i, params in tqdm(enumerate(best_params), total=len(best_params)):\n",
    "        \n",
    "        if how == 'tabpfn':\n",
    "            X, y, test = train_df_tabpfn[num_cols], train_df['Class'], test_df_tabpfn[num_cols]\n",
    "        else:\n",
    "            X, y, test = train_df[features], train_df['Class'], test_df[features]\n",
    "    \n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=80620231+i)\n",
    "\n",
    "        print(f\"Training with {blu}{len(features)}{res} features\")\n",
    "\n",
    "        for fold, (fit_idx, val_idx) in enumerate(kf.split(X=X, y=greeks.iloc[:,1:4]), start=1):\n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[fit_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[fit_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # Make random under- or oversampling to balance classes\n",
    "            if CFG.undersample or CFG.oversample:\n",
    "                if CFG.undersample:\n",
    "                    positive_count_train = y_train.value_counts()[1]\n",
    "                    sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train * class_imbalance, \n",
    "                                                                    1: positive_count_train}, \n",
    "                                                random_state=15062023+i, \n",
    "                                                replacement=True)\n",
    "                elif CFG.oversample:\n",
    "                    negative_count_train = y_train.value_counts()[0]\n",
    "                    sampler = RandomOverSampler(sampling_strategy={0: negative_count_train, \n",
    "                                                                   1: negative_count_train // class_imbalance}, \n",
    "                                                random_state=2306020231+i)\n",
    "\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "            \n",
    "            if how == 'catboost':\n",
    "                train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "                val_pool = Pool(X_val, y_val, cat_features=['EJ'])           \n",
    "            \n",
    "            if how == 'lgbm':\n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=bll_metric, verbose=0)\n",
    "                best_iter = model.best_iteration_\n",
    "            elif how == 'xgboost':\n",
    "                model = xgb.XGBClassifier(**params)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "                best_iter = model.get_booster().best_iteration\n",
    "            elif how == 'catboost':\n",
    "                model = cat.CatBoostClassifier(**params)\n",
    "                model.fit(train_pool, eval_set=val_pool, verbose=0)\n",
    "                best_iter = model.best_iteration_\n",
    "            elif how == 'tabpfn':\n",
    "                model = TabPFNClassifier(N_ensemble_configurations=64, device='cuda:0')\n",
    "                model.fit(X_train, y_train, overwrite_warning=True)\n",
    "                best_iter = 0\n",
    "            else:\n",
    "                return None, None\n",
    "                \n",
    "            if how == 'tabpfn':\n",
    "                val_preds = pp_prob(model.predict_proba(X_val))\n",
    "                oof_level2_test[:, i] += pp_prob(model.predict_proba(test))\n",
    "            else:\n",
    "                val_preds = model.predict_proba(X_val)[:,1]\n",
    "                oof_level2_test[:, i] += model.predict_proba(test)[:,1]\n",
    "            \n",
    "            oof_level2[val_idx, i] = val_preds\n",
    "\n",
    "            val_score = balanced_log_loss(y_val, val_preds)\n",
    "            \n",
    "            print(f'Fold: {blu}{fold:>3}{res}| bll_metric: {blu}{val_score:.5f}{res}'\n",
    "                    f' | Best iteration: {blu}{best_iter:>4}{res}') \n",
    "        \n",
    "    return oof_level2, oof_level2_test / CFG.n_stacking_folds\n",
    "\n",
    "oof_train_list = list()\n",
    "oof_test_list = list()\n",
    "\n",
    "if CFG.lgbm_train:\n",
    "    oof_level2_lgbm, oof_level2_test_lgbm = model_train('lgbm', best_lgbm_params)\n",
    "    oof_train_list.append(oof_level2_lgbm[:,:-1])\n",
    "    oof_test_list.append(oof_level2_test_lgbm)\n",
    "    y = oof_level2_lgbm[:,-1]\n",
    "\n",
    "if CFG.xgb_train:\n",
    "    oof_level2_xgb, oof_level2_test_xgb = model_train('xgboost', best_xgb_params)\n",
    "    oof_train_list.append(oof_level2_xgb[:,:-1])\n",
    "    oof_test_list.append(oof_level2_test_xgb)\n",
    "    y = oof_level2_xgb[:,-1]\n",
    "\n",
    "if CFG.cb_train:\n",
    "    oof_level2_cb, oof_level2_test_cb = model_train('catboost', best_cb_params)\n",
    "    oof_train_list.append(oof_level2_cb[:,:-1])\n",
    "    oof_test_list.append(oof_level2_test_cb)\n",
    "    y = oof_level2_cb[:,-1]\n",
    "\n",
    "if CFG.tabpfn_train:\n",
    "    oof_level2_tabpfn, oof_level2_test_tabpfn = model_train('tabpfn', [i for i in range(CFG.n_stacking_models_tabpfn)])\n",
    "    oof_train_list.append(oof_level2_tabpfn[:,:-1])\n",
    "    oof_test_list.append(oof_level2_test_tabpfn)\n",
    "    y = oof_level2_tabpfn[:,-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13307232895428073\n",
      "0.09321539940061024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "oof_level2 = np.concatenate(oof_train_list, axis=1)\n",
    "oof_level2_test = np.concatenate(oof_test_list, axis=1)\n",
    "\n",
    "X = oof_level2\n",
    "\n",
    "# mean bll\n",
    "print(balanced_log_loss(y, np.mean(X, axis=1)))\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "lr.fit(X, y)\n",
    "\n",
    "pred = lr.predict_proba(X)[:,1]\n",
    "\n",
    "# lr bll\n",
    "print(balanced_log_loss(y, pred))\n",
    "\n",
    "weights = lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM full dataset\n",
    "# 0.13372873188516746\n",
    "# 0.09363332625161021\n",
    "\n",
    "# LGBM full dataset with adjusted scaling\n",
    "# 0.13467176782918622\n",
    "# 0.09374656290880284\n",
    "\n",
    "# full dataset with class balance 3\n",
    "# 0.18130449603081458\n",
    "# 0.13249114243596113\n",
    "\n",
    "# undersample with class balance 3\n",
    "# 0.11174849200860162\n",
    "# 0.09973545010826133\n",
    "\n",
    "# undersample with class balance 3 and different undersamping for every model (validatidation was not undersampled)\n",
    "# 0.19671222032350008 / CV ~ 0.21\n",
    "# 0.12812153512778934\n",
    "\n",
    "# oversample with class balance 3\n",
    "# 0.17393849284307183\n",
    "# 0.11238039356223456\n",
    "\n",
    "# oversample with class balance 3 and different undersamping for every model (validatidation was not undersampled)\n",
    "# 0.17459339388826078\n",
    "# 0.11296531409464912\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM + CatBoost + XGBoost + TabPFN\n",
    "# 0.17472710249039772\n",
    "# 0.09683636947851168\n",
    "\n",
    "# LGBM oversampled 10 folds\n",
    "# 0.1899300127485599\n",
    "# 0.1321074079639491\n",
    "\n",
    "# LGBM + CatBoost + XGBoost + TabPFN + different k-fold for every model\n",
    "# 0.17616782811158316\n",
    "# 0.09637187593530008\n",
    "\n",
    "# LGBM + CatBoost + XGBoost + TabPFN + different k-fold for every model + 20 folds\n",
    "# 0.16113327662498975\n",
    "# 0.08182251667662065\n",
    "\n",
    "# LGBM 20 folds\n",
    "# 0.13372873188516746\n",
    "# 0.09363332625161021"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which objects are the most erroneus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[292, 102, 509, 337, 556, 380, 242]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.mean(X, axis=1)\n",
    "errors = pd.Series(np.abs(y - preds))\n",
    "errors = errors.sort_values(ascending=False) \n",
    "errors[errors >= errors.quantile(0.99)].index.to_list()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best class threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_prob3(_oof, _p, num=1.5):\n",
    "    # increase (num > 1) or decrease (num < 1) binary prediction value\n",
    "    oof = num * _oof / ((num - 1) * _oof + 1)\n",
    "    p = num * _p / ((num - 1) * _p + 1)\n",
    "    return oof, p\n",
    "\n",
    "def inflate_preds(_y, _oof, _p):\n",
    "    # find the best num multiplier for binary prediction\n",
    "    best_score = np.inf\n",
    "    best_num = None\n",
    "    best_oof = None\n",
    "    best_p = None\n",
    "    \n",
    "    candidates = np.linspace(0.05,5,100)\n",
    "    for num in candidates:\n",
    "        curr_oof, curr_p = pp_prob3(_oof, _p, num)\n",
    "        curr_score = balanced_log_loss(_y, curr_oof)\n",
    "        if curr_score < best_score:\n",
    "            best_num = num\n",
    "            best_score = curr_score\n",
    "            best_p = curr_p\n",
    "            best_oof = curr_oof\n",
    "    print('best num:', round(best_num, 2), '/ best score:', best_score)\n",
    "    return best_oof, best_p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-08T15:32:38.352845Z",
     "iopub.status.idle": "2023-06-08T15:32:38.353222Z",
     "shell.execute_reply": "2023-06-08T15:32:38.353059Z",
     "shell.execute_reply.started": "2023-06-08T15:32:38.353042Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.834341</td>\n",
       "      <td>0.165659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.834341</td>\n",
       "      <td>0.165659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.834341</td>\n",
       "      <td>0.165659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.834341</td>\n",
       "      <td>0.165659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.834341</td>\n",
       "      <td>0.165659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.834341  0.165659\n",
       "1  010ebe33f668  0.834341  0.165659\n",
       "2  02fa521e1838  0.834341  0.165659\n",
       "3  040e15f562a2  0.834341  0.165659\n",
       "4  046e85c7cc7f  0.834341  0.165659"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(X):\n",
    "    y = np.zeros(len(X))\n",
    "    for i in range(oof_level2_test.shape[1]):\n",
    "        # y += weights[i] * oof_level2_test[:,i]\n",
    "        y += oof_level2_test[:,i]\n",
    "    # return y / sum(weights)\n",
    "    return y / oof_level2_test.shape[1]\n",
    "\n",
    "predictions = predict(test_df[features])\n",
    "\n",
    "if CFG.adjust_class_threshold:\n",
    "    _, predictions = inflate_preds(y, np.mean(X, axis=1), predictions)\n",
    "\n",
    "test_df['class_1'] = predictions\n",
    "test_df['class_0'] = 1 - predictions\n",
    "\n",
    "sample_submission[['class_0', 'class_1']] = test_df[['class_0', 'class_1']]\n",
    "sample_submission.to_csv(r\"submission.csv\", index=False)\n",
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
