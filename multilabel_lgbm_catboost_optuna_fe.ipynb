{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:23.665663Z",
     "iopub.status.busy": "2023-06-08T15:31:23.665223Z",
     "iopub.status.idle": "2023-06-08T15:31:35.997437Z",
     "shell.execute_reply": "2023-06-08T15:31:35.996163Z",
     "shell.execute_reply.started": "2023-06-08T15:31:23.665630Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "from catboost import Pool\n",
    "import xgboost as xgb\n",
    "\n",
    "import itertools\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits, BaseShuffleSplit, _validate_shuffle_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import _num_samples, check_array\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import eli5\n",
    "from IPython.display import display\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "from colorama import Style, Fore\n",
    "\n",
    "palette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n",
    "           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n",
    "\n",
    "blk = Style.BRIGHT + Fore.BLACK\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "res = Style.RESET_ALL\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    kaggle = False\n",
    "    undersample = False\n",
    "    test = False\n",
    "    del_errs = False\n",
    "    del_outliers = True\n",
    "    \n",
    "    feature_sel = False\n",
    "    n_feature_sel_folds = 5\n",
    "    \n",
    "    n_estimators = 3000\n",
    "    early_stopping_rounds = 100\n",
    "    \n",
    "    lgbm_optimize = False\n",
    "    xgb_optimize = False\n",
    "    cb_optimize = False\n",
    "    \n",
    "    n_trials = 1000\n",
    "    n_optimize_folds = 5\n",
    "    n_optimize_repeats = 3\n",
    "    \n",
    "    stacking = True\n",
    "    n_stacking_folds = 10\n",
    "    n_stacking_models = 20\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.001085Z",
     "iopub.status.busy": "2023-06-08T15:31:35.999808Z",
     "iopub.status.idle": "2023-06-08T15:31:36.066222Z",
     "shell.execute_reply": "2023-06-08T15:31:36.064862Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.001050Z"
    }
   },
   "outputs": [],
   "source": [
    "if CFG.kaggle:\n",
    "    COMP_PATH = \"/kaggle/input/icr-identify-age-related-conditions\"\n",
    "else:\n",
    "    COMP_PATH = \"icr-identify-age-related-conditions\"\n",
    "\n",
    "train_df = pd.read_csv(f'{COMP_PATH}//train.csv')\n",
    "test_df = pd.read_csv(f'{COMP_PATH}/test.csv')\n",
    "greeks = pd.read_csv(f\"{COMP_PATH}/greeks.csv\")\n",
    "sample_submission = pd.read_csv(f\"{COMP_PATH}/sample_submission.csv\")\n",
    "\n",
    "train_df['EJ'] = train_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "test_df['EJ'] = test_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "\n",
    "train_df.columns = train_df.columns.str.replace(' ', '')\n",
    "test_df.columns = test_df.columns.str.replace(' ', '')\n",
    "\n",
    "# train_df.drop('Id',axis=1, inplace=True)\n",
    "# train_df.fillna(train_df.median(), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.069293Z",
     "iopub.status.busy": "2023-06-08T15:31:36.068506Z",
     "iopub.status.idle": "2023-06-08T15:31:36.075275Z",
     "shell.execute_reply": "2023-06-08T15:31:36.074052Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.069253Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# new_num_cols = train_df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "# train_df[new_num_cols] = scaler.fit_transform(train_df[new_num_cols])\n",
    "# test_df[new_num_cols] = scaler.transform(test_df[new_num_cols])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force Feature Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine features in all possible ways."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log features (preserve sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in features:\n",
    "#     train_df[f] = np.sign(train_df[f]) * np.log1p(np.abs(train_df[f])) # no significant result for LGBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_outliers = [fe for fe in train_df.columns if fe not in ['BN', 'BQ', 'CW', 'EL', 'GH', \n",
    "                                                                      'GI', 'GL', 'Id', 'Class', 'EJ']]\n",
    "\n",
    "if CFG.del_outliers:\n",
    "    for f in features_with_outliers:\n",
    "        train_df[f] = train_df[f].clip(upper=train_df[f].quantile(0.99))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete erroneus objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.del_errs:\n",
    "    err_objs = [292, 102, 509, 367, 313, 462, 556]\n",
    "    train_df = train_df.loc[[i for i in train_df.index if i not in err_objs], :].reset_index(drop=True)\n",
    "    greeks = greeks.loc[[i for i in greeks.index if i not in err_objs], :].reset_index(drop=True)\n",
    "\n",
    "class_imbalance = train_df[train_df['Class'] == 0].shape[0] / train_df[train_df['Class'] == 1].shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.impute import KNNImputer\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "# train_df['BQ'] = train_df['BQ'].fillna(train_df['BQ'].min())\n",
    "# train_df['EL'] = train_df['EL'].fillna(train_df['EL'].mode()[0])\n",
    "\n",
    "\n",
    "# features = [fe for fe in train_df.columns if fe not in ['Id','Class']]\n",
    "\n",
    "# def cosine_dist(X, Y, metric='cosine', missing_values=np.nan, **kwargs):\n",
    "#     X[np.isnan(X)]=0\n",
    "#     Y[np.isnan(Y)]=0\n",
    "#     return pairwise_distances(X=X.reshape(-1, 1), \n",
    "#                               Y=Y.reshape(-1, 1), \n",
    "#                               metric='cosine').sum()\n",
    "\n",
    "# imputer = KNNImputer(n_neighbors=5, metric=cosine_dist)\n",
    "# imputer.fit_transform(train_df[features])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.080972Z",
     "iopub.status.busy": "2023-06-08T15:31:36.079281Z",
     "iopub.status.idle": "2023-06-08T15:31:44.412385Z",
     "shell.execute_reply": "2023-06-08T15:31:44.411508Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.080912Z"
    }
   },
   "outputs": [],
   "source": [
    "# features = train_df.drop(['Class', 'Id'], axis=1).columns\n",
    "\n",
    "# features = [fe for fe in train_df.columns if fe not in ['CF', 'CB', 'DV', 'BR', 'DF', 'GB', 'AH', \n",
    "#                                                         'CW', 'CL', 'BP', 'BD', 'FC', 'GE', 'GF',\n",
    "#                                                         'AR', 'GI', 'Id', 'Class', 'AX']]\n",
    "\n",
    "# def gen_features(features, df):\n",
    "#     generated_features = pd.DataFrame()\n",
    "\n",
    "#     for fe_a, fe_b in tqdm(itertools.combinations(features, 2), total=sum([1 for i in itertools.combinations(features, 2)])):\n",
    "\n",
    "# #         generated_features[f'{fe_a}_2']        = df[fe_a].pow(2)\n",
    "# #         generated_features[f'{fe_b}_2']        = df[fe_b].pow(2)\n",
    "# #         generated_features[f'{fe_a}*{fe_b}_2'] = df[fe_a] * df[fe_b].pow(2)\n",
    "# #         generated_features[f'{fe_a}_2*{fe_b}'] = df[fe_a].pow(2) * df[fe_b]\n",
    "\n",
    "# #         generated_features[f'{fe_a}_05'] = df[fe_a].pow(0.5)\n",
    "# #         generated_features[f'{fe_b}_05'] = df[fe_b].pow(0.5)\n",
    "# #         generated_features[f'{fe_a}*{fe_b}_05'] = df[fe_a] * df[fe_b].pow(0.5)\n",
    "# #         generated_features[f'{fe_a}_05*{fe_b}'] = df[fe_a].pow(0.5) * df[fe_b]\n",
    "\n",
    "# #         generated_features[f'{fe_a}_log'] = np.log(df[fe_a])\n",
    "# #         generated_features[f'{fe_b}_log'] = np.log(df[fe_b])\n",
    "# #         generated_features[f'{fe_a}*{fe_b}_log'] = df[fe_a] * np.log(df[fe_b])\n",
    "# #         generated_features[f'{fe_a}_log*{fe_b}'] = np.log(df[fe_a]) * df[fe_b]\n",
    "        \n",
    "#     generated_features = generated_features[selected]\n",
    "#     generated_features = pd.concat([generated_features, df[features]], axis=1)\n",
    "    \n",
    "#     # prevent inf\n",
    "#     for g in generated_features.columns:\n",
    "#         generated_features[g] = np.minimum(np.maximum(generated_features[g], -1e9), 1e9)\n",
    "    \n",
    "#     return generated_features\n",
    "\n",
    "# generated_features_train = gen_features(features, train_df)\n",
    "# generated_features_test = gen_features(features, test_df)\n",
    "\n",
    "# features = generated_features_train.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "\n",
    "# features = train_df.drop(['Class', 'Id'], axis=1).columns\n",
    "\n",
    "# # average label of 20 Nearest Neighbours (colsine distance)\n",
    "# knn = NearestNeighbors(n_neighbors=10, metric='cosine', n_jobs=-1)\n",
    "# knn.fit(train_df[features].fillna(0))\n",
    "\n",
    "# # train\n",
    "# dists, nears = knn.kneighbors(train_df[features].fillna(0), return_distance=True)\n",
    "# dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# train_df['class_cos'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# train_df['class_cos'] = train_df['class_cos'].astype(float)\n",
    "\n",
    "# # test\n",
    "# dists, nears = knn.kneighbors(test_df[features].fillna(0), return_distance=True)\n",
    "# dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# test_df['class_cos'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# test_df['class_cos'] = test_df['class_cos'].astype(float)\n",
    "\n",
    "features = [fe for fe in train_df.columns if fe not in ['CF', 'CB', 'DV', 'BR', 'DF', 'GB', 'AH', \n",
    "                                                        'CW', 'CL', 'BP', 'BD', 'FC', 'GE', 'GF',\n",
    "                                                        'AR', 'GI', 'Id', 'Class', 'AX']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:44.414098Z",
     "iopub.status.busy": "2023-06-08T15:31:44.413784Z",
     "iopub.status.idle": "2023-06-08T15:31:44.461531Z",
     "shell.execute_reply": "2023-06-08T15:31:44.460184Z",
     "shell.execute_reply.started": "2023-06-08T15:31:44.414071Z"
    }
   },
   "outputs": [],
   "source": [
    "def IterativeStratification(labels, r, random_state):\n",
    "    \"\"\"This function implements the Iterative Stratification algorithm described\n",
    "    in the following paper:\n",
    "    Sechidis K., Tsoumakas G., Vlahavas I. (2011) On the Stratification of\n",
    "    Multi-Label Data. In: Gunopulos D., Hofmann T., Malerba D., Vazirgiannis M.\n",
    "    (eds) Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n",
    "    2011. Lecture Notes in Computer Science, vol 6913. Springer, Berlin,\n",
    "    Heidelberg.\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = labels.shape[0]\n",
    "    test_folds = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    # Calculate the desired number of examples at each subset\n",
    "    c_folds = r * n_samples\n",
    "\n",
    "    # Calculate the desired number of examples of each label at each subset\n",
    "    c_folds_labels = np.outer(r, labels.sum(axis=0))\n",
    "\n",
    "    labels_not_processed_mask = np.ones(n_samples, dtype=bool)\n",
    "\n",
    "    while np.any(labels_not_processed_mask):\n",
    "        # Find the label with the fewest (but at least one) remaining examples,\n",
    "        # breaking ties randomly\n",
    "        num_labels = labels[labels_not_processed_mask].sum(axis=0)\n",
    "\n",
    "        # Handle case where only all-zero labels are left by distributing\n",
    "        # across all folds as evenly as possible (not in original algorithm but\n",
    "        # mentioned in the text). (By handling this case separately, some\n",
    "        # code redundancy is introduced; however, this approach allows for\n",
    "        # decreased execution time when there are a relatively large number\n",
    "        # of all-zero labels.)\n",
    "        if num_labels.sum() == 0:\n",
    "            sample_idxs = np.where(labels_not_processed_mask)[0]\n",
    "\n",
    "            for sample_idx in sample_idxs:\n",
    "                fold_idx = np.where(c_folds == c_folds.max())[0]\n",
    "\n",
    "                if fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(fold_idx.shape[0])]\n",
    "\n",
    "                test_folds[sample_idx] = fold_idx\n",
    "                c_folds[fold_idx] -= 1\n",
    "\n",
    "            break\n",
    "\n",
    "        label_idx = np.where(num_labels == num_labels[np.nonzero(num_labels)].min())[0]\n",
    "        if label_idx.shape[0] > 1:\n",
    "            label_idx = label_idx[random_state.choice(label_idx.shape[0])]\n",
    "\n",
    "        sample_idxs = np.where(np.logical_and(labels[:, label_idx].flatten(), labels_not_processed_mask))[0]\n",
    "\n",
    "        for sample_idx in sample_idxs:\n",
    "            # Find the subset(s) with the largest number of desired examples\n",
    "            # for this label, breaking ties by considering the largest number\n",
    "            # of desired examples, breaking further ties randomly\n",
    "            label_folds = c_folds_labels[:, label_idx]\n",
    "            fold_idx = np.where(label_folds == label_folds.max())[0]\n",
    "\n",
    "            if fold_idx.shape[0] > 1:\n",
    "                temp_fold_idx = np.where(c_folds[fold_idx] ==\n",
    "                                         c_folds[fold_idx].max())[0]\n",
    "                fold_idx = fold_idx[temp_fold_idx]\n",
    "\n",
    "                if temp_fold_idx.shape[0] > 1:\n",
    "                    fold_idx = fold_idx[random_state.choice(temp_fold_idx.shape[0])]\n",
    "\n",
    "            test_folds[sample_idx] = fold_idx\n",
    "            labels_not_processed_mask[sample_idx] = False\n",
    "\n",
    "            # Update desired number of examples\n",
    "            c_folds_labels[fold_idx, labels[sample_idx]] -= 1\n",
    "            c_folds[fold_idx] -= 1\n",
    "\n",
    "    return test_folds\n",
    "\n",
    "\n",
    "class MultilabelStratifiedKFold(_BaseKFold):\n",
    "    \"\"\"Multilabel stratified K-Folds cross-validator\n",
    "    Provides train/test indices to split multilabel data into train/test sets.\n",
    "    This cross-validation object is a variation of KFold that returns\n",
    "    stratified folds for multilabel data. The folds are made by preserving\n",
    "    the percentage of samples for each label.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=3\n",
    "        Number of folds. Must be at least 2.\n",
    "    shuffle : boolean, optional\n",
    "        Whether to shuffle each stratification of the data before splitting\n",
    "        into batches.\n",
    "    random_state : int, RandomState instance or None, optional, default=None\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedKFold that only uses random_state\n",
    "        when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> mskf = MultilabelStratifiedKFold(n_splits=2, random_state=0)\n",
    "    >>> mskf.get_n_splits(X, y)\n",
    "    2\n",
    "    >>> print(mskf)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    MultilabelStratifiedKFold(n_splits=2, random_state=0, shuffle=False)\n",
    "    >>> for train_index, test_index in mskf.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different in each fold.\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedMultilabelStratifiedKFold: Repeats Multilabel Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=3, *, shuffle=False, random_state=None):\n",
    "        super(MultilabelStratifiedKFold, self).__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def _make_test_folds(self, X, y):\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(type_of_target_y))\n",
    "\n",
    "        num_samples = y.shape[0]\n",
    "\n",
    "        rng = check_random_state(self.random_state)\n",
    "        indices = np.arange(num_samples)\n",
    "\n",
    "        if self.shuffle:\n",
    "            rng.shuffle(indices)\n",
    "            y = y[indices]\n",
    "\n",
    "        r = np.asarray([1 / self.n_splits] * self.n_splits)\n",
    "\n",
    "        test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "        return test_folds[np.argsort(indices)]\n",
    "\n",
    "    def _iter_test_masks(self, X=None, y=None, groups=None):\n",
    "        test_folds = self._make_test_folds(X, y)\n",
    "        for i in range(self.n_splits):\n",
    "            yield test_folds == i\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedKFold, self).split(X, y, groups)\n",
    "\n",
    "\n",
    "class RepeatedMultilabelStratifiedKFold(_RepeatedSplits):\n",
    "    \"\"\"Repeated Multilabel Stratified K-Fold cross validator.\n",
    "    Repeats Mulilabel Stratified K-Fold n times with different randomization\n",
    "    in each repetition.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of folds. Must be at least 2.\n",
    "    n_repeats : int, default=10\n",
    "        Number of times cross-validator needs to be repeated.\n",
    "    random_state : None, int or RandomState, default=None\n",
    "        Random state to be used to generate random state for each\n",
    "        repetition as well as randomly breaking ties within the iterative\n",
    "        stratification algorithm.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import RepeatedMultilabelStratifiedKFold\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> rmskf = RepeatedMultilabelStratifiedKFold(n_splits=2, n_repeats=2,\n",
    "    ...     random_state=0)\n",
    "    >>> for train_index, test_index in rmskf.split(X, y):\n",
    "    ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...     X_train, X_test = X[train_index], X[test_index]\n",
    "    ...     y_train, y_test = y[train_index], y[test_index]\n",
    "    ...\n",
    "    TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [0 1 4 5] TEST: [2 3 6 7]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    See also\n",
    "    --------\n",
    "    RepeatedStratifiedKFold: Repeats (Non-multilabel) Stratified K-Fold\n",
    "    n times.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits=5, *, n_repeats=10, random_state=None):\n",
    "        super(RepeatedMultilabelStratifiedKFold, self).__init__(\n",
    "            MultilabelStratifiedKFold, n_repeats=n_repeats, random_state=random_state,\n",
    "            n_splits=n_splits)\n",
    "\n",
    "\n",
    "class MultilabelStratifiedShuffleSplit(BaseShuffleSplit):\n",
    "    \"\"\"Multilabel Stratified ShuffleSplit cross-validator\n",
    "    Provides train/test indices to split data into train/test sets.\n",
    "    This cross-validation object is a merge of MultilabelStratifiedKFold and\n",
    "    ShuffleSplit, which returns stratified randomized folds for multilabel\n",
    "    data. The folds are made by preserving the percentage of each label.\n",
    "    Note: like the ShuffleSplit strategy, multilabel stratified random splits\n",
    "    do not guarantee that all folds will be different, although this is\n",
    "    still very likely for sizeable datasets.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default 10\n",
    "        Number of re-shuffling & splitting iterations.\n",
    "    test_size : float, int, None, optional\n",
    "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
    "        of the dataset to include in the test split. If int, represents the\n",
    "        absolute number of test samples. If None, the value is set to the\n",
    "        complement of the train size. By default, the value is set to 0.1.\n",
    "        The default will change in version 0.21. It will remain 0.1 only\n",
    "        if ``train_size`` is unspecified, otherwise it will complement\n",
    "        the specified ``train_size``.\n",
    "    train_size : float, int, or None, default is None\n",
    "        If float, should be between 0.0 and 1.0 and represent the\n",
    "        proportion of the dataset to include in the train split. If\n",
    "        int, represents the absolute number of train samples. If None,\n",
    "        the value is automatically set to the complement of the test size.\n",
    "    random_state : int, RandomState instance or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`. Unlike StratifiedShuffleSplit that only uses\n",
    "        random_state when ``shuffle`` == True, this multilabel implementation\n",
    "        always uses the random_state since the iterative stratification\n",
    "        algorithm breaks ties randomly.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "    >>> y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "    >>> msss = MultilabelStratifiedShuffleSplit(n_splits=3, test_size=0.5,\n",
    "    ...    random_state=0)\n",
    "    >>> msss.get_n_splits(X, y)\n",
    "    3\n",
    "    >>> print(mss)       # doctest: +ELLIPSIS\n",
    "    MultilabelStratifiedShuffleSplit(n_splits=3, random_state=0, test_size=0.5,\n",
    "                                     train_size=None)\n",
    "    >>> for train_index, test_index in msss.split(X, y):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
    "    TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n",
    "    TRAIN: [1 2 5 6] TEST: [0 3 4 7]\n",
    "    Notes\n",
    "    -----\n",
    "    Train and test sizes may be slightly different from desired due to the\n",
    "    preference of stratification over perfectly sized folds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=10, *, test_size=\"default\", train_size=None,\n",
    "                 random_state=None):\n",
    "        super(MultilabelStratifiedShuffleSplit, self).__init__(\n",
    "            n_splits=n_splits, test_size=test_size, train_size=train_size, random_state=random_state)\n",
    "\n",
    "    def _iter_indices(self, X, y, groups=None):\n",
    "        n_samples = _num_samples(X)\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        y = np.asarray(y, dtype=bool)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "\n",
    "        if type_of_target_y != 'multilabel-indicator':\n",
    "            raise ValueError(\n",
    "                'Supported target type is: multilabel-indicator. Got {!r} instead.'.format(\n",
    "                    type_of_target_y))\n",
    "\n",
    "        n_train, n_test = _validate_shuffle_split(n_samples, self.test_size,\n",
    "                                                  self.train_size)\n",
    "\n",
    "        n_samples = y.shape[0]\n",
    "        rng = check_random_state(self.random_state)\n",
    "        y_orig = y.copy()\n",
    "\n",
    "        r = np.array([n_train, n_test]) / (n_train + n_test)\n",
    "\n",
    "        for _ in range(self.n_splits):\n",
    "            indices = np.arange(n_samples)\n",
    "            rng.shuffle(indices)\n",
    "            y = y_orig[indices]\n",
    "\n",
    "            test_folds = IterativeStratification(labels=y, r=r, random_state=rng)\n",
    "\n",
    "            test_idx = test_folds[np.argsort(indices)] == 1\n",
    "            test = np.where(test_idx)[0]\n",
    "            train = np.where(~test_idx)[0]\n",
    "\n",
    "            yield train, test\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "            Note that providing ``y`` is sufficient to generate the splits and\n",
    "            hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
    "            ``X`` instead of actual training data.\n",
    "        y : array-like, shape (n_samples, n_labels)\n",
    "            The target variable for supervised learning problems.\n",
    "            Multilabel stratification is done based on the y labels.\n",
    "        groups : object\n",
    "            Always ignored, exists for compatibility.\n",
    "        Returns\n",
    "        -------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        Notes\n",
    "        -----\n",
    "        Randomized CV splitters may return different results for each call of\n",
    "        split. You can make the results identical by setting ``random_state``\n",
    "        to an integer.\n",
    "        \"\"\"\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        return super(MultilabelStratifiedShuffleSplit, self).split(X, y, groups)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:41.223344Z",
     "iopub.status.busy": "2023-06-08T15:32:41.222954Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not CFG.kaggle:\n",
    "\n",
    "    from shaphypetune import BoostBoruta\n",
    "\n",
    "    params = {\n",
    "                'n_estimators': CFG.n_estimators,\n",
    "                'early_stopping_round': CFG.early_stopping_rounds,\n",
    "                'objective': 'binary',\n",
    "                'metric': 'logloss', \n",
    "                'n_jobs': -1,\n",
    "                'is_unbalance':True, \n",
    "                'verbose': -1,\n",
    "                'seed': 19062023,\n",
    "            }\n",
    "\n",
    "    def balanced_log_loss(y_true, y_pred):\n",
    "\n",
    "        # Nc is the number of observations\n",
    "        N_1 = np.sum(y_true == 1, axis=0)\n",
    "        N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "        # In order to avoid the extremes of the log function, each predicted probability 𝑝 is replaced with max(min(𝑝,1−10−15),10−15)\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "        # balanced logarithmic loss\n",
    "        loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1 - y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "        return loss_numerator / 2\n",
    "\n",
    "    def bll_metric(y_true, y_pred):\n",
    "        return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "    def calc_log_loss_weight(y_true): \n",
    "        '''w0, w1 assign different weights to individual data points during training.'''\n",
    "        nc = np.bincount(y_true)\n",
    "        w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "        return w0, w1\n",
    "\n",
    "    def lgbm_tuning(features, permut=False, boruta=False):\n",
    "        metric = balanced_log_loss\n",
    "        eval_results_ = {}\n",
    "\n",
    "        cv_scores = [] # store all cv scores of outer loop inference\n",
    "\n",
    "        perm_df_ = pd.DataFrame()\n",
    "        feature_importances_ = pd.DataFrame()\n",
    "        boruta_df_ = pd.DataFrame()\n",
    "        \n",
    "        for i in range(CFG.n_optimize_repeats):\n",
    "            print(f'Repeat {blu}#{i+1}')\n",
    "            \n",
    "            # Make random under-sampling to balance classes\n",
    "            positive_count_train = train_df['Class'].value_counts()[1]\n",
    "            sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                            1: positive_count_train}, \n",
    "                                        random_state=15062023+i, \n",
    "                                        replacement=True)\n",
    "\n",
    "            X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "            \n",
    "            if CFG.undersample:\n",
    "                X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "            \n",
    "            # Create Stratified Multilabel k-Fold scheme\n",
    "            kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=8062023+i)\n",
    "\n",
    "            # Create an oof array for inner loop\n",
    "            oof = np.zeros(X_re.shape[0])\n",
    "            \n",
    "            # Stratify based on Class and Alpha (3 types of conditions)\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start = 1): \n",
    "                X, y = X_re[features], y_re\n",
    "\n",
    "                # Split the dataset according to the fold indexes.\n",
    "                X_train = X.iloc[train_idx]\n",
    "                X_val = X.iloc[val_idx]\n",
    "                y_train = y.iloc[train_idx]\n",
    "                y_val = y.iloc[val_idx]\n",
    "\n",
    "\n",
    "                X_train = X_train.reset_index(drop=True)\n",
    "                y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "                # Store models here\n",
    "                models_ = [] \n",
    "\n",
    "                eval_results_[fold]= {}\n",
    "\n",
    "                clf = lgb.LGBMClassifier(**params)\n",
    "                clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                        eval_metric=bll_metric, # eval_sample_weight=w_val, \n",
    "                        verbose=1)\n",
    "\n",
    "                models_.append(clf)\n",
    "\n",
    "                val_preds = clf.predict_proba(X_val)[:,1]\n",
    "                oof[val_idx] = val_preds\n",
    "\n",
    "                val_score = metric(y_val, val_preds)\n",
    "                best_iter = clf.best_iteration_\n",
    "\n",
    "                print(f'Fold: {blu}{fold:>3}{res}| {metric.__name__}: {blu}{val_score:.5f}{res}'\n",
    "                    f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "\n",
    "                # permutation importance\n",
    "                if permut:\n",
    "                    perm = PermutationImportance(clf, scoring=None, n_iter=1, \n",
    "                                                random_state=42, cv=None, refit=False).fit(X_val, y_val)\n",
    "\n",
    "                    perm_importance_df = pd.DataFrame({'importance': perm.feature_importances_}, \n",
    "                                                    index=X_val.columns).sort_index()\n",
    "\n",
    "                    if perm_df_.shape[0] == 0:\n",
    "                        perm_df_ = perm_importance_df.copy()\n",
    "                    else:\n",
    "                        perm_df_ += perm_importance_df\n",
    "\n",
    "                # tree feature importance\n",
    "                f_i = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns), \n",
    "                                                reverse=True, key=lambda x: x[1]), \n",
    "                                columns=['Value','Feature'])\n",
    "\n",
    "                if feature_importances_.shape[0] == 0:\n",
    "                    feature_importances_ = f_i.copy()\n",
    "                else:\n",
    "\n",
    "                    feature_importances_['Value'] += f_i['Value']\n",
    "\n",
    "                # Boruta SHAP importance\n",
    "                if boruta:\n",
    "                    model = BoostBoruta(clf, importance_type='shap_importances', train_importance=False)\n",
    "                    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                            eval_metric=bll_metric, early_stopping_rounds=300, verbose=-1)\n",
    "\n",
    "                    boruta_importance_df = pd.DataFrame({'importance': model.ranking_}, \n",
    "                                                        index=X_train.columns).sort_index()\n",
    "                    if boruta_df_.shape[0] == 0:\n",
    "                        boruta_df_ = boruta_importance_df.copy()\n",
    "                    else:\n",
    "                        boruta_df_ += boruta_importance_df\n",
    "\n",
    "            fold_cv_score = metric(y_re, oof)\n",
    "            print(f'{red} CV score: {res} {metric.__name__}: {red}{fold_cv_score:.5f}{res}')\n",
    "            print(f'{\"*\" * 50}\\n')\n",
    "            cv_scores.append(fold_cv_score)\n",
    "\n",
    "\n",
    "        print(f'{red} Avg score {CFG.n_feature_sel_folds}-fold: {res} {metric.__name__}: {red}{np.mean(cv_scores):.5f}{res}')\n",
    "        print(f'{\"*\" * 50}\\n')\n",
    "        \n",
    "        if permut:\n",
    "            perm_df_ = perm_df_.sort_values('importance', ascending=False)\n",
    "            \n",
    "        if boruta:\n",
    "            boruta_df_ = boruta_df_.sort_values('importance')\n",
    "                                        \n",
    "        feature_importances_ = feature_importances_.sort_values('Value', ascending=False)\n",
    "        \n",
    "        return perm_df_, feature_importances_, boruta_df_, np.mean(cv_scores)\n",
    "\n",
    "    if CFG.feature_sel:\n",
    "        perm_df_, feature_importances_, boruta_df_, cv_scores = lgbm_tuning(features, permut=False, boruta=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check features correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    col = 'BZ'\n",
    "    x = train_df[train_df[col] <= train_df[col].quantile(0.99)]\n",
    "    cm = x[[c for c in train_df.columns if c not in ['Id', 'Class']]].corr()\n",
    "    display(np.abs(cm[col]).sort_values(ascending=False)[1:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.619184Z",
     "iopub.status.busy": "2023-06-08T15:32:11.618864Z",
     "iopub.status.idle": "2023-06-08T15:32:11.652915Z",
     "shell.execute_reply": "2023-06-08T15:32:11.652069Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.619157Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    perm_df_.to_csv('perm_df.csv')\n",
    "    perm_df_\n",
    "    perm_cols = set(perm_df_.index[-35:])\n",
    "    display(perm_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze tree gain feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.654626Z",
     "iopub.status.busy": "2023-06-08T15:32:11.654102Z",
     "iopub.status.idle": "2023-06-08T15:32:11.669674Z",
     "shell.execute_reply": "2023-06-08T15:32:11.668840Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.654583Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    feature_importances_.to_csv('feature_importances.csv')\n",
    "    feature_importances_\n",
    "    fi_cols = set(feature_importances_['Feature'].values[-23:])\n",
    "    display(fi_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze BORUTA importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    boruta_df_.to_csv('boruta_df_.csv')\n",
    "    boruta_df_\n",
    "    boruta_cols = set(boruta_df_.index[-35:])\n",
    "    display(boruta_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability 𝑝 is replaced with max(min(𝑝,1−10−15),10−15)\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1 - y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2\n",
    "\n",
    "def bll_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def calc_log_loss_weight(y_true): \n",
    "    '''w0, w1 assign different weights to individual data points during training.'''\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    return w0, w1\n",
    "\n",
    "X, y = train_df[features], train_df['Class'] \n",
    "    \n",
    "def objective(trial):\n",
    "    param = {\n",
    "        # Main parameters\n",
    "#                     'device': 'gpu',\n",
    "#                     'gpu_platform_id': 0,\n",
    "#                     'gpu_device_id': 0,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'none',\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['goss', 'gbdt']),#, 'dart']),   \n",
    "        # Hyperparamters (in order of importance decreasing)\n",
    "        'n_estimators': CFG.n_estimators, # trial.suggest_int('n_estimators', 500, 1500),  # max number of trees in model\n",
    "        'early_stopping_round': CFG.early_stopping_rounds, \n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 3e-1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True), # L1,  alias: lambda_l1\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True), # L2, alias: lambda_l2\n",
    "         # decrease to deal with overfit\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),   # tree max depth \n",
    "         # decrease to deal with overfit\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 128),  # Max number of leaves in one tree\n",
    "                                                                # should be ~ 2**(max_depth-1)\n",
    "        'subsample': None, # Randomly select part of data without \n",
    "                                  # resampling if subsample < 1.0\n",
    "                                  # alias: bagging_fraction\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.7), # Randomly select a subset of features \n",
    "                                                                   # if colsample_bytree < 1.0\n",
    "                                                                   # alias:feature_fraction\n",
    "        # decrease to deal with overfit\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                             # aliases: min_data_in_leaf, \n",
    "        # increase for accuracy, decrease to deal with overfit\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255), # Max number of bins that feature values will be bucketed in\n",
    "        # increase to deal with overfit\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 1, 7), # Perform bagging at every k iteration, alias: bagging_freq\n",
    "\n",
    "#           'subsample_for_bin': 200000, # Number of data that sampled to construct feature discrete bins; setting this \n",
    "                                     # to larger value will give better training result but may increase train time \n",
    "#           'cat_smooth': trial.suggest_float('cat_smooth', 10.0, 100.0),  # this can reduce the effect of noises in \n",
    "                                                                       # categorical features, especially for \n",
    "                                                                       # categories with few data\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    if not CFG.undersample:\n",
    "        param['is_unbalance'] = True\n",
    "        # row_dict['scale_pos_weight'] = class_imbalance\n",
    "    \n",
    "    if param['boosting_type'] != 'goss':\n",
    "        param['subsample'] = trial.suggest_float('subsample', 0.3, 0.7)\n",
    "\n",
    "    bll_list = list()\n",
    "    \n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under-sampling to balance classes\n",
    "        positive_count_train = train_df['Class'].value_counts()[1]\n",
    "        sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                        1: positive_count_train}, \n",
    "                                     random_state=15062023+i, \n",
    "                                     replacement=True)\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "            dvalid = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "            # Add a callback for pruning\n",
    "#             pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'balanced_log_loss')\n",
    "\n",
    "            gbm = lgb.train(\n",
    "                param, dtrain, valid_sets=[dvalid], # callbacks=[pruning_callback], \n",
    "                feval=bll_metric, verbose_eval=-1\n",
    "            )\n",
    "\n",
    "            val_preds = gbm.predict(X_val)\n",
    "            oof[val_idx] = val_preds\n",
    "        bll_list.append(balanced_log_loss(y_re, oof))\n",
    "\n",
    "    return np.mean(bll_list)\n",
    "            \n",
    "\n",
    "if CFG.lgbm_optimize:\n",
    "#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df.to_csv(f'optuna_lgbm.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LGBM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if CFG.kaggle:\n",
    "    param_list = glob.glob(\"/kaggle/input/icr-lgbm-optuna/optuna_lgbm.csv\")\n",
    "else:\n",
    "    param_list = glob.glob(\"optuna_lgbm.csv\")\n",
    "\n",
    "models = list()\n",
    "best_lgbm_params = list()\n",
    "\n",
    "lgbm_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if lgbm_params.shape[0] == 0:\n",
    "        lgbm_params = tmp\n",
    "    else:\n",
    "        lgbm_params = pd.concat([lgbm_params, tmp])\n",
    "        \n",
    "lgbm_params = lgbm_params.sort_values('value').head(CFG.n_stacking_models)\n",
    "param_cols = [c for c in lgbm_params.columns if c.startswith('params_')]\n",
    "lgbm_params = lgbm_params[param_cols]\n",
    "\n",
    "for idx, row in lgbm_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['objective'] = 'binary'\n",
    "    row_dict['metric'] = 'none'\n",
    "#     row_dict['subsample_for_bin'] = 300000\n",
    "    row_dict['force_col_wise'] = False\n",
    "    row_dict['n_estimators'] = CFG.n_estimators\n",
    "    row_dict['early_stopping_round'] = CFG.early_stopping_rounds\n",
    "    row_dict['boosting_type'] = 'goss'\n",
    "    row_dict['verbose'] = -1\n",
    "    row_dict['max_bin'] = 255\n",
    "    \n",
    "    row_dict['num_leaves'] = int(row_dict['num_leaves'])\n",
    "    row_dict['max_depth'] = int(row_dict['max_depth'])\n",
    "    row_dict['min_data_in_leaf'] = int(row_dict['min_data_in_leaf'])\n",
    "    row_dict['bagging_freq'] = int(row_dict['bagging_freq'])\n",
    "    row_dict['learning_rate'] = 0.06433232950390658 # float(row_dict['learning_rate'])\n",
    "    \n",
    "    if not CFG.undersample:\n",
    "        row_dict['is_unbalance'] = True\n",
    "        row_dict['class_weight'] = 'balanced'\n",
    "        # row_dict['scale_pos_weight'] = class_imbalance\n",
    "    \n",
    "    if row_dict['boosting_type'] == 'goss':\n",
    "        row_dict['subsample'] = None\n",
    "        \n",
    "    best_lgbm_params.append(row_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.test:\n",
    "    best_lgbm_params = [{\n",
    "            'n_estimators': CFG.n_estimators,\n",
    "            'early_stopping_round': CFG.early_stopping_rounds,\n",
    "            'objective': 'binary',\n",
    "            'metric': 'logloss', \n",
    "            'n_jobs': -1,\n",
    "            'is_unbalance':True, \n",
    "            'verbose': -1,\n",
    "            'seed': 19062023,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.672883Z",
     "iopub.status.busy": "2023-06-08T15:32:11.672350Z",
     "iopub.status.idle": "2023-06-08T15:32:38.349383Z",
     "shell.execute_reply": "2023-06-08T15:32:38.347823Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.672854Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with \u001b[1m\u001b[34m39\u001b[0m features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9388b2a40854412fb6f733ab26e0f878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22225\u001b[0m | Best iteration: \u001b[1m\u001b[34m 380\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22313\u001b[0m | Best iteration: \u001b[1m\u001b[34m 203\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23114\u001b[0m | Best iteration: \u001b[1m\u001b[34m 205\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18902\u001b[0m | Best iteration: \u001b[1m\u001b[34m 210\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18199\u001b[0m | Best iteration: \u001b[1m\u001b[34m 346\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21874\u001b[0m | Best iteration: \u001b[1m\u001b[34m 184\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20695\u001b[0m | Best iteration: \u001b[1m\u001b[34m 233\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22919\u001b[0m | Best iteration: \u001b[1m\u001b[34m 207\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21432\u001b[0m | Best iteration: \u001b[1m\u001b[34m 318\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22307\u001b[0m | Best iteration: \u001b[1m\u001b[34m 225\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19600\u001b[0m | Best iteration: \u001b[1m\u001b[34m 236\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20277\u001b[0m | Best iteration: \u001b[1m\u001b[34m 248\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20534\u001b[0m | Best iteration: \u001b[1m\u001b[34m 220\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19254\u001b[0m | Best iteration: \u001b[1m\u001b[34m 240\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24238\u001b[0m | Best iteration: \u001b[1m\u001b[34m 331\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18654\u001b[0m | Best iteration: \u001b[1m\u001b[34m 192\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17452\u001b[0m | Best iteration: \u001b[1m\u001b[34m 210\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14441\u001b[0m | Best iteration: \u001b[1m\u001b[34m 392\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19920\u001b[0m | Best iteration: \u001b[1m\u001b[34m 222\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20393\u001b[0m | Best iteration: \u001b[1m\u001b[34m 248\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18264\u001b[0m | Best iteration: \u001b[1m\u001b[34m 201\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20661\u001b[0m | Best iteration: \u001b[1m\u001b[34m 213\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26098\u001b[0m | Best iteration: \u001b[1m\u001b[34m 291\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26015\u001b[0m | Best iteration: \u001b[1m\u001b[34m 349\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23256\u001b[0m | Best iteration: \u001b[1m\u001b[34m 125\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.31033\u001b[0m | Best iteration: \u001b[1m\u001b[34m 219\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24650\u001b[0m | Best iteration: \u001b[1m\u001b[34m 154\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14703\u001b[0m | Best iteration: \u001b[1m\u001b[34m 348\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27298\u001b[0m | Best iteration: \u001b[1m\u001b[34m 201\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27717\u001b[0m | Best iteration: \u001b[1m\u001b[34m  92\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21338\u001b[0m | Best iteration: \u001b[1m\u001b[34m 161\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18380\u001b[0m | Best iteration: \u001b[1m\u001b[34m 239\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19371\u001b[0m | Best iteration: \u001b[1m\u001b[34m 184\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16120\u001b[0m | Best iteration: \u001b[1m\u001b[34m 179\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29034\u001b[0m | Best iteration: \u001b[1m\u001b[34m 218\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34175\u001b[0m | Best iteration: \u001b[1m\u001b[34m  76\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19858\u001b[0m | Best iteration: \u001b[1m\u001b[34m 147\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29868\u001b[0m | Best iteration: \u001b[1m\u001b[34m 152\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23564\u001b[0m | Best iteration: \u001b[1m\u001b[34m 331\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20507\u001b[0m | Best iteration: \u001b[1m\u001b[34m 131\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25137\u001b[0m | Best iteration: \u001b[1m\u001b[34m 165\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20983\u001b[0m | Best iteration: \u001b[1m\u001b[34m 104\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23836\u001b[0m | Best iteration: \u001b[1m\u001b[34m 107\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21555\u001b[0m | Best iteration: \u001b[1m\u001b[34m 129\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25120\u001b[0m | Best iteration: \u001b[1m\u001b[34m  93\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20458\u001b[0m | Best iteration: \u001b[1m\u001b[34m 113\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22243\u001b[0m | Best iteration: \u001b[1m\u001b[34m 104\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18574\u001b[0m | Best iteration: \u001b[1m\u001b[34m 119\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21770\u001b[0m | Best iteration: \u001b[1m\u001b[34m 110\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26630\u001b[0m | Best iteration: \u001b[1m\u001b[34m  74\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20313\u001b[0m | Best iteration: \u001b[1m\u001b[34m  93\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18252\u001b[0m | Best iteration: \u001b[1m\u001b[34m 122\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19720\u001b[0m | Best iteration: \u001b[1m\u001b[34m 169\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20605\u001b[0m | Best iteration: \u001b[1m\u001b[34m 119\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23693\u001b[0m | Best iteration: \u001b[1m\u001b[34m 104\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21578\u001b[0m | Best iteration: \u001b[1m\u001b[34m 137\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23586\u001b[0m | Best iteration: \u001b[1m\u001b[34m  99\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23451\u001b[0m | Best iteration: \u001b[1m\u001b[34m  81\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22133\u001b[0m | Best iteration: \u001b[1m\u001b[34m 107\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21074\u001b[0m | Best iteration: \u001b[1m\u001b[34m  77\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06858\u001b[0m | Best iteration: \u001b[1m\u001b[34m 398\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06469\u001b[0m | Best iteration: \u001b[1m\u001b[34m 345\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.05926\u001b[0m | Best iteration: \u001b[1m\u001b[34m 336\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07913\u001b[0m | Best iteration: \u001b[1m\u001b[34m 278\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06356\u001b[0m | Best iteration: \u001b[1m\u001b[34m 330\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06853\u001b[0m | Best iteration: \u001b[1m\u001b[34m 350\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09074\u001b[0m | Best iteration: \u001b[1m\u001b[34m 266\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07177\u001b[0m | Best iteration: \u001b[1m\u001b[34m 398\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09114\u001b[0m | Best iteration: \u001b[1m\u001b[34m 340\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06930\u001b[0m | Best iteration: \u001b[1m\u001b[34m 377\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08570\u001b[0m | Best iteration: \u001b[1m\u001b[34m 287\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10763\u001b[0m | Best iteration: \u001b[1m\u001b[34m 313\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06124\u001b[0m | Best iteration: \u001b[1m\u001b[34m 415\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06991\u001b[0m | Best iteration: \u001b[1m\u001b[34m 313\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08710\u001b[0m | Best iteration: \u001b[1m\u001b[34m 276\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08131\u001b[0m | Best iteration: \u001b[1m\u001b[34m 279\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11099\u001b[0m | Best iteration: \u001b[1m\u001b[34m 258\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09743\u001b[0m | Best iteration: \u001b[1m\u001b[34m 287\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10623\u001b[0m | Best iteration: \u001b[1m\u001b[34m 278\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08481\u001b[0m | Best iteration: \u001b[1m\u001b[34m 300\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11529\u001b[0m | Best iteration: \u001b[1m\u001b[34m 131\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13174\u001b[0m | Best iteration: \u001b[1m\u001b[34m 198\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09663\u001b[0m | Best iteration: \u001b[1m\u001b[34m 174\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12114\u001b[0m | Best iteration: \u001b[1m\u001b[34m 178\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11142\u001b[0m | Best iteration: \u001b[1m\u001b[34m 142\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07866\u001b[0m | Best iteration: \u001b[1m\u001b[34m 289\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11094\u001b[0m | Best iteration: \u001b[1m\u001b[34m 259\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12343\u001b[0m | Best iteration: \u001b[1m\u001b[34m 119\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11696\u001b[0m | Best iteration: \u001b[1m\u001b[34m 168\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14137\u001b[0m | Best iteration: \u001b[1m\u001b[34m 100\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11246\u001b[0m | Best iteration: \u001b[1m\u001b[34m 140\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11788\u001b[0m | Best iteration: \u001b[1m\u001b[34m 130\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13097\u001b[0m | Best iteration: \u001b[1m\u001b[34m 151\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10180\u001b[0m | Best iteration: \u001b[1m\u001b[34m 175\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08697\u001b[0m | Best iteration: \u001b[1m\u001b[34m 196\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10943\u001b[0m | Best iteration: \u001b[1m\u001b[34m 139\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13088\u001b[0m | Best iteration: \u001b[1m\u001b[34m 173\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11299\u001b[0m | Best iteration: \u001b[1m\u001b[34m 133\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10131\u001b[0m | Best iteration: \u001b[1m\u001b[34m 230\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12871\u001b[0m | Best iteration: \u001b[1m\u001b[34m 134\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13795\u001b[0m | Best iteration: \u001b[1m\u001b[34m 233\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17041\u001b[0m | Best iteration: \u001b[1m\u001b[34m 187\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13727\u001b[0m | Best iteration: \u001b[1m\u001b[34m 223\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16364\u001b[0m | Best iteration: \u001b[1m\u001b[34m 152\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17768\u001b[0m | Best iteration: \u001b[1m\u001b[34m 214\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15675\u001b[0m | Best iteration: \u001b[1m\u001b[34m 235\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16181\u001b[0m | Best iteration: \u001b[1m\u001b[34m 151\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14370\u001b[0m | Best iteration: \u001b[1m\u001b[34m 142\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18061\u001b[0m | Best iteration: \u001b[1m\u001b[34m 228\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17894\u001b[0m | Best iteration: \u001b[1m\u001b[34m 219\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17326\u001b[0m | Best iteration: \u001b[1m\u001b[34m 153\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17428\u001b[0m | Best iteration: \u001b[1m\u001b[34m 233\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14518\u001b[0m | Best iteration: \u001b[1m\u001b[34m 185\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19193\u001b[0m | Best iteration: \u001b[1m\u001b[34m 164\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16927\u001b[0m | Best iteration: \u001b[1m\u001b[34m 325\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17046\u001b[0m | Best iteration: \u001b[1m\u001b[34m 232\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17731\u001b[0m | Best iteration: \u001b[1m\u001b[34m 234\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15013\u001b[0m | Best iteration: \u001b[1m\u001b[34m 248\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17847\u001b[0m | Best iteration: \u001b[1m\u001b[34m 166\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17842\u001b[0m | Best iteration: \u001b[1m\u001b[34m 150\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10491\u001b[0m | Best iteration: \u001b[1m\u001b[34m 184\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09173\u001b[0m | Best iteration: \u001b[1m\u001b[34m 211\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09768\u001b[0m | Best iteration: \u001b[1m\u001b[34m 157\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09355\u001b[0m | Best iteration: \u001b[1m\u001b[34m 274\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09104\u001b[0m | Best iteration: \u001b[1m\u001b[34m 231\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08012\u001b[0m | Best iteration: \u001b[1m\u001b[34m 222\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06466\u001b[0m | Best iteration: \u001b[1m\u001b[34m 222\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09455\u001b[0m | Best iteration: \u001b[1m\u001b[34m 230\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07142\u001b[0m | Best iteration: \u001b[1m\u001b[34m 211\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08934\u001b[0m | Best iteration: \u001b[1m\u001b[34m 271\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10914\u001b[0m | Best iteration: \u001b[1m\u001b[34m 185\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08877\u001b[0m | Best iteration: \u001b[1m\u001b[34m 323\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09928\u001b[0m | Best iteration: \u001b[1m\u001b[34m 206\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08941\u001b[0m | Best iteration: \u001b[1m\u001b[34m 198\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09690\u001b[0m | Best iteration: \u001b[1m\u001b[34m 204\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09495\u001b[0m | Best iteration: \u001b[1m\u001b[34m 127\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07908\u001b[0m | Best iteration: \u001b[1m\u001b[34m 226\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07611\u001b[0m | Best iteration: \u001b[1m\u001b[34m 416\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09495\u001b[0m | Best iteration: \u001b[1m\u001b[34m 127\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07432\u001b[0m | Best iteration: \u001b[1m\u001b[34m 278\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38255\u001b[0m | Best iteration: \u001b[1m\u001b[34m  95\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.36990\u001b[0m | Best iteration: \u001b[1m\u001b[34m  45\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39407\u001b[0m | Best iteration: \u001b[1m\u001b[34m  46\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33591\u001b[0m | Best iteration: \u001b[1m\u001b[34m 114\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.35819\u001b[0m | Best iteration: \u001b[1m\u001b[34m 132\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34689\u001b[0m | Best iteration: \u001b[1m\u001b[34m 146\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38529\u001b[0m | Best iteration: \u001b[1m\u001b[34m  42\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.40346\u001b[0m | Best iteration: \u001b[1m\u001b[34m  38\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38886\u001b[0m | Best iteration: \u001b[1m\u001b[34m 136\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39255\u001b[0m | Best iteration: \u001b[1m\u001b[34m  46\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42007\u001b[0m | Best iteration: \u001b[1m\u001b[34m  51\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.40406\u001b[0m | Best iteration: \u001b[1m\u001b[34m  66\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.40346\u001b[0m | Best iteration: \u001b[1m\u001b[34m  38\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33920\u001b[0m | Best iteration: \u001b[1m\u001b[34m 115\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.36197\u001b[0m | Best iteration: \u001b[1m\u001b[34m 135\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.37059\u001b[0m | Best iteration: \u001b[1m\u001b[34m 112\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39870\u001b[0m | Best iteration: \u001b[1m\u001b[34m  87\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38273\u001b[0m | Best iteration: \u001b[1m\u001b[34m  74\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.37071\u001b[0m | Best iteration: \u001b[1m\u001b[34m 112\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39991\u001b[0m | Best iteration: \u001b[1m\u001b[34m  49\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08268\u001b[0m | Best iteration: \u001b[1m\u001b[34m 454\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09997\u001b[0m | Best iteration: \u001b[1m\u001b[34m 318\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11418\u001b[0m | Best iteration: \u001b[1m\u001b[34m 434\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08490\u001b[0m | Best iteration: \u001b[1m\u001b[34m 378\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08228\u001b[0m | Best iteration: \u001b[1m\u001b[34m 534\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09500\u001b[0m | Best iteration: \u001b[1m\u001b[34m 402\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08966\u001b[0m | Best iteration: \u001b[1m\u001b[34m 416\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09982\u001b[0m | Best iteration: \u001b[1m\u001b[34m 424\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10633\u001b[0m | Best iteration: \u001b[1m\u001b[34m 453\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09477\u001b[0m | Best iteration: \u001b[1m\u001b[34m 294\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12611\u001b[0m | Best iteration: \u001b[1m\u001b[34m 213\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12160\u001b[0m | Best iteration: \u001b[1m\u001b[34m 479\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10388\u001b[0m | Best iteration: \u001b[1m\u001b[34m 300\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09368\u001b[0m | Best iteration: \u001b[1m\u001b[34m 693\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09201\u001b[0m | Best iteration: \u001b[1m\u001b[34m 503\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10219\u001b[0m | Best iteration: \u001b[1m\u001b[34m 227\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11268\u001b[0m | Best iteration: \u001b[1m\u001b[34m 323\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09704\u001b[0m | Best iteration: \u001b[1m\u001b[34m 475\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07516\u001b[0m | Best iteration: \u001b[1m\u001b[34m 486\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08993\u001b[0m | Best iteration: \u001b[1m\u001b[34m 540\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6246598507060309, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6246598507060309\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7522707651576903e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7522707651576903e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7964370113205523e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7964370113205523e-08\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19078\u001b[0m | Best iteration: \u001b[1m\u001b[34m 254\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6068378806689372, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6068378806689372\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.538151412119281e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.538151412119281e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.841201567781372e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.841201567781372e-08\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23889\u001b[0m | Best iteration: \u001b[1m\u001b[34m  94\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6150903977071068, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6150903977071068\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.664310638314929e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.664310638314929e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0075204418283168, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0075204418283168\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18250\u001b[0m | Best iteration: \u001b[1m\u001b[34m 162\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6001560497106277, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6001560497106277\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.709506926535794e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.709506926535794e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.865875232096201e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.865875232096201e-05\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21819\u001b[0m | Best iteration: \u001b[1m\u001b[34m 110\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4949457616678508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4949457616678508\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6155016833246405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6155016833246405e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0081151338007454, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0081151338007454\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15256\u001b[0m | Best iteration: \u001b[1m\u001b[34m 153\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6088179069881259, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6088179069881259\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.303293050219396e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.303293050219396e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001336655634154, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001336655634154\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18794\u001b[0m | Best iteration: \u001b[1m\u001b[34m 146\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5288974232551956, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5288974232551956\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.27322014998632e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.27322014998632e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001480696470031, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001480696470031\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20163\u001b[0m | Best iteration: \u001b[1m\u001b[34m 185\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5508612953001655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508612953001655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.935044119726908e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.935044119726908e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0010643779594581, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010643779594581\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21086\u001b[0m | Best iteration: \u001b[1m\u001b[34m 103\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] feature_fraction is set=0.518763379157297, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.518763379157297\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4279459922382534e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4279459922382534e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.457907852244724e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.457907852244724e-05\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20229\u001b[0m | Best iteration: \u001b[1m\u001b[34m 116\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6194170869456598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6194170869456598\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2238557923503e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2238557923503e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0044521732783548, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0044521732783548\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18183\u001b[0m | Best iteration: \u001b[1m\u001b[34m 122\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.511279218172116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.511279218172116\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8484453731934468e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8484453731934468e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001454687537519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001454687537519\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14552\u001b[0m | Best iteration: \u001b[1m\u001b[34m 152\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3700160061529473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3700160061529473\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.4808900057624336e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.4808900057624336e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.667715087832313e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.667715087832313e-06\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21555\u001b[0m | Best iteration: \u001b[1m\u001b[34m 151\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5324680203813787, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5324680203813787\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7477628916919897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7477628916919897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001946386713123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001946386713123\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18736\u001b[0m | Best iteration: \u001b[1m\u001b[34m 150\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3758190441185572, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.3758190441185572\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.41496232873838e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.41496232873838e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5968329050885574e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5968329050885574e-08\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22221\u001b[0m | Best iteration: \u001b[1m\u001b[34m 108\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5554950793890557, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5554950793890557\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.851263586392904e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.851263586392904e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.806564821200964e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.806564821200964e-08\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20095\u001b[0m | Best iteration: \u001b[1m\u001b[34m 170\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.596529533507711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.596529533507711\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3646337855571897e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3646337855571897e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.181846710983762e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.181846710983762e-06\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17207\u001b[0m | Best iteration: \u001b[1m\u001b[34m 163\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4795187637817097, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4795187637817097\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.763924644936586e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.763924644936586e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0529539750398388, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0529539750398388\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21893\u001b[0m | Best iteration: \u001b[1m\u001b[34m 147\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=17, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=17\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952064641566988, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952064641566988\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.487970823983076e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.487970823983076e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.171051202505303e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.171051202505303e-06\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14443\u001b[0m | Best iteration: \u001b[1m\u001b[34m 223\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5871468389445917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5871468389445917\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.4489915641012655e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.4489915641012655e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.265958128288523e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.265958128288523e-05\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20070\u001b[0m | Best iteration: \u001b[1m\u001b[34m 122\u001b[0m\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5898692915854895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5898692915854895\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.568212546244471e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.568212546244471e-06\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.5475491423727646e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.5475491423727646e-08\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18153\u001b[0m | Best iteration: \u001b[1m\u001b[34m 194\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def lgbm_training():\n",
    "    # Make random under-sampling to balance classes\n",
    "    positive_count_train = train_df['Class'].value_counts()[1]\n",
    "    sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                    1: positive_count_train}, \n",
    "                                 random_state=150620231, \n",
    "                                 replacement=True)\n",
    "\n",
    "    X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "\n",
    "    if CFG.undersample:\n",
    "        X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "    \n",
    "    kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=80620231)\n",
    "\n",
    "    oof_level2 = np.zeros([y_re.shape[0], len(best_lgbm_params) + 1])\n",
    "    oof_level2[:, len(best_lgbm_params)] = y_re\n",
    "    oof_level2_test = np.zeros([test_df.shape[0], len(best_lgbm_params)])\n",
    "\n",
    "    print(f\"Training with {blu}{len(features)}{res} features\")\n",
    "\n",
    "    for fold, (fit_idx, val_idx) in tqdm(enumerate(kf.split(X=X_re, y=X_re.iloc[:,-3:]), start = 1),\n",
    "                                         total=CFG.n_stacking_folds):\n",
    "        X, y, test = X_re[features], y_re, test_df[features]\n",
    "        \n",
    "        # Split the dataset according to the fold indexes.\n",
    "        X_train = X.iloc[fit_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_train = y.iloc[fit_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        for i, params in enumerate(best_lgbm_params):\n",
    "            \n",
    "            clf = lgb.LGBMClassifier(**params)\n",
    "            clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                    eval_metric=bll_metric, verbose=-1)\n",
    "\n",
    "            val_preds = clf.predict_proba(X_val)[:,1]\n",
    "            oof_level2[val_idx, i] = val_preds\n",
    "\n",
    "            val_score = balanced_log_loss(y_val, val_preds)\n",
    "            best_iter = clf.best_iteration_\n",
    "            \n",
    "            print(f'Fold: {blu}{fold:>3}{res}| bll_metric: {blu}{val_score:.5f}{res}'\n",
    "                  f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "            \n",
    "            oof_level2_test[:, i] += clf.predict_proba(test)[:,1]\n",
    "        \n",
    "    return oof_level2, oof_level2_test / CFG.n_stacking_folds\n",
    "\n",
    "if CFG.stacking:\n",
    "    oof_level2_lgbm, oof_level2_test_lgbm = lgbm_training()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = train_df[features], train_df['Class']\n",
    "\n",
    "def objective(trial):\n",
    "    bll_list = list()\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": CFG.n_estimators, # trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        \"early_stopping_rounds\": CFG.early_stopping_rounds,\n",
    "        \"verbosity\": 0,\n",
    "        \"random_state\": 14062023,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        # use exact for small dataset.\n",
    "        \"tree_method\": \"exact\",\n",
    "        # defines booster, gblinear for linear functions.\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),# \"dart\", \"gblinear\"]), \n",
    "        # L1 regularization weight.\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        # L2 regularization weight.\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        # sampling ratio for training data.\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "        # sampling according to each tree.\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "    }\n",
    "\n",
    "    if not CFG.undersample:\n",
    "        params[\"scale_pos_weight\"] = class_imbalance\n",
    "    \n",
    "    if params[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        params[\"learning_rate\"] = trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True) # alias eta\n",
    "        # maximum depth of the tree, signifies complexity of the tree.\n",
    "        params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "        # minimum child weight, larger the term more conservative the tree.\n",
    "        params[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "        # defines how selective algorithm is.\n",
    "        params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "    if params[\"booster\"] == \"dart\":\n",
    "        params[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        params[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        params[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        params[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "\n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under-sampling to balance classes\n",
    "        positive_count_train = train_df['Class'].value_counts()[1]\n",
    "        sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                        1: positive_count_train}, \n",
    "                                     random_state=15062023+i, \n",
    "                                     replacement=True)\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # Learning\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=-1)\n",
    "            # Predict\n",
    "            val_preds = model.predict_proba(X_val)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "        \n",
    "        bll_list.append(balanced_log_loss(y_re, oof))    \n",
    "    \n",
    "    return np.mean(bll_list)\n",
    "\n",
    "if CFG.xgb_optimize:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials, )\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe()\n",
    "    df.to_csv(f'optuna_xgb.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load XGBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if CFG.kaggle:\n",
    "    param_list = glob.glob(\"/kaggle/input/icr-lgbm-optuna/optuna_xgb.csv\")\n",
    "else:\n",
    "    param_list = glob.glob(\"optuna_xgb.csv\")\n",
    "\n",
    "models = list()\n",
    "best_xb_params = list()\n",
    "\n",
    "xb_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if xb_params.shape[0] == 0:\n",
    "        xb_params = tmp\n",
    "    else:\n",
    "        xb_params = pd.concat([xb_params, tmp])\n",
    "        \n",
    "xb_params = xb_params.sort_values('value').head(10)#CFG.n_stacking_models)\n",
    "param_cols = [c for c in xb_params.columns if c.startswith('params_')]\n",
    "xb_params = xb_params[param_cols]\n",
    "\n",
    "for idx, row in xb_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['n_estimators'] = CFG.n_estimators\n",
    "    row_dict['early_stopping_rounds'] = CFG.early_stopping_rounds\n",
    "    row_dict['random_state'] = 14062023\n",
    "    row_dict['verbosity'] = 0\n",
    "    row_dict['objective'] = \"binary:logistic\"\n",
    "    row_dict['eval_metric'] = \"logloss\"\n",
    "    row_dict['tree_method'] = \"exact\"\n",
    "    row_dict['booster'] = \"gbtree\"\n",
    "\n",
    "    if not CFG.undersample:\n",
    "        row_dict['scale_pos_weight'] = class_imbalance\n",
    "\n",
    "    if row_dict[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        row_dict[\"max_depth\"] = int(row_dict[\"max_depth\"])\n",
    "        row_dict[\"min_child_weight\"] = int(row_dict[\"min_child_weight\"])\n",
    "    else:\n",
    "        row_dict[\"learning_rate\"] = None\n",
    "        row_dict[\"max_depth\"] = None\n",
    "        row_dict[\"min_child_weight\"] = None\n",
    "        row_dict[\"gamma\"] = None\n",
    "        row_dict[\"grow_policy\"] = None     \n",
    "\n",
    "    if row_dict[\"booster\"] != \"dart\":\n",
    "        row_dict[\"sample_type\"] = None\n",
    "        row_dict[\"normalize_type\"] = None\n",
    "        row_dict[\"rate_drop\"] = None\n",
    "        row_dict[\"skip_drop\"] = None\n",
    "\n",
    "    best_xb_params.append(row_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.test:\n",
    "    best_xb_params = [{\n",
    "            'n_estimators': CFG.n_estimators,\n",
    "            'early_stopping_rounds': CFG.early_stopping_rounds,\n",
    "            'objective': \"binary:logistic\",\n",
    "            'scale_pos_weight':class_imbalance, \n",
    "            'verbosity': 0,\n",
    "            'random_state': 19062023,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with \u001b[1m\u001b[34m39\u001b[0m features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68251a739d44fe0b153400fa26ddca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19858\u001b[0m | Best iteration: \u001b[1m\u001b[34m 196\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23490\u001b[0m | Best iteration: \u001b[1m\u001b[34m 204\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18805\u001b[0m | Best iteration: \u001b[1m\u001b[34m 151\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17577\u001b[0m | Best iteration: \u001b[1m\u001b[34m 224\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19296\u001b[0m | Best iteration: \u001b[1m\u001b[34m 197\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16506\u001b[0m | Best iteration: \u001b[1m\u001b[34m 198\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18672\u001b[0m | Best iteration: \u001b[1m\u001b[34m 198\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18548\u001b[0m | Best iteration: \u001b[1m\u001b[34m 204\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21109\u001b[0m | Best iteration: \u001b[1m\u001b[34m 207\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22085\u001b[0m | Best iteration: \u001b[1m\u001b[34m 165\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28461\u001b[0m | Best iteration: \u001b[1m\u001b[34m 247\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26038\u001b[0m | Best iteration: \u001b[1m\u001b[34m 464\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26264\u001b[0m | Best iteration: \u001b[1m\u001b[34m 202\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24407\u001b[0m | Best iteration: \u001b[1m\u001b[34m 335\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28010\u001b[0m | Best iteration: \u001b[1m\u001b[34m 449\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23674\u001b[0m | Best iteration: \u001b[1m\u001b[34m 192\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23599\u001b[0m | Best iteration: \u001b[1m\u001b[34m 436\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23305\u001b[0m | Best iteration: \u001b[1m\u001b[34m 350\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25940\u001b[0m | Best iteration: \u001b[1m\u001b[34m 450\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24512\u001b[0m | Best iteration: \u001b[1m\u001b[34m 192\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42547\u001b[0m | Best iteration: \u001b[1m\u001b[34m 321\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39189\u001b[0m | Best iteration: \u001b[1m\u001b[34m 213\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.35608\u001b[0m | Best iteration: \u001b[1m\u001b[34m 148\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33924\u001b[0m | Best iteration: \u001b[1m\u001b[34m 325\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.37214\u001b[0m | Best iteration: \u001b[1m\u001b[34m 148\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39821\u001b[0m | Best iteration: \u001b[1m\u001b[34m 213\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.37469\u001b[0m | Best iteration: \u001b[1m\u001b[34m 213\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34631\u001b[0m | Best iteration: \u001b[1m\u001b[34m 291\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34698\u001b[0m | Best iteration: \u001b[1m\u001b[34m 490\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34719\u001b[0m | Best iteration: \u001b[1m\u001b[34m 489\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22813\u001b[0m | Best iteration: \u001b[1m\u001b[34m 131\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26982\u001b[0m | Best iteration: \u001b[1m\u001b[34m 299\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19509\u001b[0m | Best iteration: \u001b[1m\u001b[34m 279\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26492\u001b[0m | Best iteration: \u001b[1m\u001b[34m 369\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21185\u001b[0m | Best iteration: \u001b[1m\u001b[34m 261\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26094\u001b[0m | Best iteration: \u001b[1m\u001b[34m 204\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26078\u001b[0m | Best iteration: \u001b[1m\u001b[34m 369\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22834\u001b[0m | Best iteration: \u001b[1m\u001b[34m 369\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25743\u001b[0m | Best iteration: \u001b[1m\u001b[34m 369\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23719\u001b[0m | Best iteration: \u001b[1m\u001b[34m 369\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27378\u001b[0m | Best iteration: \u001b[1m\u001b[34m 206\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29674\u001b[0m | Best iteration: \u001b[1m\u001b[34m 259\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24927\u001b[0m | Best iteration: \u001b[1m\u001b[34m 142\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27762\u001b[0m | Best iteration: \u001b[1m\u001b[34m 216\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27964\u001b[0m | Best iteration: \u001b[1m\u001b[34m 136\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25942\u001b[0m | Best iteration: \u001b[1m\u001b[34m 180\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29564\u001b[0m | Best iteration: \u001b[1m\u001b[34m 169\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26999\u001b[0m | Best iteration: \u001b[1m\u001b[34m 196\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28275\u001b[0m | Best iteration: \u001b[1m\u001b[34m 201\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27079\u001b[0m | Best iteration: \u001b[1m\u001b[34m 212\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28569\u001b[0m | Best iteration: \u001b[1m\u001b[34m 200\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27938\u001b[0m | Best iteration: \u001b[1m\u001b[34m 480\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29658\u001b[0m | Best iteration: \u001b[1m\u001b[34m 223\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28879\u001b[0m | Best iteration: \u001b[1m\u001b[34m 358\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.31791\u001b[0m | Best iteration: \u001b[1m\u001b[34m 382\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29801\u001b[0m | Best iteration: \u001b[1m\u001b[34m 477\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27749\u001b[0m | Best iteration: \u001b[1m\u001b[34m 232\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29617\u001b[0m | Best iteration: \u001b[1m\u001b[34m 200\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29265\u001b[0m | Best iteration: \u001b[1m\u001b[34m 383\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.31213\u001b[0m | Best iteration: \u001b[1m\u001b[34m 529\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22945\u001b[0m | Best iteration: \u001b[1m\u001b[34m 255\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22465\u001b[0m | Best iteration: \u001b[1m\u001b[34m 360\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19842\u001b[0m | Best iteration: \u001b[1m\u001b[34m 282\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17176\u001b[0m | Best iteration: \u001b[1m\u001b[34m 362\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18474\u001b[0m | Best iteration: \u001b[1m\u001b[34m 290\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19271\u001b[0m | Best iteration: \u001b[1m\u001b[34m 330\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18472\u001b[0m | Best iteration: \u001b[1m\u001b[34m 288\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19866\u001b[0m | Best iteration: \u001b[1m\u001b[34m 364\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19067\u001b[0m | Best iteration: \u001b[1m\u001b[34m 471\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18234\u001b[0m | Best iteration: \u001b[1m\u001b[34m 291\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29138\u001b[0m | Best iteration: \u001b[1m\u001b[34m 516\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.32468\u001b[0m | Best iteration: \u001b[1m\u001b[34m 394\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29416\u001b[0m | Best iteration: \u001b[1m\u001b[34m 231\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.36588\u001b[0m | Best iteration: \u001b[1m\u001b[34m 471\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28825\u001b[0m | Best iteration: \u001b[1m\u001b[34m 190\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28721\u001b[0m | Best iteration: \u001b[1m\u001b[34m 182\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28118\u001b[0m | Best iteration: \u001b[1m\u001b[34m 191\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.34156\u001b[0m | Best iteration: \u001b[1m\u001b[34m 182\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.32326\u001b[0m | Best iteration: \u001b[1m\u001b[34m 465\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.31232\u001b[0m | Best iteration: \u001b[1m\u001b[34m 392\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18481\u001b[0m | Best iteration: \u001b[1m\u001b[34m 597\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19624\u001b[0m | Best iteration: \u001b[1m\u001b[34m 811\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16774\u001b[0m | Best iteration: \u001b[1m\u001b[34m 593\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19309\u001b[0m | Best iteration: \u001b[1m\u001b[34m 638\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20063\u001b[0m | Best iteration: \u001b[1m\u001b[34m 644\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19858\u001b[0m | Best iteration: \u001b[1m\u001b[34m 745\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19936\u001b[0m | Best iteration: \u001b[1m\u001b[34m 802\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20485\u001b[0m | Best iteration: \u001b[1m\u001b[34m 745\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22088\u001b[0m | Best iteration: \u001b[1m\u001b[34m 484\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24277\u001b[0m | Best iteration: \u001b[1m\u001b[34m 290\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25755\u001b[0m | Best iteration: \u001b[1m\u001b[34m 306\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24087\u001b[0m | Best iteration: \u001b[1m\u001b[34m 451\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24636\u001b[0m | Best iteration: \u001b[1m\u001b[34m 307\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25756\u001b[0m | Best iteration: \u001b[1m\u001b[34m 314\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25513\u001b[0m | Best iteration: \u001b[1m\u001b[34m 319\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27245\u001b[0m | Best iteration: \u001b[1m\u001b[34m 334\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28690\u001b[0m | Best iteration: \u001b[1m\u001b[34m 334\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23812\u001b[0m | Best iteration: \u001b[1m\u001b[34m 306\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24778\u001b[0m | Best iteration: \u001b[1m\u001b[34m 327\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25094\u001b[0m | Best iteration: \u001b[1m\u001b[34m 232\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def xgboost_training():\n",
    "    # Make random under-sampling to balance classes\n",
    "    positive_count_train = train_df['Class'].value_counts()[1]\n",
    "    sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                    1: positive_count_train}, \n",
    "                                 random_state=150620232, \n",
    "                                 replacement=True)\n",
    "\n",
    "    X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "\n",
    "    if CFG.undersample:\n",
    "        X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "    \n",
    "    kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=80620232)\n",
    "\n",
    "    oof_level2 = np.zeros([y_re.shape[0], len(best_xb_params) + 1])\n",
    "    oof_level2[:, len(best_xb_params)] = y_re\n",
    "    oof_level2_test = np.zeros([test_df.shape[0], len(best_xb_params)])\n",
    "\n",
    "    print(f\"Training with {blu}{len(features)}{res} features\")\n",
    "\n",
    "    for fold, (fit_idx, val_idx) in tqdm(enumerate(kf.split(X=X_re, y=X_re.iloc[:,-3:]), start = 1),\n",
    "                                         total=CFG.n_stacking_folds):\n",
    "        X, y, test = X_re[features], y_re, test_df[features]\n",
    "        \n",
    "        # Split the dataset according to the fold indexes.\n",
    "        X_train = X.iloc[fit_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_train = y.iloc[fit_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        for i, params in enumerate(best_xb_params):\n",
    "            clf = xgb.XGBClassifier(**params)\n",
    "            \n",
    "            clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "\n",
    "            val_preds = clf.predict_proba(X_val)[:,1]\n",
    "            oof_level2[val_idx, i] = val_preds\n",
    "\n",
    "            val_score = balanced_log_loss(y_val, val_preds)\n",
    "            best_iter = clf.get_booster().best_iteration\n",
    "            \n",
    "            print(f'Fold: {blu}{fold:>3}{res}| bll_metric: {blu}{val_score:.5f}{res}'\n",
    "                  f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "        \n",
    "            oof_level2_test[:, i] += clf.predict_proba(test)[:,1]\n",
    "        \n",
    "    return oof_level2, oof_level2_test / CFG.n_stacking_folds\n",
    "\n",
    "if CFG.stacking:\n",
    "    oof_level2_xgb, oof_level2_test_xgb = xgboost_training()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from optuna.integration import CatBoostPruningCallback\n",
    "\n",
    "X, y = train_df[features], train_df['Class']\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    bll_list = list()\n",
    "\n",
    "    # Parameters\n",
    "    params = {\n",
    "        'task_type': 'CPU', # GPU\n",
    "        'eval_metric': 'Logloss',\n",
    "        'loss_function': 'Logloss', \n",
    "        'random_seed': 19062023,\n",
    "        'od_type': 'Iter', # Type of overfitting detector - stop after k iteraions\n",
    "        'iterations' : CFG.n_estimators, # trial.suggest_int('iterations', 300, 1200),        \n",
    "        'od_wait': CFG.early_stopping_rounds, # Overfitting detector - stop training after k iterations without metric improvement\n",
    "        # 'metric_period': 100, # Show metric each k iterations\n",
    "        # Hyperparamters (in order of importance decreasing)\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS', 'No']),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-3, 3e-1), \n",
    "        'l2_leaf_reg': trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
    "        'depth' : trial.suggest_int('depth', 4, 10),  # Max tree depth                                          \n",
    "         # increase to deal with overfit\n",
    "        'random_strength': trial.suggest_float('random_strength', 0, 100), # The amount of randomness to use\n",
    "                                                                           # for scoring splits when the tree structure\n",
    "                                                                           # is selected. Helps to avoid overfitting\n",
    "                                                                           # CPU only\n",
    "        # per_float_feature_quantization='0:border_count=1024'\n",
    "        'border_count': 254, # trial.suggest_categorical('border_count', [128, 254]), # The number of splits for numerical features\n",
    "                                                                                      # bigger is better but slowly\n",
    "                                                                                      # alias: max_bin\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                           # aliases: min_child_samples, \n",
    "\n",
    "    }\n",
    "\n",
    "    if not CFG.undersample:\n",
    "        row_dict['auto_class_weights'] = 'Balanced'\n",
    "        # params['scale_pos_weight'] = class_imbalance\n",
    "        \n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 100) # Assigns random \n",
    "                                                                                           # weights to objects\n",
    "                                                                                           # works only with \n",
    "                                                                                           # Bayesian bootstrap\n",
    "    if params[\"bootstrap_type\"] in [\"Poisson\", \"Bernoulli\", \"MVS\"]:\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.3, 1) # Percentage of objects to use \n",
    "                                                                        # at each split\n",
    "\n",
    "    if params['task_type'] == 'CPU' and params['bootstrap_type'] != 'Bayesian':\n",
    "        params[\"colsample_bylevel\"] = trial.suggest_float(\"colsample_bylevel\", 0.3, 1)  # Percentage of features to use \n",
    "                                                                                        # at each split;\n",
    "                                                                                        # with Bayesian bootstrap and Lossguide grop policy\n",
    "                                                                                        # leads to error (CatBoost bug)\n",
    "    else:\n",
    "        params[\"colsample_bylevel\"] = None                                                     \n",
    "\n",
    "    if params['grow_policy'] == 'Lossguide': \n",
    "        params['max_leaves'] = trial.suggest_int('max_leaves', 4, 128) # Max number of leaves in one tree \n",
    "                                                                       # decrease to deal with the overfit\n",
    "\n",
    "    if params['grow_policy'] == 'SymmetricTree': \n",
    "        params['boosting_type'] = trial.suggest_categorical('boosting_type', ['Ordered', 'Plain'])\n",
    "    else:\n",
    "        params['boosting_type'] = 'Plain'\n",
    "    \n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under-sampling to balance classes\n",
    "        positive_count_train = train_df['Class'].value_counts()[1]\n",
    "        sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                        1: positive_count_train}, \n",
    "                                     random_state=15062023+i, \n",
    "                                     replacement=True)\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "            val_pool = Pool(X_val, y_val, cat_features=['EJ'])\n",
    "\n",
    "            # Learning\n",
    "            model = cat.CatBoostClassifier(**params)     \n",
    "            # Add a callback for pruning\n",
    "#             pruning_callback = optuna.integration.CatBoostPruningCallback(trial, \"Logloss\")\n",
    "            model.fit(train_pool, eval_set=val_pool, verbose=0)#, callbacks=[pruning_callback])\n",
    "            # Evoke pruning manually\n",
    "#                 pruning_callback.check_pruned()\n",
    "            # Predict\n",
    "            val_preds = model.predict_proba(val_pool)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "        \n",
    "        bll_list.append(balanced_log_loss(y_re, oof))    \n",
    "    \n",
    "    return np.mean(bll_list)\n",
    "\n",
    "if CFG.cb_optimize:\n",
    "#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df.to_csv(f'optuna_catboost.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CatBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if CFG.kaggle:\n",
    "    param_list = glob.glob(\"/kaggle/input/icr-lgbm-optuna/optuna_catboost.csv\")\n",
    "else:\n",
    "    param_list = glob.glob(\"optuna_catboost.csv\")\n",
    "\n",
    "models = list()\n",
    "best_cb_params = list()\n",
    "\n",
    "cb_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if cb_params.shape[0] == 0:\n",
    "        cb_params = tmp\n",
    "    else:\n",
    "        cb_params = pd.concat([cb_params, tmp])\n",
    "        \n",
    "cb_params = cb_params.sort_values('value').head(10)#CFG.n_stacking_models)\n",
    "param_cols = [c for c in cb_params.columns if c.startswith('params_')]\n",
    "cb_params = cb_params[param_cols]\n",
    "\n",
    "\n",
    "for idx, row in cb_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['task_type'] = 'CPU'\n",
    "    row_dict['eval_metric'] = 'Logloss'\n",
    "    row_dict['loss_function'] = 'Logloss'\n",
    "    row_dict['random_seed'] = 13062023\n",
    "    row_dict['verbose'] = 0\n",
    "    row_dict['od_type'] = 'Iter'\n",
    "    row_dict['iterations'] = CFG.n_estimators * 4\n",
    "    row_dict['od_wait'] = CFG.early_stopping_rounds\n",
    "    row_dict['border_count'] = 254\n",
    "    \n",
    "    if not CFG.undersample:\n",
    "        row_dict['auto_class_weights'] = 'Balanced'\n",
    "        # row_dict['scale_pos_weight'] = class_imbalance\n",
    "        \n",
    "    if row_dict[\"task_type\"] != \"GPU\":\n",
    "        row_dict['colsample_bylevel'] = None\n",
    "    \n",
    "    if row_dict[\"bootstrap_type\"] != \"Bayesian\":\n",
    "        row_dict['bagging_temperature'] = None\n",
    "        \n",
    "    if row_dict[\"bootstrap_type\"] not in [\"Poisson\", \"Bernoulli\", \"MVS\"]:\n",
    "        row_dict['subsample'] = None\n",
    "    \n",
    "    if row_dict['grow_policy'] == 'Lossguide':\n",
    "        row_dict['max_leaves'] = int(row_dict['max_leaves'])\n",
    "    else:\n",
    "        row_dict['max_leaves'] = None\n",
    "    \n",
    "    if row_dict['grow_policy'] != 'SymmetricTree':\n",
    "        row_dict['boosting_type'] = 'Plain'\n",
    "    \n",
    "    best_cb_params.append(row_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.test:\n",
    "    best_cb_params = [{\n",
    "            'iterations': CFG.n_estimators,\n",
    "            'od_type': 'Iter',\n",
    "            'od_wait': CFG.early_stopping_rounds,\n",
    "            'eval_metric': \"Logloss\",\n",
    "            'loss_function': \"Logloss\",\n",
    "            'auto_class_weights': 'Balanced', \n",
    "            'verbose': 0,\n",
    "            'random_seed': 19062023,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with \u001b[1m\u001b[34m39\u001b[0m features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e4ea178d134df28ac27fdbddb8e591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.40906\u001b[0m | Best iteration: \u001b[1m\u001b[34m 313\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.41344\u001b[0m | Best iteration: \u001b[1m\u001b[34m 337\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.40167\u001b[0m | Best iteration: \u001b[1m\u001b[34m 435\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.41216\u001b[0m | Best iteration: \u001b[1m\u001b[34m 446\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38410\u001b[0m | Best iteration: \u001b[1m\u001b[34m 356\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.40146\u001b[0m | Best iteration: \u001b[1m\u001b[34m 385\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.44489\u001b[0m | Best iteration: \u001b[1m\u001b[34m 345\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.43166\u001b[0m | Best iteration: \u001b[1m\u001b[34m 149\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.41059\u001b[0m | Best iteration: \u001b[1m\u001b[34m 515\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42907\u001b[0m | Best iteration: \u001b[1m\u001b[34m 602\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.43046\u001b[0m | Best iteration: \u001b[1m\u001b[34m 155\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38334\u001b[0m | Best iteration: \u001b[1m\u001b[34m 266\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.46198\u001b[0m | Best iteration: \u001b[1m\u001b[34m 153\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.46479\u001b[0m | Best iteration: \u001b[1m\u001b[34m 157\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.44748\u001b[0m | Best iteration: \u001b[1m\u001b[34m 151\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38346\u001b[0m | Best iteration: \u001b[1m\u001b[34m 478\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.41067\u001b[0m | Best iteration: \u001b[1m\u001b[34m 330\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39472\u001b[0m | Best iteration: \u001b[1m\u001b[34m 313\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.40679\u001b[0m | Best iteration: \u001b[1m\u001b[34m 420\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.44071\u001b[0m | Best iteration: \u001b[1m\u001b[34m 211\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13932\u001b[0m | Best iteration: \u001b[1m\u001b[34m1091\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17391\u001b[0m | Best iteration: \u001b[1m\u001b[34m 767\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15325\u001b[0m | Best iteration: \u001b[1m\u001b[34m1172\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15117\u001b[0m | Best iteration: \u001b[1m\u001b[34m 834\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12385\u001b[0m | Best iteration: \u001b[1m\u001b[34m1278\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20343\u001b[0m | Best iteration: \u001b[1m\u001b[34m 831\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16023\u001b[0m | Best iteration: \u001b[1m\u001b[34m1543\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09267\u001b[0m | Best iteration: \u001b[1m\u001b[34m2050\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14976\u001b[0m | Best iteration: \u001b[1m\u001b[34m1440\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16144\u001b[0m | Best iteration: \u001b[1m\u001b[34m2131\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22888\u001b[0m | Best iteration: \u001b[1m\u001b[34m 406\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22069\u001b[0m | Best iteration: \u001b[1m\u001b[34m 828\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19965\u001b[0m | Best iteration: \u001b[1m\u001b[34m1078\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16821\u001b[0m | Best iteration: \u001b[1m\u001b[34m1086\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19031\u001b[0m | Best iteration: \u001b[1m\u001b[34m 972\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26236\u001b[0m | Best iteration: \u001b[1m\u001b[34m 867\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18422\u001b[0m | Best iteration: \u001b[1m\u001b[34m1395\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22893\u001b[0m | Best iteration: \u001b[1m\u001b[34m 924\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21784\u001b[0m | Best iteration: \u001b[1m\u001b[34m1129\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27692\u001b[0m | Best iteration: \u001b[1m\u001b[34m 743\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12509\u001b[0m | Best iteration: \u001b[1m\u001b[34m 994\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09469\u001b[0m | Best iteration: \u001b[1m\u001b[34m2053\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11616\u001b[0m | Best iteration: \u001b[1m\u001b[34m1295\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09275\u001b[0m | Best iteration: \u001b[1m\u001b[34m2843\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11067\u001b[0m | Best iteration: \u001b[1m\u001b[34m1082\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13427\u001b[0m | Best iteration: \u001b[1m\u001b[34m1946\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11422\u001b[0m | Best iteration: \u001b[1m\u001b[34m2617\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14004\u001b[0m | Best iteration: \u001b[1m\u001b[34m1343\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12900\u001b[0m | Best iteration: \u001b[1m\u001b[34m1740\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16625\u001b[0m | Best iteration: \u001b[1m\u001b[34m1697\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17878\u001b[0m | Best iteration: \u001b[1m\u001b[34m 341\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22263\u001b[0m | Best iteration: \u001b[1m\u001b[34m 346\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19532\u001b[0m | Best iteration: \u001b[1m\u001b[34m 688\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15045\u001b[0m | Best iteration: \u001b[1m\u001b[34m 478\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19946\u001b[0m | Best iteration: \u001b[1m\u001b[34m 440\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18578\u001b[0m | Best iteration: \u001b[1m\u001b[34m 663\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19184\u001b[0m | Best iteration: \u001b[1m\u001b[34m 580\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16099\u001b[0m | Best iteration: \u001b[1m\u001b[34m 590\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19321\u001b[0m | Best iteration: \u001b[1m\u001b[34m 643\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15735\u001b[0m | Best iteration: \u001b[1m\u001b[34m1338\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16189\u001b[0m | Best iteration: \u001b[1m\u001b[34m 558\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15922\u001b[0m | Best iteration: \u001b[1m\u001b[34m 714\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19028\u001b[0m | Best iteration: \u001b[1m\u001b[34m 568\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16179\u001b[0m | Best iteration: \u001b[1m\u001b[34m 722\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17141\u001b[0m | Best iteration: \u001b[1m\u001b[34m 729\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17831\u001b[0m | Best iteration: \u001b[1m\u001b[34m1094\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15345\u001b[0m | Best iteration: \u001b[1m\u001b[34m1653\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16474\u001b[0m | Best iteration: \u001b[1m\u001b[34m 994\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17916\u001b[0m | Best iteration: \u001b[1m\u001b[34m1326\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15850\u001b[0m | Best iteration: \u001b[1m\u001b[34m1270\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10564\u001b[0m | Best iteration: \u001b[1m\u001b[34m 951\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07521\u001b[0m | Best iteration: \u001b[1m\u001b[34m2818\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.05961\u001b[0m | Best iteration: \u001b[1m\u001b[34m2131\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12399\u001b[0m | Best iteration: \u001b[1m\u001b[34m1230\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06390\u001b[0m | Best iteration: \u001b[1m\u001b[34m2167\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09804\u001b[0m | Best iteration: \u001b[1m\u001b[34m2905\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11463\u001b[0m | Best iteration: \u001b[1m\u001b[34m1783\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12523\u001b[0m | Best iteration: \u001b[1m\u001b[34m 808\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06445\u001b[0m | Best iteration: \u001b[1m\u001b[34m3403\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10575\u001b[0m | Best iteration: \u001b[1m\u001b[34m1530\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24826\u001b[0m | Best iteration: \u001b[1m\u001b[34m 333\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21540\u001b[0m | Best iteration: \u001b[1m\u001b[34m 558\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20980\u001b[0m | Best iteration: \u001b[1m\u001b[34m 469\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19712\u001b[0m | Best iteration: \u001b[1m\u001b[34m 425\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19872\u001b[0m | Best iteration: \u001b[1m\u001b[34m 404\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21542\u001b[0m | Best iteration: \u001b[1m\u001b[34m 634\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20083\u001b[0m | Best iteration: \u001b[1m\u001b[34m 657\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21813\u001b[0m | Best iteration: \u001b[1m\u001b[34m 413\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21354\u001b[0m | Best iteration: \u001b[1m\u001b[34m 683\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19984\u001b[0m | Best iteration: \u001b[1m\u001b[34m 670\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09912\u001b[0m | Best iteration: \u001b[1m\u001b[34m 911\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18104\u001b[0m | Best iteration: \u001b[1m\u001b[34m 476\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15792\u001b[0m | Best iteration: \u001b[1m\u001b[34m 597\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15877\u001b[0m | Best iteration: \u001b[1m\u001b[34m 433\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18010\u001b[0m | Best iteration: \u001b[1m\u001b[34m 628\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13048\u001b[0m | Best iteration: \u001b[1m\u001b[34m1597\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13470\u001b[0m | Best iteration: \u001b[1m\u001b[34m1044\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14589\u001b[0m | Best iteration: \u001b[1m\u001b[34m 640\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13781\u001b[0m | Best iteration: \u001b[1m\u001b[34m1828\u001b[0m\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13894\u001b[0m | Best iteration: \u001b[1m\u001b[34m 935\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def cb_training():\n",
    "    # Make random under-sampling to balance classes\n",
    "    positive_count_train = train_df['Class'].value_counts()[1]\n",
    "    sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                    1: positive_count_train}, \n",
    "                                 random_state=150620233, \n",
    "                                 replacement=True)\n",
    "\n",
    "    X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "\n",
    "    if CFG.undersample:\n",
    "        X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "    \n",
    "    kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=80620233)\n",
    "\n",
    "    oof_level2 = np.zeros([y_re.shape[0], len(best_cb_params) + 1])\n",
    "    oof_level2[:, len(best_cb_params)] = y_re\n",
    "    oof_level2_test = np.zeros([test_df.shape[0], len(best_cb_params)])\n",
    "\n",
    "    print(f\"Training with {blu}{len(features)}{res} features\")\n",
    "\n",
    "    for fold, (fit_idx, val_idx) in tqdm(enumerate(kf.split(X=X_re, y=X_re.iloc[:,-3:]), start = 1),\n",
    "                                         total=CFG.n_stacking_folds):\n",
    "        X, y, test = X_re[features], y_re, test_df[features]\n",
    "        \n",
    "        # Split the dataset according to the fold indexes.\n",
    "        X_train = X.iloc[fit_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_train = y.iloc[fit_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "        val_pool = Pool(X_val, y_val, cat_features=['EJ'])\n",
    "        \n",
    "        for i, params in enumerate(best_cb_params):\n",
    "            \n",
    "            model = cat.CatBoostClassifier(**params)\n",
    "            model.fit(train_pool, eval_set=val_pool, verbose=0)\n",
    "\n",
    "            val_preds = model.predict_proba(val_pool)[:,1]\n",
    "            oof_level2[val_idx, i] = val_preds\n",
    "\n",
    "            val_score = balanced_log_loss(y_val, val_preds)\n",
    "            best_iter = model.best_iteration_\n",
    "            \n",
    "            print(f'Fold: {blu}{fold:>3}{res}| bll_metric: {blu}{val_score:.5f}{res}'\n",
    "                  f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "        \n",
    "            oof_level2_test[:, i] += model.predict_proba(test)[:,1]\n",
    "        \n",
    "    return oof_level2, oof_level2_test / CFG.n_stacking_folds\n",
    "\n",
    "if CFG.stacking:\n",
    "    oof_level2_cb, oof_level2_test_cb = cb_training()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking with Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18805292825841224\n",
      "0.15827603204818558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "oof_level2 = np.concatenate([oof_level2_lgbm[:,:-1], oof_level2_xgb[:,:-1], oof_level2_cb[:,:-1]], axis=1)\n",
    "oof_level2_test = np.concatenate([oof_level2_test_lgbm, oof_level2_test_xgb, oof_level2_test_cb], axis=1)\n",
    "\n",
    "X = oof_level2\n",
    "y = oof_level2_cb[:,-1]\n",
    "\n",
    "# mean bll\n",
    "print(balanced_log_loss(y, np.mean(X, axis=1)))\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "lr.fit(X, y)\n",
    "\n",
    "pred = lr.predict_proba(X)[:,1]\n",
    "\n",
    "# lr bll\n",
    "print(balanced_log_loss(y, pred))\n",
    "\n",
    "weights = lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1002285020362512"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 folds\n",
    "0.18644189855630458\n",
    "0.15105966209005686\n",
    "\n",
    "# 15 folds\n",
    "0.17500717692858106\n",
    "0.13966564052716351\n",
    "\n",
    "# 15 folds + drop err objects\n",
    "0.13200526889584116\n",
    "0.1002285020362512\n",
    "\n",
    "# 10 folds + new cb\n",
    "0.18667614053330772\n",
    "0.15508252648502444\n",
    "\n",
    "# 10 folds + 20 lgbms + 10 xgb + 10 new cb\n",
    "0.18805292825841224\n",
    "0.15827603204818558"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which objects are the most erroneus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[102, 292, 509, 367, 556, 380, 462]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.mean(X, axis=1)\n",
    "errors = pd.Series(np.abs(y - preds))\n",
    "errors = errors.sort_values(ascending=False)\n",
    "errors[errors >= errors.quantile(0.99)].index.to_list()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-08T15:32:38.350522Z",
     "iopub.status.idle": "2023-06-08T15:32:38.351460Z",
     "shell.execute_reply": "2023-06-08T15:32:38.351239Z",
     "shell.execute_reply.started": "2023-06-08T15:32:38.351217Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## Model Evaluation\n",
    "# metric_score_folds = pd.DataFrame.from_dict(all_eval_results_)\n",
    "# fit_logloss = []\n",
    "# val_logloss = []\n",
    "\n",
    "# for seed in CFG.seeds:\n",
    "#     for fold in range(1,CFG.n_folds+1):\n",
    "#         fit_logloss.append(metric_score_folds[seed][fold]['training']['balanced_log_loss'])\n",
    "#         val_logloss.append(metric_score_folds[seed][fold]['valid_1']['balanced_log_loss'])\n",
    "\n",
    "# fig, axes = plt.subplots(math.ceil(CFG.n_folds*len(CFG.seeds)/CFG.n_folds), CFG.n_folds, figsize=(20, 20), dpi=150)\n",
    "# ax = axes.flatten()\n",
    "# for i, (f, v, m) in enumerate(zip(fit_logloss, val_logloss, models_), start = 1): \n",
    "#     sns.lineplot(f, color='#B90000', ax=ax[i-1], label='fit')\n",
    "#     sns.lineplot(v, color='#048BA8', ax=ax[i-1], label='val')\n",
    "#     ax[i-1].legend()\n",
    "#     ax[i-1].spines['top'].set_visible(False);\n",
    "#     ax[i-1].spines['right'].set_visible(False)\n",
    "#     ax[i-1].set_title(f'Seed {CFG.seeds[(i-1)//CFG.n_folds]} Fold {CFG.n_folds if i%CFG.n_folds==0 else i%CFG.n_folds}', fontdict={'fontweight': 'bold'})\n",
    "\n",
    "#     color =  ['#048BA8', palette[-3]]\n",
    "#     best_iter = m.best_iteration_\n",
    "#     span_range = [[0, best_iter], [best_iter + 10, best_iter + CFG.num_boost_round]]\n",
    "\n",
    "#     for idx, sub_title in enumerate([f'Best\\nIteration: {best_iter}', f'Early\\n Stopping: 2000']):\n",
    "#         ax[i-1].annotate(sub_title,\n",
    "#                     xy=(sum(span_range[idx])/2 , 0.5),\n",
    "#                     xytext=(0,0), textcoords='offset points',\n",
    "#                     va=\"center\", ha=\"center\",\n",
    "#                     color=\"w\", fontsize=16, fontweight='bold',\n",
    "#                     bbox=dict(boxstyle='round4', pad=0.4, color=color[idx], alpha=0.6))\n",
    "#         ax[i-1].axvspan(span_range[idx][0]-0.4,span_range[idx][1]+0.4,  color=color[idx], alpha=0.07)\n",
    "\n",
    "#     ax[i-1].set_xlim(0, best_iter + 20 + 2000)\n",
    "#     ax[i-1].legend(bbox_to_anchor=(0.95, 1), loc='upper right', title='logloss')\n",
    "\n",
    "# plt.tight_layout();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-08T15:32:38.352845Z",
     "iopub.status.idle": "2023-06-08T15:32:38.353222Z",
     "shell.execute_reply": "2023-06-08T15:32:38.353059Z",
     "shell.execute_reply.started": "2023-06-08T15:32:38.353042Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.639703</td>\n",
       "      <td>0.360297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.639703</td>\n",
       "      <td>0.360297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.639703</td>\n",
       "      <td>0.360297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.639703</td>\n",
       "      <td>0.360297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.639703</td>\n",
       "      <td>0.360297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.639703  0.360297\n",
       "1  010ebe33f668  0.639703  0.360297\n",
       "2  02fa521e1838  0.639703  0.360297\n",
       "3  040e15f562a2  0.639703  0.360297\n",
       "4  046e85c7cc7f  0.639703  0.360297"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(X):\n",
    "    y = np.zeros(len(X))\n",
    "    for i in range(oof_level2_test.shape[1]):\n",
    "        y += weights[i] * oof_level2_test[:,i]\n",
    "        # y += oof_level2_test[:,i]\n",
    "    return y / sum(weights)\n",
    "    # return y / oof_level2_test.shape[1]\n",
    "\n",
    "predictions = predict(test_df[features])\n",
    "# predictions = predict(generated_features_test)\n",
    "\n",
    "test_df['class_1'] = predictions\n",
    "test_df['class_0'] = 1 - predictions\n",
    "\n",
    "sample_submission[['class_0', 'class_1']] = test_df[['class_0', 'class_1']]\n",
    "sample_submission.to_csv(r\"submission.csv\", index=False)\n",
    "sample_submission"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a lot of resulting features. I have already identified a few important once. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
