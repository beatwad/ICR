{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabpfn --no-index --find-links=file:///kaggle/input/pip-packages-icr/pip-packages\n",
    "# !mkdir -p /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "# !cp /kaggle/input/pip-packages-icr/pip-packages/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:23.665663Z",
     "iopub.status.busy": "2023-06-08T15:31:23.665223Z",
     "iopub.status.idle": "2023-06-08T15:31:35.997437Z",
     "shell.execute_reply": "2023-06-08T15:31:35.996163Z",
     "shell.execute_reply.started": "2023-06-08T15:31:23.665630Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/iter-strat/iter_strat')\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "from catboost import Pool\n",
    "import xgboost as xgb\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "import itertools\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits, BaseShuffleSplit, _validate_shuffle_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import _num_samples, check_array\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import eli5\n",
    "from IPython.display import display\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "from colorama import Style, Fore\n",
    "\n",
    "palette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n",
    "           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n",
    "\n",
    "blk = Style.BRIGHT + Fore.BLACK\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "res = Style.RESET_ALL\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    # main\n",
    "    kaggle = False\n",
    "    test = False\n",
    "    \n",
    "    # features\n",
    "    fe_drop = True\n",
    "    del_errs = False\n",
    "    del_outliers = True\n",
    "    feature_sel = False\n",
    "    n_feature_sel_folds = 5\n",
    "    undersample = False\n",
    "    oversample = True\n",
    "    nan_impute = False\n",
    "    \n",
    "    # optimization\n",
    "    n_estimators = 3000\n",
    "    early_stopping_rounds = 100\n",
    "    \n",
    "    lgbm_optimize = True\n",
    "    xgb_optimize = False\n",
    "    cb_optimize = False\n",
    "    \n",
    "    n_trials = 500\n",
    "    n_optimize_folds = 10\n",
    "    n_optimize_repeats = 2\n",
    "    \n",
    "    # train\n",
    "    lgbm_train = True\n",
    "    xgb_train = False\n",
    "    cb_train = False\n",
    "    tabpfn_train = False\n",
    "\n",
    "    # inference\n",
    "    n_stacking_folds = 10\n",
    "    n_stacking_models_lgbm = 40\n",
    "    n_stacking_models_xgb = 10\n",
    "    n_stacking_models_cb = 20\n",
    "    n_stacking_models_tabpfn = 20\n",
    "\n",
    "    adjust_class_threshold = False\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:31:36.001085Z",
     "iopub.status.busy": "2023-06-08T15:31:35.999808Z",
     "iopub.status.idle": "2023-06-08T15:31:36.066222Z",
     "shell.execute_reply": "2023-06-08T15:31:36.064862Z",
     "shell.execute_reply.started": "2023-06-08T15:31:36.001050Z"
    }
   },
   "outputs": [],
   "source": [
    "if CFG.kaggle:\n",
    "    COMP_PATH = \"/kaggle/input/icr-identify-age-related-conditions\"\n",
    "else:\n",
    "    COMP_PATH = \"icr-identify-age-related-conditions\"\n",
    "\n",
    "train_df = pd.read_csv(f'{COMP_PATH}//train.csv')\n",
    "test_df = pd.read_csv(f'{COMP_PATH}/test.csv')\n",
    "greeks = pd.read_csv(f\"{COMP_PATH}/greeks.csv\")\n",
    "sample_submission = pd.read_csv(f\"{COMP_PATH}/sample_submission.csv\")\n",
    "\n",
    "train_df['EJ'] = train_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "test_df['EJ'] = test_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "\n",
    "train_df.columns = train_df.columns.str.replace(' ', '')\n",
    "test_df.columns = test_df.columns.str.replace(' ', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log features (preserve sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in features:\n",
    "#     train_df[f] = np.sign(train_df[f]) * np.log1p(np.abs(train_df[f])) # no significant result for LGBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_outliers = [fe for fe in train_df.columns if fe not in ['BN', 'BQ', 'CW', 'EL', 'GH', \n",
    "                                                                      'GI', 'GL', 'Id', 'Class', 'EJ']]\n",
    "\n",
    "if CFG.del_outliers:\n",
    "    for f in features_with_outliers:\n",
    "        train_df[f] = train_df[f].clip(upper=train_df[f].quantile(0.99))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete erroneus objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.del_errs:\n",
    "    err_objs = [292, 102, 509, 367, 313, 462, 556]\n",
    "    train_df = train_df.loc[[i for i in train_df.index if i not in err_objs], :].reset_index(drop=True)\n",
    "    greeks = greeks.loc[[i for i in greeks.index if i not in err_objs], :].reset_index(drop=True)\n",
    "\n",
    "class_imbalance = train_df[train_df['Class'] == 0].shape[0] / train_df[train_df['Class'] == 1].shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "\n",
    "# features = train_df.drop(['Class', 'Id'], axis=1).columns\n",
    "\n",
    "# # average label of 20 Nearest Neighbours (colsine distance)\n",
    "# knn = NearestNeighbors(n_neighbors=10, metric='cosine', n_jobs=-1)\n",
    "# knn.fit(train_df[features].fillna(0))\n",
    "\n",
    "# # train\n",
    "# dists, nears = knn.kneighbors(train_df[features].fillna(0), return_distance=True)\n",
    "# dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# train_df['class_cos'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# train_df['class_cos'] = train_df['class_cos'].astype(float)\n",
    "\n",
    "# # test\n",
    "# dists, nears = knn.kneighbors(test_df[features].fillna(0), return_distance=True)\n",
    "# dists, nears = dists[:,1:], nears[:,1:]\n",
    "\n",
    "# classes = np.array([train_df.loc[n, 'Class'] for n in nears])\n",
    "# test_df['class_cos'] = np.array(classes[i].mean() for i in range(len(nears)))\n",
    "# test_df['class_cos'] = test_df['class_cos'].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop not necessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CFG.fe_drop:\n",
    "    features = [fe for fe in train_df.columns if fe not in ['CF', 'CB', 'DV', 'BR', 'DF', 'GB', 'AH',\n",
    "                                                            'CW', 'CL', 'BP', 'BD', 'FC', 'GE', 'GF',\n",
    "                                                            'AR', 'GI', 'Id', 'Class', 'AX', 'DA']]\n",
    "else:\n",
    "    features = [fe for fe in train_df.columns if fe not in ['Id', 'Class']]\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN imputing and Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "# greeks.loc[greeks.Epsilon != 'Unknown','Epsilon'] = greeks.loc[greeks.Epsilon != 'Unknown','Epsilon'].map(lambda x: datetime.strptime(x,'%m/%d/%Y').toordinal())\n",
    "# greeks.loc[greeks.Epsilon == 'Unknown','Epsilon'] = np.nan\n",
    "# greeks['Alpha'] = greeks['Alpha'].map({'A':0,'B':1,'D':2,'G':3})\n",
    "\n",
    "# train_df['Epsilon'] = greeks['Epsilon']\n",
    "# test_df['Epsilon'] = greeks['Epsilon'].max() + 1\n",
    "\n",
    "train_df_tabpfn = imp.fit_transform(train_df[features])\n",
    "test_df_tabpfn = imp.transform(test_df[features])\n",
    "\n",
    "sc = StandardScaler()\n",
    "train_df_tabpfn = sc.fit_transform(train_df_tabpfn)\n",
    "test_df_tabpfn = sc.transform(test_df_tabpfn)\n",
    "\n",
    "train_df_tabpfn = pd.DataFrame(train_df_tabpfn, columns=features)\n",
    "test_df_tabpfn = pd.DataFrame(test_df_tabpfn, columns=features)\n",
    "\n",
    "if CFG.nan_impute:\n",
    "    train_df[features] = train_df_tabpfn[features]\n",
    "    test_df[features] = test_df_tabpfn[features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:41.223344Z",
     "iopub.status.busy": "2023-06-08T15:32:41.222954Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not CFG.kaggle:\n",
    "\n",
    "    from shaphypetune import BoostBoruta\n",
    "\n",
    "    params = {\n",
    "                'n_estimators': CFG.n_estimators,\n",
    "                'early_stopping_round': CFG.early_stopping_rounds,\n",
    "                'objective': 'binary',\n",
    "                'metric': 'logloss', \n",
    "                'n_jobs': -1,\n",
    "                'is_unbalance':True, \n",
    "                'verbose': -1,\n",
    "                'seed': 19062023,\n",
    "            }\n",
    "\n",
    "    def balanced_log_loss(y_true, y_pred):\n",
    "\n",
    "        # Nc is the number of observations\n",
    "        N_1 = np.sum(y_true == 1, axis=0)\n",
    "        N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "        # In order to avoid the extremes of the log function, each predicted probability ð‘ is replaced with max(min(ð‘,1âˆ’10âˆ’15),10âˆ’15)\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "        # balanced logarithmic loss\n",
    "        loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1 - y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "        return loss_numerator / 2\n",
    "\n",
    "    def bll_metric(y_true, y_pred):\n",
    "        return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "    def calc_log_loss_weight(y_true): \n",
    "        '''w0, w1 assign different weights to individual data points during training.'''\n",
    "        nc = np.bincount(y_true)\n",
    "        w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "        return w0, w1\n",
    "\n",
    "    def lgbm_tuning(features, permut=False, boruta=False):\n",
    "        metric = balanced_log_loss\n",
    "        eval_results_ = {}\n",
    "\n",
    "        cv_scores = [] # store all cv scores of outer loop inference\n",
    "\n",
    "        perm_df_ = pd.DataFrame()\n",
    "        feature_importances_ = pd.DataFrame()\n",
    "        boruta_df_ = pd.DataFrame()\n",
    "        \n",
    "        for i in range(CFG.n_optimize_repeats):\n",
    "            print(f'Repeat {blu}#{i+1}')\n",
    "            \n",
    "            # Make random under-sampling to balance classes\n",
    "            positive_count_train = train_df['Class'].value_counts()[1]\n",
    "            sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                            1: positive_count_train}, \n",
    "                                        random_state=15062023+i, \n",
    "                                        replacement=True)\n",
    "\n",
    "            X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "            \n",
    "            if CFG.undersample:\n",
    "                X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "            \n",
    "            # Create Stratified Multilabel k-Fold scheme\n",
    "            kf = MultilabelStratifiedKFold(n_splits=CFG.n_feature_sel_folds, shuffle=True, random_state=8062023+i)\n",
    "\n",
    "            # Create an oof array for inner loop\n",
    "            oof = np.zeros(X_re.shape[0])\n",
    "            \n",
    "            # Stratify based on Class and Alpha (3 types of conditions)\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start = 1): \n",
    "                X, y = X_re[features], y_re\n",
    "\n",
    "                # Split the dataset according to the fold indexes.\n",
    "                X_train = X.iloc[train_idx]\n",
    "                X_val = X.iloc[val_idx]\n",
    "                y_train = y.iloc[train_idx]\n",
    "                y_val = y.iloc[val_idx]\n",
    "\n",
    "\n",
    "                X_train = X_train.reset_index(drop=True)\n",
    "                y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "                # Store models here\n",
    "                models_ = [] \n",
    "\n",
    "                eval_results_[fold]= {}\n",
    "\n",
    "                clf = lgb.LGBMClassifier(**params)\n",
    "                clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                        eval_metric=bll_metric, # eval_sample_weight=w_val, \n",
    "                        verbose=1)\n",
    "\n",
    "                models_.append(clf)\n",
    "\n",
    "                val_preds = clf.predict_proba(X_val)[:,1]\n",
    "                oof[val_idx] = val_preds\n",
    "\n",
    "                val_score = metric(y_val, val_preds)\n",
    "                best_iter = clf.best_iteration_\n",
    "\n",
    "                print(f'Fold: {blu}{fold:>3}{res}| {metric.__name__}: {blu}{val_score:.5f}{res}'\n",
    "                    f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "\n",
    "                # permutation importance\n",
    "                if permut:\n",
    "                    perm = PermutationImportance(clf, scoring=None, n_iter=1, \n",
    "                                                random_state=42, cv=None, refit=False).fit(X_val, y_val)\n",
    "\n",
    "                    perm_importance_df = pd.DataFrame({'importance': perm.feature_importances_}, \n",
    "                                                    index=X_val.columns).sort_index()\n",
    "\n",
    "                    if perm_df_.shape[0] == 0:\n",
    "                        perm_df_ = perm_importance_df.copy()\n",
    "                    else:\n",
    "                        perm_df_ += perm_importance_df\n",
    "\n",
    "                # tree feature importance\n",
    "                f_i = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns), \n",
    "                                                reverse=True, key=lambda x: x[1]), \n",
    "                                columns=['Value','Feature'])\n",
    "\n",
    "                if feature_importances_.shape[0] == 0:\n",
    "                    feature_importances_ = f_i.copy()\n",
    "                else:\n",
    "\n",
    "                    feature_importances_['Value'] += f_i['Value']\n",
    "\n",
    "                # Boruta SHAP importance\n",
    "                if boruta:\n",
    "                    model = BoostBoruta(clf, importance_type='shap_importances', train_importance=False)\n",
    "                    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                            eval_metric=bll_metric, early_stopping_rounds=300, verbose=-1)\n",
    "\n",
    "                    boruta_importance_df = pd.DataFrame({'importance': model.ranking_}, \n",
    "                                                        index=X_train.columns).sort_index()\n",
    "                    if boruta_df_.shape[0] == 0:\n",
    "                        boruta_df_ = boruta_importance_df.copy()\n",
    "                    else:\n",
    "                        boruta_df_ += boruta_importance_df\n",
    "\n",
    "            fold_cv_score = metric(y_re, oof)\n",
    "            print(f'{red} CV score: {res} {metric.__name__}: {red}{fold_cv_score:.5f}{res}')\n",
    "            print(f'{\"*\" * 50}\\n')\n",
    "            cv_scores.append(fold_cv_score)\n",
    "\n",
    "\n",
    "        print(f'{red} Avg score {CFG.n_feature_sel_folds}-fold: {res} {metric.__name__}: {red}{np.mean(cv_scores):.5f}{res}')\n",
    "        print(f'{\"*\" * 50}\\n')\n",
    "        \n",
    "        if permut:\n",
    "            perm_df_ = perm_df_.sort_values('importance', ascending=False)\n",
    "            \n",
    "        if boruta:\n",
    "            boruta_df_ = boruta_df_.sort_values('importance')\n",
    "                                        \n",
    "        feature_importances_ = feature_importances_.sort_values('Value', ascending=False)\n",
    "        \n",
    "        return perm_df_, feature_importances_, boruta_df_, np.mean(cv_scores)\n",
    "\n",
    "    if CFG.feature_sel:\n",
    "        perm_df_, feature_importances_, boruta_df_, cv_scores = lgbm_tuning(features, permut=False, boruta=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check features correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    col = 'DA'\n",
    "    x = train_df[train_df[col] <= train_df[col].quantile(0.99)]\n",
    "    cm = x[[c for c in train_df.columns if c not in ['Id', 'Class']]].corr()\n",
    "    display(np.abs(cm[col]).sort_values(ascending=False)[1:])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.619184Z",
     "iopub.status.busy": "2023-06-08T15:32:11.618864Z",
     "iopub.status.idle": "2023-06-08T15:32:11.652915Z",
     "shell.execute_reply": "2023-06-08T15:32:11.652069Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.619157Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    perm_df_.to_csv('perm_df.csv')\n",
    "    perm_df_\n",
    "    perm_cols = set(perm_df_.index[-35:])\n",
    "    display(perm_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze tree gain feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-08T15:32:11.654626Z",
     "iopub.status.busy": "2023-06-08T15:32:11.654102Z",
     "iopub.status.idle": "2023-06-08T15:32:11.669674Z",
     "shell.execute_reply": "2023-06-08T15:32:11.668840Z",
     "shell.execute_reply.started": "2023-06-08T15:32:11.654583Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    feature_importances_.to_csv('feature_importances.csv')\n",
    "    feature_importances_\n",
    "    fi_cols = set(feature_importances_['Feature'].values[-23:])\n",
    "    display(fi_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze BORUTA importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.feature_sel:\n",
    "    boruta_df_.to_csv('boruta_df_.csv')\n",
    "    boruta_df_\n",
    "    boruta_cols = set(boruta_df_.index[-35:])\n",
    "    display(boruta_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-23 19:56:21,322] A new study created in memory with name: no-name-a25f53b1-4e99-427e-aa88-f6b47ed6397b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat \u001b[1m\u001b[34m#1\n"
     ]
    }
   ],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability ð‘ is replaced with max(min(ð‘,1âˆ’10âˆ’15),10âˆ’15)\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1 - y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2\n",
    "\n",
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def calc_log_loss_weight(y_true): \n",
    "    '''w0, w1 assign different weights to individual data points during training.'''\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    return w0, w1\n",
    "\n",
    "X, y = train_df[features], train_df['Class'] \n",
    "    \n",
    "def objective(trial):\n",
    "    param = {\n",
    "        # Main parameters\n",
    "#                     'device': 'gpu',\n",
    "#                     'gpu_platform_id': 0,\n",
    "#                     'gpu_device_id': 0,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'none',\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['goss', 'gbdt']),#, 'dart']),   \n",
    "        # Hyperparamters (in order of importance decreasing)\n",
    "        'n_estimators': CFG.n_estimators, # trial.suggest_int('n_estimators', 500, 1500),  # max number of trees in model\n",
    "        'early_stopping_round': CFG.early_stopping_rounds, \n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 3e-1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True), # L1,  alias: lambda_l1\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True), # L2, alias: lambda_l2\n",
    "         # decrease to deal with overfit\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),   # tree max depth \n",
    "         # decrease to deal with overfit\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 128),  # Max number of leaves in one tree\n",
    "                                                                # should be ~ 2**(max_depth-1)\n",
    "        'subsample': None, # Randomly select part of data without \n",
    "                                  # resampling if subsample < 1.0\n",
    "                                  # alias: bagging_fraction\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.7), # Randomly select a subset of features \n",
    "                                                                   # if colsample_bytree < 1.0\n",
    "                                                                   # alias:feature_fraction\n",
    "        # decrease to deal with overfit\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                             # aliases: min_data_in_leaf, \n",
    "        # increase for accuracy, decrease to deal with overfit\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255), # Max number of bins that feature values will be bucketed in\n",
    "        # increase to deal with overfit\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 1, 7), # Perform bagging at every k iteration, alias: bagging_freq\n",
    "\n",
    "#           'subsample_for_bin': 200000, # Number of data that sampled to construct feature discrete bins; setting this \n",
    "                                     # to larger value will give better training result but may increase train time \n",
    "#           'cat_smooth': trial.suggest_float('cat_smooth', 10.0, 100.0),  # this can reduce the effect of noises in \n",
    "                                                                       # categorical features, especially for \n",
    "                                                                       # categories with few data\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        param['is_unbalance'] = True\n",
    "        param['class_weight'] = 'balanced'\n",
    "    \n",
    "    if param['boosting_type'] != 'goss':\n",
    "        param['subsample'] = trial.suggest_float('subsample', 0.3, 0.7)\n",
    "\n",
    "    bll_list = list()\n",
    "    \n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under- or oversampling to balance classes\n",
    "        if CFG.undersample:\n",
    "            positive_count_train = train_df['Class'].value_counts()[1]\n",
    "            sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                            1: positive_count_train}, \n",
    "                                        random_state=15062023+i, \n",
    "                                        replacement=True)\n",
    "        elif CFG.oversample:\n",
    "            sampler = RandomOverSampler(random_state=2306020231)\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_optimize_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # oversample\n",
    "            if CFG.oversample:\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "            clf = lgb.LGBMClassifier(**param)\n",
    "            clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
    "                    eval_metric=bll_metric, verbose=0)\n",
    "\n",
    "            val_preds = clf.predict_proba(X_val)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "        bll_list.append(balanced_log_loss(y_re, oof))\n",
    "\n",
    "    return np.mean(bll_list)\n",
    "            \n",
    "\n",
    "if CFG.lgbm_optimize:\n",
    "#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials * 2)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df.to_csv(f'optuna_lgbm.csv')\n",
    "\n",
    "    display(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LGBM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if CFG.kaggle:\n",
    "    param_list = glob.glob(\"/kaggle/input/icr-optuna-no-da/optuna_lgbm.csv\")\n",
    "else:\n",
    "    param_list = glob.glob(\"optuna_lgbm.csv\")\n",
    "\n",
    "models = list()\n",
    "best_lgbm_params = list()\n",
    "\n",
    "lgbm_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if lgbm_params.shape[0] == 0:\n",
    "        lgbm_params = tmp\n",
    "    else:\n",
    "        lgbm_params = pd.concat([lgbm_params, tmp])\n",
    "        \n",
    "lgbm_params = lgbm_params.sort_values('value').head(CFG.n_stacking_models_lgbm)\n",
    "param_cols = [c for c in lgbm_params.columns if c.startswith('params_')]\n",
    "lgbm_params = lgbm_params[param_cols]\n",
    "\n",
    "for idx, row in lgbm_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['objective'] = 'binary'\n",
    "    row_dict['metric'] = 'none'\n",
    "#     row_dict['subsample_for_bin'] = 300000\n",
    "    row_dict['force_col_wise'] = False\n",
    "    row_dict['n_estimators'] = CFG.n_estimators\n",
    "    row_dict['early_stopping_round'] = CFG.early_stopping_rounds\n",
    "    row_dict['verbose'] = -1\n",
    "    row_dict['max_bin'] = 255\n",
    "    \n",
    "    row_dict['num_leaves'] = int(row_dict['num_leaves'])\n",
    "    row_dict['max_depth'] = int(row_dict['max_depth'])\n",
    "    row_dict['min_child_samples'] = int(row_dict['min_child_samples'])\n",
    "    row_dict['subsample_freq'] = int(row_dict['subsample_freq'])\n",
    "    row_dict['learning_rate'] = float(row_dict['learning_rate'])\n",
    "    \n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        row_dict['is_unbalance'] = True\n",
    "        row_dict['class_weight'] = 'balanced'\n",
    "        # row_dict['scale_pos_weight'] = class_imbalance\n",
    "    \n",
    "    if row_dict['boosting_type'] == 'goss':\n",
    "        row_dict['subsample'] = None\n",
    "        \n",
    "    best_lgbm_params.append(row_dict)\n",
    "\n",
    "if CFG.test:\n",
    "    best_lgbm_params = [{\n",
    "            'n_estimators': CFG.n_estimators,\n",
    "            'early_stopping_round': CFG.early_stopping_rounds,\n",
    "            'objective': 'binary',\n",
    "            'metric': 'logloss', \n",
    "            'n_jobs': -1,\n",
    "            'is_unbalance':True, \n",
    "            'verbose': -1,\n",
    "            'seed': 19062023,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = train_df[features], train_df['Class']\n",
    "\n",
    "def objective(trial):\n",
    "    bll_list = list()\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": CFG.n_estimators, # trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        \"early_stopping_rounds\": CFG.early_stopping_rounds,\n",
    "        \"verbosity\": 0,\n",
    "        \"random_state\": 14062023,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        # use exact for small dataset.\n",
    "        \"tree_method\": \"exact\",\n",
    "        # defines booster, gblinear for linear functions.\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),# \"dart\", \"gblinear\"]), \n",
    "        # L1 regularization weight.\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        # L2 regularization weight.\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        # sampling ratio for training data.\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n",
    "        # sampling according to each tree.\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "    }\n",
    "\n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        params[\"scale_pos_weight\"] = class_imbalance\n",
    "    \n",
    "    if params[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        params[\"learning_rate\"] = trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True) # alias eta\n",
    "        # maximum depth of the tree, signifies complexity of the tree.\n",
    "        params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "        # minimum child weight, larger the term more conservative the tree.\n",
    "        params[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "        # defines how selective algorithm is.\n",
    "        params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "    if params[\"booster\"] == \"dart\":\n",
    "        params[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        params[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        params[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        params[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "\n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under- or oversampling to balance classes\n",
    "        positive_count_train = train_df['Class'].value_counts()[1]\n",
    "        if CFG.undersample:\n",
    "            sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                            1: positive_count_train}, \n",
    "                                        random_state=15062023+i, \n",
    "                                        replacement=True)\n",
    "        elif CFG.oversample:\n",
    "            sampler = RandomOverSampler(random_state=2306020231)\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_optimize_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # oversample\n",
    "            if CFG.oversample:\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "            # Learning\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "            # Predict\n",
    "            val_preds = model.predict_proba(X_val)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "        \n",
    "        bll_list.append(balanced_log_loss(y_re, oof))    \n",
    "    \n",
    "    return np.mean(bll_list)\n",
    "\n",
    "if CFG.xgb_optimize:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials * 2)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df.to_csv(f'optuna_xgb.csv')\n",
    "\n",
    "    display(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load XGBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if CFG.kaggle:\n",
    "    param_list = glob.glob(\"/kaggle/input/icr-optuna-no-da/optuna_xgb.csv\")\n",
    "else:\n",
    "    param_list = glob.glob(\"optuna_xgb.csv\")\n",
    "\n",
    "models = list()\n",
    "best_xgb_params = list()\n",
    "\n",
    "xgb_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if xgb_params.shape[0] == 0:\n",
    "        xgb_params = tmp\n",
    "    else:\n",
    "        xgb_params = pd.concat([xgb_params, tmp])\n",
    "        \n",
    "xgb_params = xgb_params.sort_values('value').head(CFG.n_stacking_models_xgb)\n",
    "param_cols = [c for c in xgb_params.columns if c.startswith('params_')]\n",
    "xgb_params = xgb_params[param_cols]\n",
    "\n",
    "for idx, row in xgb_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['n_estimators'] = CFG.n_estimators\n",
    "    row_dict['early_stopping_rounds'] = CFG.early_stopping_rounds\n",
    "    row_dict['random_state'] = 14062023\n",
    "    row_dict['verbosity'] = 0\n",
    "    row_dict['objective'] = \"binary:logistic\"\n",
    "    row_dict['eval_metric'] = \"logloss\"\n",
    "    row_dict['tree_method'] = \"exact\"\n",
    "    row_dict['booster'] = \"gbtree\"\n",
    "\n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        row_dict['scale_pos_weight'] = class_imbalance\n",
    "\n",
    "    if row_dict[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        row_dict[\"max_depth\"] = int(row_dict[\"max_depth\"])\n",
    "        row_dict[\"min_child_weight\"] = int(row_dict[\"min_child_weight\"])\n",
    "    else:\n",
    "        row_dict[\"learning_rate\"] = None\n",
    "        row_dict[\"max_depth\"] = None\n",
    "        row_dict[\"min_child_weight\"] = None\n",
    "        row_dict[\"gamma\"] = None\n",
    "        row_dict[\"grow_policy\"] = None     \n",
    "\n",
    "    if row_dict[\"booster\"] != \"dart\":\n",
    "        row_dict[\"sample_type\"] = None\n",
    "        row_dict[\"normalize_type\"] = None\n",
    "        row_dict[\"rate_drop\"] = None\n",
    "        row_dict[\"skip_drop\"] = None\n",
    "\n",
    "    best_xgb_params.append(row_dict)\n",
    "\n",
    "if CFG.test:\n",
    "    best_xgb_params = [{\n",
    "            'n_estimators': CFG.n_estimators,\n",
    "            'early_stopping_rounds': CFG.early_stopping_rounds,\n",
    "            'objective': \"binary:logistic\",\n",
    "            'scale_pos_weight': class_imbalance, \n",
    "            'verbosity': 0,\n",
    "            'random_state': 19062023,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = train_df[features], train_df['Class']\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    bll_list = list()\n",
    "\n",
    "    # Parameters\n",
    "    params = {\n",
    "        'task_type': 'CPU', # GPU\n",
    "        'eval_metric': 'Logloss',\n",
    "        'loss_function': 'Logloss', \n",
    "        'random_seed': 19062023,\n",
    "        'od_type': 'Iter', # Type of overfitting detector - stop after k iteraions\n",
    "        'iterations' : CFG.n_estimators, # trial.suggest_int('iterations', 300, 1200),        \n",
    "        'od_wait': CFG.early_stopping_rounds, # Overfitting detector - stop training after k iterations without metric improvement\n",
    "        # 'metric_period': 100, # Show metric each k iterations\n",
    "        # Hyperparamters (in order of importance decreasing)\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS', 'No']),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-3, 3e-1), \n",
    "        'l2_leaf_reg': trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
    "        'depth' : trial.suggest_int('depth', 4, 10),  # Max tree depth                                          \n",
    "         # increase to deal with overfit\n",
    "        'random_strength': trial.suggest_float('random_strength', 0, 100), # The amount of randomness to use\n",
    "                                                                           # for scoring splits when the tree structure\n",
    "                                                                           # is selected. Helps to avoid overfitting\n",
    "                                                                           # CPU only\n",
    "        # per_float_feature_quantization='0:border_count=1024'\n",
    "        'border_count': 254, # trial.suggest_categorical('border_count', [128, 254]), # The number of splits for numerical features\n",
    "                                                                                      # bigger is better but slowly\n",
    "                                                                                      # alias: max_bin\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100), # Minimal number of data in one leaf\n",
    "                                                                           # aliases: min_child_samples, \n",
    "\n",
    "    }\n",
    "\n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        params['auto_class_weights'] = 'Balanced'\n",
    "        # params['scale_pos_weight'] = class_imbalance\n",
    "        \n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 100) # Assigns random \n",
    "                                                                                           # weights to objects\n",
    "                                                                                           # works only with \n",
    "                                                                                           # Bayesian bootstrap\n",
    "    if params[\"bootstrap_type\"] in [\"Poisson\", \"Bernoulli\", \"MVS\"]:\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.3, 1) # Percentage of objects to use \n",
    "                                                                        # at each split\n",
    "\n",
    "    if params['task_type'] == 'CPU' and params['bootstrap_type'] != 'Bayesian':\n",
    "        params[\"colsample_bylevel\"] = trial.suggest_float(\"colsample_bylevel\", 0.3, 1)  # Percentage of features to use \n",
    "                                                                                        # at each split;\n",
    "                                                                                        # with Bayesian bootstrap and Lossguide grop policy\n",
    "                                                                                        # leads to error (CatBoost bug)\n",
    "    else:\n",
    "        params[\"colsample_bylevel\"] = None                                                     \n",
    "\n",
    "    if params['grow_policy'] == 'Lossguide': \n",
    "        params['max_leaves'] = trial.suggest_int('max_leaves', 4, 128) # Max number of leaves in one tree \n",
    "                                                                       # decrease to deal with the overfit\n",
    "\n",
    "    if params['grow_policy'] == 'SymmetricTree': \n",
    "        params['boosting_type'] = trial.suggest_categorical('boosting_type', ['Ordered', 'Plain'])\n",
    "    else:\n",
    "        params['boosting_type'] = 'Plain'\n",
    "    \n",
    "    for i in range(CFG.n_optimize_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "\n",
    "        # Make random under- or oversampling to balance classes\n",
    "        positive_count_train = train_df['Class'].value_counts()[1]\n",
    "        if CFG.undersample:\n",
    "            sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                            1: positive_count_train}, \n",
    "                                        random_state=15062023+i, \n",
    "                                        replacement=True)\n",
    "        elif CFG.oversample:\n",
    "            sampler = RandomOverSampler(random_state=2306020231)\n",
    "\n",
    "        X_re, y_re = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class']\n",
    "        \n",
    "        if CFG.undersample:\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "        \n",
    "        # Create Stratified Multilabel k-Fold scheme\n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_optimize_folds, shuffle=True, random_state=10062023+i)\n",
    "\n",
    "        # Create an oof array for inner loop\n",
    "        oof = np.zeros(X_re.shape[0])\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=X_re[features], y=X_re.iloc[:,-3:]), start=1): \n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "            \n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # oversample\n",
    "            if CFG.oversample:\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "            train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "            val_pool = Pool(X_val, y_val, cat_features=['EJ'])\n",
    "\n",
    "            # Learning\n",
    "            model = cat.CatBoostClassifier(**params)     \n",
    "            # Add a callback for pruning\n",
    "#             pruning_callback = optuna.integration.CatBoostPruningCallback(trial, \"Logloss\")\n",
    "            model.fit(train_pool, eval_set=val_pool, verbose=0)#, callbacks=[pruning_callback])\n",
    "            # Evoke pruning manually\n",
    "#                 pruning_callback.check_pruned()\n",
    "            # Predict\n",
    "            val_preds = model.predict_proba(val_pool)[:,1]\n",
    "            oof[val_idx] = val_preds\n",
    "        \n",
    "        bll_list.append(balanced_log_loss(y_re, oof))    \n",
    "    \n",
    "    return np.mean(bll_list)\n",
    "\n",
    "if CFG.cb_optimize:\n",
    "#     study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=100), direction=\"minimize\")\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=CFG.n_trials)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    df = study.trials_dataframe().sort_values('value')\n",
    "    df.to_csv(f'optuna_catboost.csv')\n",
    "\n",
    "    display(df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CatBoost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if CFG.kaggle:\n",
    "    param_list = glob.glob(\"/kaggle/input/icr-optuna-no-da/optuna_catboost.csv\")\n",
    "else:\n",
    "    param_list = glob.glob(\"optuna_catboost.csv\")\n",
    "\n",
    "models = list()\n",
    "best_cb_params = list()\n",
    "\n",
    "cb_params = pd.DataFrame()\n",
    "\n",
    "for f in param_list:\n",
    "    tmp = pd.read_csv(f, index_col='Unnamed: 0')\n",
    "    if cb_params.shape[0] == 0:\n",
    "        cb_params = tmp\n",
    "    else:\n",
    "        cb_params = pd.concat([cb_params, tmp])\n",
    "        \n",
    "cb_params = cb_params.sort_values('value').head(CFG.n_stacking_models_cb)\n",
    "param_cols = [c for c in cb_params.columns if c.startswith('params_')]\n",
    "cb_params = cb_params[param_cols]\n",
    "\n",
    "\n",
    "for idx, row in cb_params.iterrows():\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['task_type'] = 'CPU'\n",
    "    row_dict['eval_metric'] = 'Logloss'\n",
    "    row_dict['loss_function'] = 'Logloss'\n",
    "    row_dict['random_seed'] = 13062023\n",
    "    row_dict['verbose'] = 0\n",
    "    row_dict['od_type'] = 'Iter'\n",
    "    row_dict['iterations'] = CFG.n_estimators * 4\n",
    "    row_dict['od_wait'] = CFG.early_stopping_rounds\n",
    "    row_dict['border_count'] = 254\n",
    "    \n",
    "    if not CFG.oversample and not CFG.undersample:\n",
    "        row_dict['auto_class_weights'] = 'Balanced'\n",
    "        \n",
    "    if row_dict[\"task_type\"] != \"GPU\":\n",
    "        row_dict['colsample_bylevel'] = None\n",
    "    \n",
    "    if row_dict[\"bootstrap_type\"] != \"Bayesian\":\n",
    "        row_dict['bagging_temperature'] = None\n",
    "        \n",
    "    if row_dict[\"bootstrap_type\"] not in [\"Poisson\", \"Bernoulli\", \"MVS\"]:\n",
    "        row_dict['subsample'] = None\n",
    "    \n",
    "    if row_dict['grow_policy'] == 'Lossguide':\n",
    "        row_dict['max_leaves'] = int(row_dict['max_leaves'])\n",
    "    else:\n",
    "        row_dict['max_leaves'] = None\n",
    "    \n",
    "    if row_dict['grow_policy'] != 'SymmetricTree':\n",
    "        row_dict['boosting_type'] = 'Plain'\n",
    "    \n",
    "    best_cb_params.append(row_dict)\n",
    "\n",
    "if CFG.test:\n",
    "    best_cb_params = [{\n",
    "            'iterations': CFG.n_estimators,\n",
    "            'od_type': 'Iter',\n",
    "            'od_wait': CFG.early_stopping_rounds,\n",
    "            'eval_metric': \"Logloss\",\n",
    "            'loss_function': \"Logloss\",\n",
    "            'auto_class_weights': 'Balanced', \n",
    "            'verbose': 0,\n",
    "            'random_seed': 19062023,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa4f160349e495f83578d159b44e775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28436\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14375\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26257\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15897\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14087\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21062\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19912\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.62434\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19571\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23145\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17294\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20016\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.40427\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13160\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21388\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42511\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17960\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38630\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12127\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13838\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.30612\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.61337\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20957\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17343\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15148\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14389\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24021\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14990\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18957\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20351\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09552\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18244\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42900\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27547\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15800\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16966\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38920\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19024\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23169\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21847\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12610\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20781\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15798\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.32471\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.50345\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13147\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22545\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15477\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20994\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33348\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.54417\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18654\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12922\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16203\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23143\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12666\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26163\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18825\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24650\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15521\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12222\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.45089\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22500\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25580\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27158\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10306\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12994\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22497\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28934\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16085\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.71136\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24018\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28775\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21747\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21362\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33044\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18550\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16903\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16600\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12545\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15334\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09235\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20880\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21089\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17863\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19273\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15815\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24444\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27685\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.49298\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22331\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12124\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25748\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16900\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18420\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12253\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16778\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.59113\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14190\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28333\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07261\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20857\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.83530\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11600\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.30110\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17806\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19436\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.33045\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23825\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12594\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12986\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19882\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14675\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.36166\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24159\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14034\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21289\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.59521\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22147\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07768\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09640\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16361\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.30306\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23826\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.66862\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18522\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09486\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12117\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28777\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17292\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15357\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.58124\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15951\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17835\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24988\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08436\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17455\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22965\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19823\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22549\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23305\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08505\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19456\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12874\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.49857\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25603\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10621\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16456\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14233\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28121\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18477\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19459\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14551\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21042\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21566\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18781\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19529\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.61795\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25251\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13804\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19833\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27960\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15555\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.07429\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.43225\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10666\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21210\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15309\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22506\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.32071\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26187\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28391\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27189\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19204\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22186\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12106\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23889\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09078\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11499\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.61717\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16076\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.58890\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14857\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13866\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14478\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14760\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38078\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.31794\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21198\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14102\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21115\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25638\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16027\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16347\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19233\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.54033\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20541\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13272\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23876\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19434\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.32915\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22450\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21381\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.31555\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20116\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10387\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14586\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17059\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16773\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.49761\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12504\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.32033\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23640\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21630\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19355\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13827\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20569\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.65251\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14542\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12084\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08474\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.08269\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26892\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14796\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13034\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28467\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.50213\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16301\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18408\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.30996\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20776\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.26747\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.59724\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23475\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.27851\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.38779\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12570\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15268\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.06746\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.10638\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42142\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11101\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16939\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16051\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39491\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28216\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.28539\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21399\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.09193\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17481\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21036\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19877\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.30351\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.79824\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17553\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14029\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13271\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23987\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.35652\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11233\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29653\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.42933\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17064\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.12464\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20825\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13150\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29808\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21371\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16059\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.21230\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11507\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16223\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19136\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20773\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.24437\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.69112\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.16511\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18210\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.19188\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18021\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25088\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.29823\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.39073\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.23518\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.37656\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15575\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15404\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.11116\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.20328\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13729\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Training with \u001b[1m\u001b[34m38\u001b[0m features\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  1\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.22139\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  2\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.56985\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  3\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.17430\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  4\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.25785\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  5\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.13041\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  6\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15493\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  7\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.55349\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  8\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.18671\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m  9\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.14846\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Fold: \u001b[1m\u001b[34m 10\u001b[0m| bll_metric: \u001b[1m\u001b[34m0.15490\u001b[0m | Best iteration: \u001b[1m\u001b[34m   0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def bll_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False\n",
    "\n",
    "def pp_prob(p):\n",
    "    c0 = p[:,0].sum()\n",
    "    c1 = p[:,1:].sum()\n",
    "    new_p = p * np.array([[1/(c0 if i==0 else c1) for i in range(p.shape[1])]])\n",
    "    new_p = new_p / np.sum(new_p,axis=1,keepdims=1)\n",
    "    return np.sum(new_p[:,1:],1,keepdims=False)\n",
    "\n",
    "def model_train(how, best_params):\n",
    "    # Make random under-sampling to balance classes\n",
    "    positive_count_train = train_df['Class'].value_counts()[1]\n",
    "    if CFG.undersample:\n",
    "        sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, \n",
    "                                                        1: positive_count_train}, \n",
    "                                    random_state=150620231, \n",
    "                                    replacement=True)\n",
    "    elif CFG.oversample:\n",
    "        sampler = RandomOverSampler(random_state=2306020231)\n",
    "\n",
    "    if how == 'tabpfn':\n",
    "        X_re, y_re, test = pd.concat([train_df_tabpfn, greeks.iloc[:,1:4]], axis=1), train_df['Class'], test_df_tabpfn\n",
    "    else:\n",
    "        X_re, y_re, test = pd.concat([train_df[features], greeks.iloc[:,1:4]], axis=1), train_df['Class'], test_df[features]\n",
    "\n",
    "    if CFG.undersample:\n",
    "        X_re, y_re = sampler.fit_resample(X_re, y_re)\n",
    "    \n",
    "    oof_level2 = np.zeros([y_re.shape[0], len(best_params) + 1])\n",
    "    oof_level2[:, len(best_params)] = y_re\n",
    "    oof_level2_test = np.zeros([test_df.shape[0], len(best_params)])\n",
    "    \n",
    "    for i, params in tqdm(enumerate(best_params), total=len(best_params)):\n",
    "    \n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_stacking_folds, shuffle=True, random_state=80620231+i)\n",
    "\n",
    "        print(f\"Training with {blu}{len(features)}{res} features\")\n",
    "\n",
    "        for fold, (fit_idx, val_idx) in enumerate(kf.split(X=X_re, y=X_re.iloc[:,-3:]), start = 1):\n",
    "            X, y = X_re[features], y_re\n",
    "            \n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[fit_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[fit_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # oversample\n",
    "            if CFG.oversample:\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "            \n",
    "            if how == 'catboost':\n",
    "                train_pool = Pool(X_train, y_train, cat_features=['EJ'])\n",
    "                val_pool = Pool(X_val, y_val, cat_features=['EJ'])           \n",
    "            \n",
    "            if how == 'lgbm':\n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=bll_metric, verbose=0)\n",
    "                best_iter = model.best_iteration_\n",
    "            elif how == 'xgboost':\n",
    "                model = xgb.XGBClassifier(**params)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "                best_iter = model.get_booster().best_iteration\n",
    "            elif how == 'catboost':\n",
    "                model = cat.CatBoostClassifier(**params)\n",
    "                model.fit(train_pool, eval_set=val_pool, verbose=0)\n",
    "                best_iter = model.best_iteration_\n",
    "            elif how == 'tabpfn':\n",
    "                model = TabPFNClassifier(N_ensemble_configurations=64, device='cuda:0')\n",
    "                model.fit(X_train, y_train, overwrite_warning=True)\n",
    "                best_iter = 0\n",
    "            else:\n",
    "                return None, None\n",
    "                \n",
    "            if how == 'tabpfn':\n",
    "                val_preds = pp_prob(model.predict_proba(X_val))\n",
    "                oof_level2_test[:, i] += pp_prob(model.predict_proba(test))\n",
    "            else:\n",
    "                val_preds = model.predict_proba(X_val)[:,1]\n",
    "                oof_level2_test[:, i] += model.predict_proba(test)[:,1]\n",
    "            \n",
    "            oof_level2[val_idx, i] = val_preds\n",
    "\n",
    "            val_score = balanced_log_loss(y_val, val_preds)\n",
    "            \n",
    "            print(f'Fold: {blu}{fold:>3}{res}| bll_metric: {blu}{val_score:.5f}{res}'\n",
    "                    f' | Best iteration: {blu}{best_iter:>4}{res}') \n",
    "        \n",
    "    return oof_level2, oof_level2_test / CFG.n_stacking_folds\n",
    "\n",
    "\n",
    "oof_train_list = list()\n",
    "oof_test_list = list()\n",
    "\n",
    "if CFG.lgbm_train:\n",
    "    oof_level2_lgbm, oof_level2_test_lgbm = model_train('lgbm', best_lgbm_params)\n",
    "    oof_train_list.append(oof_level2_lgbm[:,:-1])\n",
    "    oof_test_list.append(oof_level2_test_lgbm)\n",
    "    y = oof_level2_lgbm[:,-1]\n",
    "\n",
    "if CFG.xgb_train:\n",
    "    oof_level2_xgb, oof_level2_test_xgb = model_train('xgboost', best_xgb_params)\n",
    "    oof_train_list.append(oof_level2_xgb[:,:-1])\n",
    "    oof_test_list.append(oof_level2_test_xgb)\n",
    "    y = oof_level2_xgb[:,-1]\n",
    "\n",
    "if CFG.cb_train:\n",
    "    oof_level2_cb, oof_level2_test_cb = model_train('catboost', best_cb_params)\n",
    "    oof_train_list.append(oof_level2_cb[:,:-1])\n",
    "    oof_test_list.append(oof_level2_test_cb)\n",
    "    y = oof_level2_cb[:,-1]\n",
    "\n",
    "if CFG.tabpfn_train:\n",
    "    oof_level2_tabpfn, oof_level2_test_tabpfn = model_train('tabpfn', [i for i in range(CFG.n_stacking_models_tabpfn)])\n",
    "    oof_train_list.append(oof_level2_tabpfn[:,:-1])\n",
    "    oof_test_list.append(oof_level2_test_tabpfn)\n",
    "    y = oof_level2_tabpfn[:,-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2339165231760004\n",
      "0.20671325918340408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "oof_level2 = np.concatenate(oof_train_list, axis=1)\n",
    "oof_level2_test = np.concatenate(oof_test_list, axis=1)\n",
    "\n",
    "X = oof_level2\n",
    "\n",
    "# mean bll\n",
    "print(balanced_log_loss(y, np.mean(X, axis=1)))\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced')\n",
    "lr.fit(X, y)\n",
    "\n",
    "pred = lr.predict_proba(X)[:,1]\n",
    "\n",
    "# lr bll\n",
    "print(balanced_log_loss(y, pred))\n",
    "\n",
    "weights = lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM + CatBoost + XGBoost + TabPFN\n",
    "# 0.17472710249039772\n",
    "# 0.09683636947851168\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which objects are the most erroneus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[509, 102, 586, 292, 372, 267, 313]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.mean(X, axis=1)\n",
    "errors = pd.Series(np.abs(y - preds))\n",
    "errors = errors.sort_values(ascending=False) \n",
    "errors[errors >= errors.quantile(0.99)].index.to_list()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best class threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_prob3(_oof, _p, num=1.5):\n",
    "    # increase (num > 1) or decrease (num < 1) binary prediction value\n",
    "    oof = num * _oof / ((num - 1) * _oof + 1)\n",
    "    p = num * _p / ((num - 1) * _p + 1)\n",
    "    return oof, p\n",
    "\n",
    "def inflate_preds(_y, _oof, _p):\n",
    "    # find the best num multiplier for binary prediction\n",
    "    best_score = np.inf\n",
    "    best_num = None\n",
    "    best_oof = None\n",
    "    best_p = None\n",
    "    \n",
    "    candidates = np.linspace(0.05,5,100)\n",
    "    for num in candidates:\n",
    "        curr_oof, curr_p = pp_prob3(_oof, _p, num)\n",
    "        curr_score = balanced_log_loss(_y, curr_oof)\n",
    "        if curr_score < best_score:\n",
    "            best_num = num\n",
    "            best_score = curr_score\n",
    "            best_p = curr_p\n",
    "            best_oof = curr_oof\n",
    "    print('best num:', round(best_num, 2), '/ best score:', best_score)\n",
    "    return best_oof, best_p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-08T15:32:38.352845Z",
     "iopub.status.idle": "2023-06-08T15:32:38.353222Z",
     "shell.execute_reply": "2023-06-08T15:32:38.353059Z",
     "shell.execute_reply.started": "2023-06-08T15:32:38.353042Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  class_0  class_1\n",
       "0  00eed32682bb      0.5      0.5\n",
       "1  010ebe33f668      0.5      0.5\n",
       "2  02fa521e1838      0.5      0.5\n",
       "3  040e15f562a2      0.5      0.5\n",
       "4  046e85c7cc7f      0.5      0.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(X):\n",
    "    y = np.zeros(len(X))\n",
    "    for i in range(oof_level2_test.shape[1]):\n",
    "        # y += weights[i] * oof_level2_test[:,i]\n",
    "        y += oof_level2_test[:,i]\n",
    "    # return y / sum(weights)\n",
    "    return y / oof_level2_test.shape[1]\n",
    "\n",
    "predictions = predict(test_df[features])\n",
    "\n",
    "if CFG.adjust_class_threshold:\n",
    "    _, predictions = inflate_preds(y, np.mean(X, axis=1), predictions)\n",
    "\n",
    "test_df['class_1'] = predictions\n",
    "test_df['class_0'] = 1 - predictions\n",
    "\n",
    "sample_submission[['class_0', 'class_1']] = test_df[['class_0', 'class_1']]\n",
    "sample_submission.to_csv(r\"submission.csv\", index=False)\n",
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
